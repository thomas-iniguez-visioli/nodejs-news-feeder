{
  "lastCheckTimestamp": 1764867323817,
  "reposPaginationLimit": 250,
  "releasePaginationLimit": 10,
  "commentsPaginationLimit": 100,
  "retrospective": {
    "lastDay": "2024-12-09",
    "nextDay": "2024-12-10"
  },
  "breakDelimiter": "</image>",
  "discussionsInScope": [],
  "issuesInScope": [],
  "cve": {
    "apiEndpoint": "https://services.nvd.nist.gov/rest/json/cves/2.0",
    "resultsPerPage": 100,
    "maxResults": 500,
    "apiKey": null,
    "minSeverity": null
  },
  "lastFeedContent": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\r\n<rss version=\"2.0\" xmlns:atom=\"http://www.w3.org/2005/Atom\">\r\n  <channel>\r\n    <title>cybernews</title>\r\n    <link>https://thomas-iniguez-visioli.github.io/nodejs-news-feeder/feed.xml</link>\r\n    <atom:link href=\"https://thomas-iniguez-visioli.github.io/nodejs-news-feeder/feed.xml\" rel=\"self\" type=\"application/atom+xml\"/>\r\n    <description>fuite de donnée enregistrée </description>\r\n    <pubDate>Tue, 13 Jun 2023 04:17:50 GMT</pubDate>\r\n    <language>en-us</language>\r\n    <docs>https://validator.w3.org/feed/docs/rss2.html</docs>\r\n    <lastBuildDate>Thu, 04 Dec 2025 16:55:00 GMT</lastBuildDate>\r\n    <image>\r\n      <title>Node.js News</title>\r\n      <url>https://nodejs.org/static/images/logo-hexagon-card.png</url>\r\n      <link>https://github.com/nodejs/nodejs-news-feeder</link>\r\n    </image>\n    <item>\n      <title>Chauffe, bruit, performances  que vaut la Geforce RTX 5070 Ti de Zotac sur les plus gros jeux du moment ? [Sponso]</title>\n      <description>![CDATA[div class=\"chapo has-text-weight-semibold mb-5\">\ndiv>Connaissez-vous Zotac ? Bien connue dans le petit monde du hardware PC gaming, cette marque asiatique est spécialisée dans la conception de cartes graphiques Nvidia. Une activité dans laquelle elle excelle, comme en témoignent nos tests de performances réalisés sur sa RTX 5070 Ti Solid SFF./div>\n/div>]]>  </description>\n      <pubDate>Thu, 04 Dec 2025 16:32:00 GMT</pubDate>\n      <link>https//www.frandroid.com/produits-android/hardware/cartes-graphiques/2895913_chauffe-bruit-performances-que-vaut-la-geforce-rtx-5070-ti-de-zotac-sur-les-plus-gros-jeux-du-moment</link>\n      <guid>https://www.frandroid.com/produits-android/hardware/cartes-graphiques/2895913_chauffe-bruit-performances-que-vaut-la-geforce-rtx-5070-ti-de-zotac-sur-les-plus-gros-jeux-du-moment</guid><category><![CDATA[Cartes graphiques]]></category>\n<category><![CDATA[Hardware]]></category>\n<category><![CDATA[Marques]]></category>\n<category><![CDATA[Nvidia]]></category>\n<category><![CDATA[Produits]]></category>\n<category><![CDATA[Nvidia DLSS]]></category>\n<category><![CDATA[Nvidia GeForce RTX 5070 Ti]]></category>\n<category><![CDATA[zotac]]></category>\n    </item>\n  \n    <item>\n      <title>Amazon retire les doublages IA de l’anime Banana Fish après la colère des fans</title>\n      <description>![CDATA[\nLe lancement, fin novembre 2025, par Amazon de doublages d’anime générés par IA en anglais a déclenché une tempête, entre fans scandalisés, acteurs de doublage indignés et extraits moqués en masse sur les réseaux sociaux. Face aux critiques, la plateforme a rapidement fait marche arrière.\n]]>  </description>\n      <pubDate>Thu, 04 Dec 2025 16:33:00 GMT</pubDate>\n      <link>https//www.numerama.com/pop-culture/2134959-amazon-retire-les-doublages-ia-de-lanime-banana-fish-apres-la-colere-des-fans.html</link>\n      <guid>https://www.numerama.com/pop-culture/2134959-amazon-retire-les-doublages-ia-de-lanime-banana-fish-apres-la-colere-des-fans.html</guid><category><![CDATA[Pop culture]]></category>\n<category><![CDATA[Séries et cinéma]]></category>\n<category><![CDATA[Streaming]]></category>\n<category><![CDATA[Amazon]]></category>\n<category><![CDATA[Anglais]]></category>\n<category><![CDATA[Anime]]></category>\n<category><![CDATA[Doublage]]></category>\n<category><![CDATA[IA]]></category>\n<category><![CDATA[Intelligence artificielle]]></category>\n<category><![CDATA[Japonais]]></category>\n<category><![CDATA[Manga]]></category>\n<category><![CDATA[réseaux sociaux]]></category>\n    </item>\n  \n    <item>\n      <title>Meta fait un sale coup à Apple  comment expliquer la fuite de ses talents ?</title>\n      <description>![CDATA[\nLe départ d'Alan Dye, visage du design chez Apple et membre de l'équipe design depuis 2006, est un coup dur pour le géant californien, qui voit de nombreuses pointures partir à la chaîne. Meta, qui ne cesse de déclarer la guerre à Apple depuis des années, est prêt à tout pour lui piquer ses meilleurs talents.\n]]>  </description>\n      <pubDate>Thu, 04 Dec 2025 16:36:00 GMT</pubDate>\n      <link>https//www.numerama.com/tech/2135089-meta-fait-un-sale-coup-a-apple-comment-expliquer-la-fuite-de-ses-talents.html</link>\n      <guid>https://www.numerama.com/tech/2135089-meta-fait-un-sale-coup-a-apple-comment-expliquer-la-fuite-de-ses-talents.html</guid><category><![CDATA[Apple iPhone]]></category>\n<category><![CDATA[Smartphone]]></category>\n<category><![CDATA[Tech]]></category>\n<category><![CDATA[Apple]]></category>\n<category><![CDATA[Design]]></category>\n<category><![CDATA[iOS 26]]></category>\n<category><![CDATA[Meta]]></category>\n    </item>\n  \n    <item>\n      <title>LAX (Los Angeles) on 2025-12-15</title>\n      <description>![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>15/var>, var data-var='time'>1000/var> - var data-var='time'>1400/var> UTC/strong>small>Dec var data-var='date'> 4/var>, var data-var='time'>1628/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in LAX (Los Angeles) datacenter on 2025-12-15 between 1000 and 1400 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  </description>\n      <pubDate>Mon, 15 Dec 2025 10:00:00 GMT</pubDate>\n      <link>https//www.cloudflarestatus.com/incidents/f346hryd0kf7</link>\n      <guid>https://www.cloudflarestatus.com/incidents/f346hryd0kf7</guid>\n    </item>\n  \r\n    <item>\r\n      <title>ICN (Seoul) on 2025-12-15</title>\r\n      <description>![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>15/var>, var data-var='time'>1700/var> - var data-var='time'>2300/var> UTC/strong>small>Dec var data-var='date'> 4/var>, var data-var='time'>0110/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in ICN (Seoul) datacenter on 2025-12-15 between 1700 and 2300 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  </description>\r\n      <pubDate>Mon, 15 Dec 2025 17:00:00 GMT</pubDate>\r\n      <link>https//www.cloudflarestatus.com/incidents/wv1jccnb1gch</link>\r\n      <guid>https://www.cloudflarestatus.com/incidents/wv1jccnb1gch</guid>\r\n    </item>\r\n    <item>\r\n      <title>IAD (Ashburn) on 2025-12-15</title>\r\n      <description>![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>15/var>, var data-var='time'>0700/var> - var data-var='time'>1100/var> UTC/strong>small>Dec var data-var='date'> 4/var>, var data-var='time'>1018/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in IAD (Ashburn) datacenter on 2025-12-15 between 0700 and 1100 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  </description>\r\n      <pubDate>Mon, 15 Dec 2025 07:00:00 GMT</pubDate>\r\n      <link>https//www.cloudflarestatus.com/incidents/zy74fzks8cdq</link>\r\n      <guid>https://www.cloudflarestatus.com/incidents/zy74fzks8cdq</guid>\r\n    </item>\r\n    <item>\r\n      <title>YXE (Saskatoon) on 2025-12-12</title>\r\n      <description>![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>12/var>, var data-var='time'>0830/var> - var data-var='time'>1300/var> UTC/strong>small>Dec var data-var='date'> 4/var>, var data-var='time'>0858/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in YXE (Saskatoon) datacenter on 2025-12-12 between 0830 and 1300 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  </description>\r\n      <pubDate>Fri, 12 Dec 2025 08:30:00 GMT</pubDate>\r\n      <link>https//www.cloudflarestatus.com/incidents/jr4wt9dntrvj</link>\r\n      <guid>https://www.cloudflarestatus.com/incidents/jr4wt9dntrvj</guid>\r\n    </item>\r\n    <item>\r\n      <title>YYC (Calgary) on 2025-12-12</title>\r\n      <description>![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>12/var>, var data-var='time'>0830/var> - var data-var='time'>1300/var> UTC/strong>small>Dec var data-var='date'> 4/var>, var data-var='time'>0858/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in YYC (Calgary) datacenter on 2025-12-12 between 0830 and 1300 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  </description>\r\n      <pubDate>Fri, 12 Dec 2025 08:30:00 GMT</pubDate>\r\n      <link>https//www.cloudflarestatus.com/incidents/b70fwxb4g22t</link>\r\n      <guid>https://www.cloudflarestatus.com/incidents/b70fwxb4g22t</guid>\r\n    </item>\r\n    <item>\r\n      <title>DEN (Denver) on 2025-12-12</title>\r\n      <description>![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>12/var>, var data-var='time'>0830/var> - var data-var='time'>1300/var> UTC/strong>small>Dec var data-var='date'> 4/var>, var data-var='time'>0902/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in DEN (Denver) datacenter on 2025-12-12 between 0830 and 1300 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  </description>\r\n      <pubDate>Fri, 12 Dec 2025 08:30:00 GMT</pubDate>\r\n      <link>https//www.cloudflarestatus.com/incidents/hj7zvl61kxl8</link>\r\n      <guid>https://www.cloudflarestatus.com/incidents/hj7zvl61kxl8</guid>\r\n    </item>\r\n    <item>\r\n      <title>DFW (Dallas) on 2025-12-12</title>\r\n      <description>![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>12/var>, var data-var='time'>0800/var> - var data-var='time'>1200/var> UTC/strong>small>Dec var data-var='date'> 4/var>, var data-var='time'>1104/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in DFW (Dallas) datacenter on 2025-12-12 between 0800 and 1200 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  </description>\r\n      <pubDate>Fri, 12 Dec 2025 08:00:00 GMT</pubDate>\r\n      <link>https//www.cloudflarestatus.com/incidents/g038h6c8h1nh</link>\r\n      <guid>https://www.cloudflarestatus.com/incidents/g038h6c8h1nh</guid>\r\n    </item>\r\n    <item>\r\n      <title>HKG (Hong Kong) on 2025-12-11</title>\r\n      <description>![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>11/var>, var data-var='time'>1800/var> - var data-var='time'>2300/var> UTC/strong>small>Dec var data-var='date'> 3/var>, var data-var='time'>0530/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in HKG (Hong Kong) datacenter on 2025-12-11 between 1800 and 2300 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  </description>\r\n      <pubDate>Thu, 11 Dec 2025 18:00:00 GMT</pubDate>\r\n      <link>https//www.cloudflarestatus.com/incidents/zs533w5kzgdx</link>\r\n      <guid>https://www.cloudflarestatus.com/incidents/zs533w5kzgdx</guid>\r\n    </item>\r\n    <item>\r\n      <title>SIN (Singapore) on 2025-12-11</title>\r\n      <description>![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>11/var>, var data-var='time'>1600/var> UTC nbsp-nbsp Dec var data-var='date'>12/var>, var data-var='time'>0000/var> UTC/strong>small>Dec var data-var='date'> 4/var>, var data-var='time'>0346/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in SIN (Singapore) datacenter between 2025-12-11 1600 and 2025-12-12 0000 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  </description>\r\n      <pubDate>Thu, 11 Dec 2025 16:00:00 GMT</pubDate>\r\n      <link>https//www.cloudflarestatus.com/incidents/6wlpd2nz1zpd</link>\r\n      <guid>https://www.cloudflarestatus.com/incidents/6wlpd2nz1zpd</guid>\r\n    </item>\r\n    <item>\r\n      <title>AUS (Austin) on 2025-12-11</title>\r\n      <description>![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>11/var>, var data-var='time'>0900/var> - var data-var='time'>1200/var> UTC/strong>small>Dec var data-var='date'> 4/var>, var data-var='time'>1102/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in AUS (Austin) datacenter on 2025-12-11 between 0900 and 1200 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  </description>\r\n      <pubDate>Thu, 11 Dec 2025 09:00:00 GMT</pubDate>\r\n      <link>https//www.cloudflarestatus.com/incidents/vq283hs7vtqw</link>\r\n      <guid>https://www.cloudflarestatus.com/incidents/vq283hs7vtqw</guid>\r\n    </item>\r\n    <item>\r\n      <title>SJC (San Jose) on 2025-12-11</title>\r\n      <description>![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>11/var>, var data-var='time'>0830/var> - var data-var='time'>1300/var> UTC/strong>small>Dec var data-var='date'> 3/var>, var data-var='time'>2300/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in SJC (San Jose) datacenter on 2025-12-11 between 0830 and 1300 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  </description>\r\n      <pubDate>Thu, 11 Dec 2025 08:30:00 GMT</pubDate>\r\n      <link>https//www.cloudflarestatus.com/incidents/9rcq983c8w6z</link>\r\n      <guid>https://www.cloudflarestatus.com/incidents/9rcq983c8w6z</guid>\r\n    </item>\r\n    <item>\r\n      <title>TLH (Tallahassee) on 2025-12-11</title>\r\n      <description>![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>11/var>, var data-var='time'>0700/var> - var data-var='time'>1100/var> UTC/strong>small>Dec var data-var='date'> 3/var>, var data-var='time'>2232/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in TLH (Tallahassee) datacenter on 2025-12-11 between 0700 and 1100 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  </description>\r\n      <pubDate>Thu, 11 Dec 2025 07:00:00 GMT</pubDate>\r\n      <link>https//www.cloudflarestatus.com/incidents/gqs7jxs4ndzw</link>\r\n      <guid>https://www.cloudflarestatus.com/incidents/gqs7jxs4ndzw</guid>\r\n    </item>\r\n    <item>\r\n      <title>IAD (Ashburn) on 2025-12-11</title>\r\n      <description>![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>11/var>, var data-var='time'>0700/var> - var data-var='time'>1100/var> UTC/strong>small>Dec var data-var='date'> 3/var>, var data-var='time'>1816/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in IAD (Ashburn) datacenter on 2025-12-11 between 0700 and 1100 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  </description>\r\n      <pubDate>Thu, 11 Dec 2025 07:00:00 GMT</pubDate>\r\n      <link>https//www.cloudflarestatus.com/incidents/fgtpdgmv4mr5</link>\r\n      <guid>https://www.cloudflarestatus.com/incidents/fgtpdgmv4mr5</guid>\r\n    </item>\r\n    <item>\r\n      <title>EZE (Buenos Aires) on 2025-12-11</title>\r\n      <description>![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>11/var>, var data-var='time'>0500/var> - var data-var='time'>0900/var> UTC/strong>small>Dec var data-var='date'> 4/var>, var data-var='time'>0942/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in EZE (Buenos Aires) datacenter on 2025-12-11 between 0500 and 0900 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  </description>\r\n      <pubDate>Thu, 11 Dec 2025 05:00:00 GMT</pubDate>\r\n      <link>https//www.cloudflarestatus.com/incidents/cb2j6y554165</link>\r\n      <guid>https://www.cloudflarestatus.com/incidents/cb2j6y554165</guid>\r\n    </item>\r\n    <item>\r\n      <title>GRU (São Paulo) on 2025-12-11</title>\r\n      <description>![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>11/var>, var data-var='time'>0500/var> - var data-var='time'>0900/var> UTC/strong>small>Dec var data-var='date'> 2/var>, var data-var='time'>1726/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in GRU (São Paulo) datacenter on 2025-12-11 between 0500 and 0900 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  </description>\r\n      <pubDate>Thu, 11 Dec 2025 05:00:00 GMT</pubDate>\r\n      <link>https//www.cloudflarestatus.com/incidents/mzlhhfz1lnhc</link>\r\n      <guid>https://www.cloudflarestatus.com/incidents/mzlhhfz1lnhc</guid>\r\n    </item>\r\n    <item>\r\n      <title>SIN (Singapore) on 2025-12-10</title>\r\n      <description>![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>10/var>, var data-var='time'>1600/var> UTC nbsp-nbsp Dec var data-var='date'>11/var>, var data-var='time'>0000/var> UTC/strong>small>Dec var data-var='date'> 4/var>, var data-var='time'>0344/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in SIN (Singapore) datacenter between 2025-12-10 1600 and 2025-12-11 0000 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  </description>\r\n      <pubDate>Wed, 10 Dec 2025 16:00:00 GMT</pubDate>\r\n      <link>https//www.cloudflarestatus.com/incidents/lwl9y07g3jr8</link>\r\n      <guid>https://www.cloudflarestatus.com/incidents/lwl9y07g3jr8</guid>\r\n    </item>\r\n    <item>\r\n      <title>ATL (Atlanta) on 2025-12-10</title>\r\n      <description>![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>10/var>, var data-var='time'>0830/var> - var data-var='time'>1300/var> UTC/strong>small>Dec var data-var='date'> 3/var>, var data-var='time'>2246/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in ATL (Atlanta) datacenter on 2025-12-10 between 0830 and 1300 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  </description>\r\n      <pubDate>Wed, 10 Dec 2025 08:30:00 GMT</pubDate>\r\n      <link>https//www.cloudflarestatus.com/incidents/881xjrpxl4h7</link>\r\n      <guid>https://www.cloudflarestatus.com/incidents/881xjrpxl4h7</guid>\r\n    </item>\r\n    <item>\r\n      <title>QRO (Queretaro) on 2025-12-10</title>\r\n      <description>![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>10/var>, var data-var='time'>0800/var> - var data-var='time'>1200/var> UTC/strong>small>Dec var data-var='date'> 3/var>, var data-var='time'>2212/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in QRO (Queretaro) datacenter on 2025-12-10 between 0800 and 1200 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  </description>\r\n      <pubDate>Wed, 10 Dec 2025 08:00:00 GMT</pubDate>\r\n      <link>https//www.cloudflarestatus.com/incidents/vhhdg0jypmp6</link>\r\n      <guid>https://www.cloudflarestatus.com/incidents/vhhdg0jypmp6</guid>\r\n    </item>\r\n    <item>\r\n      <title>STL (St. Louis) on 2025-12-10</title>\r\n      <description>![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>10/var>, var data-var='time'>0800/var> - var data-var='time'>1200/var> UTC/strong>small>Dec var data-var='date'> 3/var>, var data-var='time'>2220/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in STL (St. Louis) datacenter on 2025-12-10 between 0800 and 1200 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  </description>\r\n      <pubDate>Wed, 10 Dec 2025 08:00:00 GMT</pubDate>\r\n      <link>https//www.cloudflarestatus.com/incidents/vjxjrwn7ckn7</link>\r\n      <guid>https://www.cloudflarestatus.com/incidents/vjxjrwn7ckn7</guid>\r\n    </item>\r\n    <item>\r\n      <title>MEM (Memphis) on 2025-12-10</title>\r\n      <description>![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>10/var>, var data-var='time'>0800/var> - var data-var='time'>1200/var> UTC/strong>small>Dec var data-var='date'> 3/var>, var data-var='time'>2224/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in MEM (Memphis) datacenter on 2025-12-10 between 0800 and 1200 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  </description>\r\n      <pubDate>Wed, 10 Dec 2025 08:00:00 GMT</pubDate>\r\n      <link>https//www.cloudflarestatus.com/incidents/cvr6jtmth2my</link>\r\n      <guid>https://www.cloudflarestatus.com/incidents/cvr6jtmth2my</guid>\r\n    </item>\r\n    <item>\r\n      <title>UIO (Quito) on 2025-12-10</title>\r\n      <description>![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>10/var>, var data-var='time'>0700/var> - var data-var='time'>1100/var> UTC/strong>small>Dec var data-var='date'> 4/var>, var data-var='time'>1058/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in UIO (Quito) datacenter on 2025-12-10 between 0700 and 1100 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  </description>\r\n      <pubDate>Wed, 10 Dec 2025 07:00:00 GMT</pubDate>\r\n      <link>https//www.cloudflarestatus.com/incidents/szsc5kf0jxzx</link>\r\n      <guid>https://www.cloudflarestatus.com/incidents/szsc5kf0jxzx</guid>\r\n    </item>\r\n    <item>\r\n      <title>DTW (Detroit) on 2025-12-10</title>\r\n      <description>![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>10/var>, var data-var='time'>0700/var> - var data-var='time'>1100/var> UTC/strong>small>Dec var data-var='date'> 3/var>, var data-var='time'>2206/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in DTW (Detroit) datacenter on 2025-12-10 between 0700 and 1100 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  </description>\r\n      <pubDate>Wed, 10 Dec 2025 07:00:00 GMT</pubDate>\r\n      <link>https//www.cloudflarestatus.com/incidents/22lp73hp9rhh</link>\r\n      <guid>https://www.cloudflarestatus.com/incidents/22lp73hp9rhh</guid>\r\n    </item>\r\n    <item>\r\n      <title>PIT (Pittsburgh) on 2025-12-10</title>\r\n      <description>![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>10/var>, var data-var='time'>0700/var> - var data-var='time'>1100/var> UTC/strong>small>Dec var data-var='date'> 3/var>, var data-var='time'>2210/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in PIT (Pittsburgh) datacenter on 2025-12-10 between 0700 and 1100 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  </description>\r\n      <pubDate>Wed, 10 Dec 2025 07:00:00 GMT</pubDate>\r\n      <link>https//www.cloudflarestatus.com/incidents/cdxn4ykf0qj9</link>\r\n      <guid>https://www.cloudflarestatus.com/incidents/cdxn4ykf0qj9</guid>\r\n    </item>\r\n    <item>\r\n      <title>YYZ (Toronto) on 2025-12-10</title>\r\n      <description>![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>10/var>, var data-var='time'>0700/var> - var data-var='time'>1100/var> UTC/strong>small>Dec var data-var='date'> 3/var>, var data-var='time'>1758/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in YYZ (Toronto) datacenter on 2025-12-10 between 0700 and 1100 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  </description>\r\n      <pubDate>Wed, 10 Dec 2025 07:00:00 GMT</pubDate>\r\n      <link>https//www.cloudflarestatus.com/incidents/k3pdp1s98ycc</link>\r\n      <guid>https://www.cloudflarestatus.com/incidents/k3pdp1s98ycc</guid>\r\n    </item>\r\n    <item>\r\n      <title>IAD (Ashburn) on 2025-12-10</title>\r\n      <description>![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>10/var>, var data-var='time'>0700/var> - var data-var='time'>1100/var> UTC/strong>small>Dec var data-var='date'> 2/var>, var data-var='time'>1804/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in IAD (Ashburn) datacenter on 2025-12-10 between 0700 and 1100 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  </description>\r\n      <pubDate>Wed, 10 Dec 2025 07:00:00 GMT</pubDate>\r\n      <link>https//www.cloudflarestatus.com/incidents/cvmrqcs2qxgx</link>\r\n      <guid>https://www.cloudflarestatus.com/incidents/cvmrqcs2qxgx</guid>\r\n    </item>\r\n    <item>\r\n      <title>GRU (São Paulo) on 2025-12-10</title>\r\n      <description>![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>10/var>, var data-var='time'>0500/var> - var data-var='time'>0900/var> UTC/strong>small>Dec var data-var='date'> 2/var>, var data-var='time'>1724/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in GRU (São Paulo) datacenter on 2025-12-10 between 0500 and 0900 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  </description>\r\n      <pubDate>Wed, 10 Dec 2025 05:00:00 GMT</pubDate>\r\n      <link>https//www.cloudflarestatus.com/incidents/pxqc2ddt7cj0</link>\r\n      <guid>https://www.cloudflarestatus.com/incidents/pxqc2ddt7cj0</guid>\r\n    </item>\r\n    <item>\r\n      <title>SIN (Singapore) on 2025-12-09</title>\r\n      <description>![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>9/var>, var data-var='time'>1600/var> UTC nbsp-nbsp Dec var data-var='date'>10/var>, var data-var='time'>0000/var> UTC/strong>small>Dec var data-var='date'> 4/var>, var data-var='time'>0344/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in SIN (Singapore) datacenter between 2025-12-09 1600 and 2025-12-10 0000 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  </description>\r\n      <pubDate>Tue, 09 Dec 2025 16:00:00 GMT</pubDate>\r\n      <link>https//www.cloudflarestatus.com/incidents/pmjjdkdvq8km</link>\r\n      <guid>https://www.cloudflarestatus.com/incidents/pmjjdkdvq8km</guid>\r\n    </item>\r\n    <item>\r\n      <title>AUS (Austin) on 2025-12-09</title>\r\n      <description>![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>9/var>, var data-var='time'>0800/var> - var data-var='time'>1200/var> UTC/strong>small>Dec var data-var='date'> 3/var>, var data-var='time'>2150/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in AUS (Austin) datacenter on 2025-12-09 between 0800 and 1200 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  </description>\r\n      <pubDate>Tue, 09 Dec 2025 08:00:00 GMT</pubDate>\r\n      <link>https//www.cloudflarestatus.com/incidents/yd2zrg547x43</link>\r\n      <guid>https://www.cloudflarestatus.com/incidents/yd2zrg547x43</guid>\r\n    </item>\r\n    <item>\r\n      <title>BNA (Nashville) on 2025-12-09</title>\r\n      <description>![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>9/var>, var data-var='time'>0800/var> - var data-var='time'>1200/var> UTC/strong>small>Dec var data-var='date'> 3/var>, var data-var='time'>1506/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in BNA (Nashville) datacenter on 2025-12-09 between 0800 and 1200 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  </description>\r\n      <pubDate>Tue, 09 Dec 2025 08:00:00 GMT</pubDate>\r\n      <link>https//www.cloudflarestatus.com/incidents/sjxbt42t9k69</link>\r\n      <guid>https://www.cloudflarestatus.com/incidents/sjxbt42t9k69</guid>\r\n    </item>\r\n    <item>\r\n      <title>DFW (Dallas) on 2025-12-09</title>\r\n      <description>![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>9/var>, var data-var='time'>0800/var> - var data-var='time'>1200/var> UTC/strong>small>Dec var data-var='date'> 2/var>, var data-var='time'>1412/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in DFW (Dallas) datacenter on 2025-12-09 between 0800 and 1200 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  </description>\r\n      <pubDate>Tue, 09 Dec 2025 08:00:00 GMT</pubDate>\r\n      <link>https//www.cloudflarestatus.com/incidents/yj9pnxw5ttx2</link>\r\n      <guid>https://www.cloudflarestatus.com/incidents/yj9pnxw5ttx2</guid>\r\n    </item>\r\n    <item>\r\n      <title>BUF (Buffalo) on 2025-12-09</title>\r\n      <description>![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>9/var>, var data-var='time'>0700/var> - var data-var='time'>1100/var> UTC/strong>small>Dec var data-var='date'> 3/var>, var data-var='time'>2156/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in BUF (Buffalo) datacenter on 2025-12-09 between 0700 and 1100 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  </description>\r\n      <pubDate>Tue, 09 Dec 2025 07:00:00 GMT</pubDate>\r\n      <link>https//www.cloudflarestatus.com/incidents/kbjmzdg16ffq</link>\r\n      <guid>https://www.cloudflarestatus.com/incidents/kbjmzdg16ffq</guid>\r\n    </item>\r\n    <item>\r\n      <title>IAD (Ashburn) on 2025-12-09</title>\r\n      <description>![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>9/var>, var data-var='time'>0700/var> - var data-var='time'>1100/var> UTC/strong>small>Dec var data-var='date'> 3/var>, var data-var='time'>1813/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in IAD (Ashburn) datacenter on 2025-12-09 between 0700 and 1100 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  </description>\r\n      <pubDate>Tue, 09 Dec 2025 07:00:00 GMT</pubDate>\r\n      <link>https//www.cloudflarestatus.com/incidents/8bqvf7gky4st</link>\r\n      <guid>https://www.cloudflarestatus.com/incidents/8bqvf7gky4st</guid>\r\n    </item>\r\n    <item>\r\n      <title>YYZ (Toronto) on 2025-12-09</title>\r\n      <description>![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>9/var>, var data-var='time'>0700/var> - var data-var='time'>1100/var> UTC/strong>small>Dec var data-var='date'> 3/var>, var data-var='time'>1754/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in YYZ (Toronto) datacenter on 2025-12-09 between 0700 and 1100 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  </description>\r\n      <pubDate>Tue, 09 Dec 2025 07:00:00 GMT</pubDate>\r\n      <link>https//www.cloudflarestatus.com/incidents/t05tmjs0d5mn</link>\r\n      <guid>https://www.cloudflarestatus.com/incidents/t05tmjs0d5mn</guid>\r\n    </item>\r\n    <item>\r\n      <title>CMH (Columbus) on 2025-12-09</title>\r\n      <description>![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>9/var>, var data-var='time'>0700/var> - var data-var='time'>1100/var> UTC/strong>small>Dec var data-var='date'> 3/var>, var data-var='time'>1440/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in CMH (Columbus) datacenter on 2025-12-09 between 0700 and 1100 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  </description>\r\n      <pubDate>Tue, 09 Dec 2025 07:00:00 GMT</pubDate>\r\n      <link>https//www.cloudflarestatus.com/incidents/x5q2dk93y2b6</link>\r\n      <guid>https://www.cloudflarestatus.com/incidents/x5q2dk93y2b6</guid>\r\n    </item>\r\n    <item>\r\n      <title>IAD (Ashburn) on 2025-12-09</title>\r\n      <description>![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>9/var>, var data-var='time'>0700/var> - var data-var='time'>1100/var> UTC/strong>small>Dec var data-var='date'> 2/var>, var data-var='time'>1744/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in IAD (Ashburn) datacenter on 2025-12-09 between 0700 and 1100 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  </description>\r\n      <pubDate>Tue, 09 Dec 2025 07:00:00 GMT</pubDate>\r\n      <link>https//www.cloudflarestatus.com/incidents/hlyvxz2wg6rf</link>\r\n      <guid>https://www.cloudflarestatus.com/incidents/hlyvxz2wg6rf</guid>\r\n    </item>\r\n    <item>\r\n      <title>GRU (São Paulo) on 2025-12-09</title>\r\n      <description>![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>9/var>, var data-var='time'>0500/var> - var data-var='time'>0900/var> UTC/strong>small>Dec var data-var='date'> 2/var>, var data-var='time'>1722/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in GRU (São Paulo) datacenter on 2025-12-09 between 0500 and 0900 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  </description>\r\n      <pubDate>Tue, 09 Dec 2025 05:00:00 GMT</pubDate>\r\n      <link>https//www.cloudflarestatus.com/incidents/2q1qzj2vzbvq</link>\r\n      <guid>https://www.cloudflarestatus.com/incidents/2q1qzj2vzbvq</guid>\r\n    </item>\r\n    <item>\r\n      <title>BNA (Nashville) on 2025-12-08</title>\r\n      <description>![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>8/var>, var data-var='time'>0800/var> - var data-var='time'>1200/var> UTC/strong>small>Dec var data-var='date'> 3/var>, var data-var='time'>1402/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in BNA (Nashville) datacenter on 2025-12-08 between 0800 and 1200 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  </description>\r\n      <pubDate>Mon, 08 Dec 2025 08:00:00 GMT</pubDate>\r\n      <link>https//www.cloudflarestatus.com/incidents/yffdhw5f27tz</link>\r\n      <guid>https://www.cloudflarestatus.com/incidents/yffdhw5f27tz</guid>\r\n    </item>\r\n    <item>\r\n      <title>BOS (Boston) on 2025-12-08</title>\r\n      <description>![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>8/var>, var data-var='time'>0700/var> - var data-var='time'>1100/var> UTC/strong>small>Dec var data-var='date'> 3/var>, var data-var='time'>1746/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in BOS (Boston) datacenter on 2025-12-08 between 0700 and 1100 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  </description>\r\n      <pubDate>Mon, 08 Dec 2025 07:00:00 GMT</pubDate>\r\n      <link>https//www.cloudflarestatus.com/incidents/h433hnnlrc9b</link>\r\n      <guid>https://www.cloudflarestatus.com/incidents/h433hnnlrc9b</guid>\r\n    </item>\r\n    <item>\r\n      <title>CMH (Columbus) on 2025-12-08</title>\r\n      <description>![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>8/var>, var data-var='time'>0700/var> - var data-var='time'>1100/var> UTC/strong>small>Dec var data-var='date'> 3/var>, var data-var='time'>1440/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in CMH (Columbus) datacenter on 2025-12-08 between 0700 and 1100 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  </description>\r\n      <pubDate>Mon, 08 Dec 2025 07:00:00 GMT</pubDate>\r\n      <link>https//www.cloudflarestatus.com/incidents/02q2016k78dm</link>\r\n      <guid>https://www.cloudflarestatus.com/incidents/02q2016k78dm</guid>\r\n    </item>\r\n    <item>\r\n      <title>EZE (Buenos Aires) on 2025-12-08</title>\r\n      <description>![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>8/var>, var data-var='time'>0500/var> - var data-var='time'>0900/var> UTC/strong>small>Dec var data-var='date'> 3/var>, var data-var='time'>1550/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in EZE (Buenos Aires) datacenter on 2025-12-08 between 0500 and 0900 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  </description>\r\n      <pubDate>Mon, 08 Dec 2025 05:00:00 GMT</pubDate>\r\n      <link>https//www.cloudflarestatus.com/incidents/pmwgdqt72nsy</link>\r\n      <guid>https://www.cloudflarestatus.com/incidents/pmwgdqt72nsy</guid>\r\n    </item>\r\n    <item>\r\n      <title>GIG (Rio de Janeiro) on 2025-12-08</title>\r\n      <description>![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>8/var>, var data-var='time'>0500/var> - var data-var='time'>0900/var> UTC/strong>small>Dec var data-var='date'> 2/var>, var data-var='time'>1730/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in GIG (Rio de Janeiro) datacenter on 2025-12-08 between 0500 and 0900 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  </description>\r\n      <pubDate>Mon, 08 Dec 2025 05:00:00 GMT</pubDate>\r\n      <link>https//www.cloudflarestatus.com/incidents/rzvlxk0s444w</link>\r\n      <guid>https://www.cloudflarestatus.com/incidents/rzvlxk0s444w</guid>\r\n    </item>\r\n    <item>\r\n      <title>GRU (São Paulo) on 2025-12-08</title>\r\n      <description>![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>8/var>, var data-var='time'>0500/var> - var data-var='time'>0900/var> UTC/strong>small>Dec var data-var='date'> 2/var>, var data-var='time'>1720/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in GRU (São Paulo) datacenter on 2025-12-08 between 0500 and 0900 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  </description>\r\n      <pubDate>Mon, 08 Dec 2025 05:00:00 GMT</pubDate>\r\n      <link>https//www.cloudflarestatus.com/incidents/fkq60k2lpd07</link>\r\n      <guid>https://www.cloudflarestatus.com/incidents/fkq60k2lpd07</guid>\r\n    </item>\r\n    <item>\r\n      <title>YXE (Saskatoon) on 2025-12-05</title>\r\n      <description>![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>5/var>, var data-var='time'>0830/var> - var data-var='time'>1300/var> UTC/strong>small>Dec var data-var='date'> 3/var>, var data-var='time'>1734/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in YXE (Saskatoon) datacenter on 2025-12-05 between 0830 and 1300 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  </description>\r\n      <pubDate>Fri, 05 Dec 2025 08:30:00 GMT</pubDate>\r\n      <link>https//www.cloudflarestatus.com/incidents/4k7d9jqltg8r</link>\r\n      <guid>https://www.cloudflarestatus.com/incidents/4k7d9jqltg8r</guid>\r\n    </item>\r\n    <item>\r\n      <title>YYC (Calgary) on 2025-12-05</title>\r\n      <description>![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>5/var>, var data-var='time'>0830/var> - var data-var='time'>1300/var> UTC/strong>small>Dec var data-var='date'> 3/var>, var data-var='time'>1734/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in YYC (Calgary) datacenter on 2025-12-05 between 0830 and 1300 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  </description>\r\n      <pubDate>Fri, 05 Dec 2025 08:30:00 GMT</pubDate>\r\n      <link>https//www.cloudflarestatus.com/incidents/zkj16p0jwywq</link>\r\n      <guid>https://www.cloudflarestatus.com/incidents/zkj16p0jwywq</guid>\r\n    </item>\r\n    <item>\r\n      <title>MSP (Minneapolis) on 2025-12-05</title>\r\n      <description>![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>5/var>, var data-var='time'>0800/var> - var data-var='time'>1200/var> UTC/strong>small>Dec var data-var='date'> 2/var>, var data-var='time'>1810/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in MSP (Minneapolis) datacenter on 2025-12-05 between 0800 and 1200 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  </description>\r\n      <pubDate>Fri, 05 Dec 2025 08:00:00 GMT</pubDate>\r\n      <link>https//www.cloudflarestatus.com/incidents/qw15318cwbzw</link>\r\n      <guid>https://www.cloudflarestatus.com/incidents/qw15318cwbzw</guid>\r\n    </item>\r\n    <item>\r\n      <title>DFW (Dallas) on 2025-12-05</title>\r\n      <description>![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>5/var>, var data-var='time'>0800/var> - var data-var='time'>1200/var> UTC/strong>small>Dec var data-var='date'> 2/var>, var data-var='time'>1404/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in DFW (Dallas) datacenter on 2025-12-05 between 0800 and 1200 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  </description>\r\n      <pubDate>Fri, 05 Dec 2025 08:00:00 GMT</pubDate>\r\n      <link>https//www.cloudflarestatus.com/incidents/ts7206lt343k</link>\r\n      <guid>https://www.cloudflarestatus.com/incidents/ts7206lt343k</guid>\r\n    </item>\r\n    <item>\r\n      <title>JAX (Jacksonville) on 2025-12-05</title>\r\n      <description>![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>5/var>, var data-var='time'>0700/var> - var data-var='time'>1100/var> UTC/strong>small>Dec var data-var='date'> 3/var>, var data-var='time'>1208/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in JAX (Jacksonville) datacenter on 2025-12-05 between 0700 and 1100 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  </description>\r\n      <pubDate>Fri, 05 Dec 2025 07:00:00 GMT</pubDate>\r\n      <link>https//www.cloudflarestatus.com/incidents/8wy4pkzrj6xn</link>\r\n      <guid>https://www.cloudflarestatus.com/incidents/8wy4pkzrj6xn</guid>\r\n    </item>\r\n    <item>\r\n      <title>UIO (Quito) on 2025-12-05</title>\r\n      <description>![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>5/var>, var data-var='time'>0700/var> - var data-var='time'>1100/var> UTC/strong>small>Dec var data-var='date'> 2/var>, var data-var='time'>1700/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in UIO (Quito) datacenter on 2025-12-05 between 0700 and 1100 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  </description>\r\n      <pubDate>Fri, 05 Dec 2025 07:00:00 GMT</pubDate>\r\n      <link>https//www.cloudflarestatus.com/incidents/xlztcrqy1b2j</link>\r\n      <guid>https://www.cloudflarestatus.com/incidents/xlztcrqy1b2j</guid>\r\n    </item>\r\n    <item>\r\n      <title>IAD (Ashburn) on 2025-12-05</title>\r\n      <description>![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>5/var>, var data-var='time'>0700/var> - var data-var='time'>1100/var> UTC/strong>small>Dec var data-var='date'> 2/var>, var data-var='time'>1410/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in IAD (Ashburn) datacenter on 2025-12-05 between 0700 and 1100 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  </description>\r\n      <pubDate>Fri, 05 Dec 2025 07:00:00 GMT</pubDate>\r\n      <link>https//www.cloudflarestatus.com/incidents/8qpg1y5nbbf1</link>\r\n      <guid>https://www.cloudflarestatus.com/incidents/8qpg1y5nbbf1</guid>\r\n    </item>\r\n    <item>\r\n      <title>SCL (Santiago) on 2025-12-05</title>\r\n      <description>![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>5/var>, var data-var='time'>0500/var> - var data-var='time'>0900/var> UTC/strong>small>Dec var data-var='date'> 2/var>, var data-var='time'>1756/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in SCL (Santiago) datacenter on 2025-12-05 between 0500 and 0900 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  </description>\r\n      <pubDate>Fri, 05 Dec 2025 05:00:00 GMT</pubDate>\r\n      <link>https//www.cloudflarestatus.com/incidents/0k5dcg7kdg07</link>\r\n      <guid>https://www.cloudflarestatus.com/incidents/0k5dcg7kdg07</guid>\r\n    </item>\r\n    <item>\r\n      <title>GIG (Rio de Janeiro) on 2025-12-05</title>\r\n      <description>![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>5/var>, var data-var='time'>0500/var> - var data-var='time'>0900/var> UTC/strong>small>Dec var data-var='date'> 2/var>, var data-var='time'>1710/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in GIG (Rio de Janeiro) datacenter on 2025-12-05 between 0500 and 0900 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  </description>\r\n      <pubDate>Fri, 05 Dec 2025 05:00:00 GMT</pubDate>\r\n      <link>https//www.cloudflarestatus.com/incidents/f8tkstgsq3n6</link>\r\n      <guid>https://www.cloudflarestatus.com/incidents/f8tkstgsq3n6</guid>\r\n    </item>\r\n    <item>\r\n      <title>GRU (São Paulo) on 2025-12-05</title>\r\n      <description>![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>5/var>, var data-var='time'>0500/var> - var data-var='time'>0900/var> UTC/strong>small>Dec var data-var='date'> 2/var>, var data-var='time'>1716/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in GRU (São Paulo) datacenter on 2025-12-05 between 0500 and 0900 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  </description>\r\n      <pubDate>Fri, 05 Dec 2025 05:00:00 GMT</pubDate>\r\n      <link>https//www.cloudflarestatus.com/incidents/96qy7jzz51nk</link>\r\n      <guid>https://www.cloudflarestatus.com/incidents/96qy7jzz51nk</guid>\r\n    </item>\r\n    <item>\r\n      <title>NAG (Nagpur) on 2025-12-04</title>\r\n      <description>![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>4/var>, var data-var='time'>2100/var> UTC nbsp-nbsp Dec var data-var='date'>5/var>, var data-var='time'>0100/var> UTC/strong>small>Dec var data-var='date'> 2/var>, var data-var='time'>1640/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in NAG (Nagpur) datacenter between 2025-12-04 2100 and 2025-12-05 0100 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  </description>\r\n      <pubDate>Thu, 04 Dec 2025 21:00:00 GMT</pubDate>\r\n      <link>https//www.cloudflarestatus.com/incidents/cr6bpm37311z</link>\r\n      <guid>https://www.cloudflarestatus.com/incidents/cr6bpm37311z</guid>\r\n    </item>\r\n    <item>\r\n      <title>PAT (Patna) on 2025-12-04</title>\r\n      <description>![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>4/var>, var data-var='time'>2100/var> UTC nbsp-nbsp Dec var data-var='date'>5/var>, var data-var='time'>0100/var> UTC/strong>small>Dec var data-var='date'> 2/var>, var data-var='time'>1646/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in PAT (Patna) datacenter between 2025-12-04 2100 and 2025-12-05 0100 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  </description>\r\n      <pubDate>Thu, 04 Dec 2025 21:00:00 GMT</pubDate>\r\n      <link>https//www.cloudflarestatus.com/incidents/kppjgs13n7h5</link>\r\n      <guid>https://www.cloudflarestatus.com/incidents/kppjgs13n7h5</guid>\r\n    </item>\r\n    <item>\r\n      <title>CVE-2025-14024 Rejected reason ** REJECT ** DO NOT USE THIS CANDIDATE NUMBER. Reason This candidate was issued in...</title>\r\n      <description>![CDATA[Rejected reason ** REJECT ** DO NOT USE THIS CANDIDATE NUMBER. Reason This candidate was issued in error. Notes All references and descriptions in this candidate have been removed to prevent accidental usage. | Severity UNKNOWN  ]]>  </description>\r\n      <pubDate>Thu, 04 Dec 2025 16:16:00 GMT</pubDate>\r\n      <link>https//nvd.nist.gov/vuln/detail/CVE-2025-14024</link>\r\n      <guid>CVE-2025-14024</guid>\r\n    </item>\r\n    <item>\r\n      <title>CVE-2025-40222 In the Linux kernel, the following vulnerability has been resolved\r\n\r\ntty serial sh-sci fix RSCI F...</title>\r\n      <description>![CDATA[In the Linux kernel, the following vulnerability has been resolved\r\n\r\ntty serial sh-sci fix RSCI FIFO overrun handling\r\n\r\nThe receive error handling code is shared between RSCI and all other\r\nSCIF port types, but the RSCI overrun_reg is specified as a memory\r\noffset, while for other SCIF types it is an enum value used to index\r\ninto the sci_port_params->regs array, as mentioned above the\r\nsci_serial_in() function.\r\n\r\nFor RSCI, the overrun_reg is CSR (0x48), causing the sci_getreg() call\r\ninside the sci_handle_fifo_overrun() function to index outside the\r\nbounds of the regs array, which currently has a size of 20, as specified\r\nby SCI_NR_REGS.\r\n\r\nBecause of this, we end up accessing memory outside of RSCI's\r\nrsci_port_params structure, which, when interpreted as a plat_sci_reg,\r\nhappens to have a non-zero size, causing the following WARN when\r\nsci_serial_in() is called, as the accidental size does not match the\r\nsupported register sizes.\r\n\r\nThe existence of the overrun_reg needs to be checked because\r\nSCIx_SH3_SCIF_REGTYPE has overrun_reg set to SCLSR, but SCLSR is not\r\npresent in the regs array.\r\n\r\nAvoid calling sci_getreg() for port types which don't use standard\r\nregister handling.\r\n\r\nUse the ops->read_reg() and ops->write_reg() functions to properly read\r\nand write registers for RSCI, and change the type of the status variable\r\nto accommodate the 32-bit CSR register.\r\n\r\nsci_getreg() and sci_serial_in() are also called with overrun_reg in the\r\nsci_mpxed_interrupt() interrupt handler, but that code path is not used\r\nfor RSCI, as it does not have a muxed interrupt.\r\n\r\n------------[ cut here ]------------\r\nInvalid register access\r\nWARNING CPU 0 PID 0 at drivers/tty/serial/sh-sci.c522 sci_serial_in+0x38/0xac\r\nModules linked in renesas_usbhs at24 rzt2h_adc industrialio_adc sha256 cfg80211 bluetooth ecdh_generic ecc rfkill fuse drm backlight ipv6\r\nCPU 0 UID 0 PID 0 Comm swapper/0 Not tainted 6.17.0-rc1+ #30 PREEMPT\r\nHardware name Renesas RZ/T2H EVK Board based on r9a09g077m44 (DT)\r\npstate 604000c5 (nZCv daIF +PAN -UAO -TCO -DIT -SSBS BTYPE=--)\r\npc  sci_serial_in+0x38/0xac\r\nlr  sci_serial_in+0x38/0xac\r\nsp  ffff800080003e80\r\nx29 ffff800080003e80 x28 ffff800082195b80 x27 000000000000000d\r\nx26 ffff8000821956d0 x25 0000000000000000 x24 ffff800082195b80\r\nx23 ffff000180e0d800 x22 0000000000000010 x21 0000000000000000\r\nx20 0000000000000010 x19 ffff000180e72000 x18 000000000000000a\r\nx17 ffff8002bcee7000 x16 ffff800080000000 x15 0720072007200720\r\nx14 0720072007200720 x13 0720072007200720 x12 0720072007200720\r\nx11 0000000000000058 x10 0000000000000018 x9  ffff8000821a6a48\r\nx8  0000000000057fa8 x7  0000000000000406 x6  ffff8000821fea48\r\nx5  ffff00033ef88408 x4  ffff8002bcee7000 x3  ffff800082195b80\r\nx2  0000000000000000 x1  0000000000000000 x0  ffff800082195b80\r\nCall trace\r\n sci_serial_in+0x38/0xac (P)\r\n sci_handle_fifo_overrun.isra.0+0x70/0x134\r\n sci_er_interrupt+0x50/0x39c\r\n __handle_irq_event_percpu+0x48/0x140\r\n handle_irq_event+0x44/0xb0\r\n handle_fasteoi_irq+0xf4/0x1a0\r\n handle_irq_desc+0x34/0x58\r\n generic_handle_domain_irq+0x1c/0x28\r\n gic_handle_irq+0x4c/0x140\r\n call_on_irq_stack+0x30/0x48\r\n do_interrupt_handler+0x80/0x84\r\n el1_interrupt+0x34/0x68\r\n el1h_64_irq_handler+0x18/0x24\r\n el1h_64_irq+0x6c/0x70\r\n default_idle_call+0x28/0x58 (P)\r\n do_idle+0x1f8/0x250\r\n cpu_startup_entry+0x34/0x3c\r\n rest_init+0xd8/0xe0\r\n console_on_rootfs+0x0/0x6c\r\n __primary_switched+0x88/0x90\r\n---[ end trace 0000000000000000 ]--- | Severity UNKNOWN  ]]></description>\r\n      <pubDate>Thu, 04 Dec 2025 16:16:00 GMT</pubDate>\r\n      <link>https//nvd.nist.gov/vuln/detail/CVE-2025-40222</link>\r\n      <guid>CVE-2025-40222</guid>\r\n    </item>\r\n    <item>\r\n      <title>CVE-2025-40223 In the Linux kernel, the following vulnerability has been resolved\r\n\r\nmost usb Fix use-after-free i...</title>\r\n      <description>![CDATA[In the Linux kernel, the following vulnerability has been resolved\r\n\r\nmost usb Fix use-after-free in hdm_disconnect\r\n\r\nhdm_disconnect() calls most_deregister_interface(), which eventually\r\nunregisters the MOST interface device with device_unregister(iface->dev).\r\nIf that drops the last reference, the device core may call release_mdev()\r\nimmediately while hdm_disconnect() is still executing.\r\n\r\nThe old code also freed several mdev-owned allocations in\r\nhdm_disconnect() and then performed additional put_device() calls.\r\nDepending on refcount order, this could lead to use-after-free or\r\ndouble-free when release_mdev() ran (or when unregister paths also\r\nperformed puts).\r\n\r\nFix by moving the frees of mdev-owned allocations into release_mdev(),\r\nso they happen exactly once when the device is truly released, and by\r\ndropping the extra put_device() calls in hdm_disconnect() that are\r\nredundant after device_unregister() and most_deregister_interface().\r\n\r\nThis addresses the KASAN slab-use-after-free reported by syzbot in\r\nhdm_disconnect(). See report and stack traces in the bug link below. | Severity UNKNOWN  ]]></description>\r\n      <pubDate>Thu, 04 Dec 2025 16:16:00 GMT</pubDate>\r\n      <link>https//nvd.nist.gov/vuln/detail/CVE-2025-40223</link>\r\n      <guid>CVE-2025-40223</guid>\r\n    </item>\r\n    <item>\r\n      <title>CVE-2025-40224 In the Linux kernel, the following vulnerability has been resolved\r\n\r\nhwmon (cgbc-hwmon) Add missing...</title>\r\n      <description>![CDATA[In the Linux kernel, the following vulnerability has been resolved\r\n\r\nhwmon (cgbc-hwmon) Add missing NULL check after devm_kzalloc()\r\n\r\nThe driver allocates memory for sensor data using devm_kzalloc(), but\r\ndid not check if the allocation succeeded. In case of memory allocation\r\nfailure, dereferencing the NULL pointer would lead to a kernel crash.\r\n\r\nAdd a NULL pointer check and return -ENOMEM to handle allocation failure\r\nproperly. | Severity UNKNOWN  ]]></description>\r\n      <pubDate>Thu, 04 Dec 2025 16:16:00 GMT</pubDate>\r\n      <link>https//nvd.nist.gov/vuln/detail/CVE-2025-40224</link>\r\n      <guid>CVE-2025-40224</guid>\r\n    </item>\r\n    <item>\r\n      <title>CVE-2025-40225 In the Linux kernel, the following vulnerability has been resolved\r\n\r\ndrm/panthor Fix kernel panic o...</title>\r\n      <description>![CDATA[In the Linux kernel, the following vulnerability has been resolved\r\n\r\ndrm/panthor Fix kernel panic on partial unmap of a GPU VA region\r\n\r\nThis commit address a kernel panic issue that can happen if Userspace\r\ntries to partially unmap a GPU virtual region (aka drm_gpuva).\r\nThe VM_BIND interface allows partial unmapping of a BO.\r\n\r\nPanthor driver pre-allocates memory for the new drm_gpuva structures\r\nthat would be needed for the map/unmap operation, done using drm_gpuvm\r\nlayer. It expected that only one new drm_gpuva would be needed on umap\r\nbut a partial unmap can require 2 new drm_gpuva and that's why it\r\nended up doing a NULL pointer dereference causing a kernel panic.\r\n\r\nFollowing dump was seen when partial unmap was exercised.\r\n Unable to handle kernel NULL pointer dereference at virtual address 0000000000000078\r\n Mem abort info\r\n   ESR = 0x0000000096000046\r\n   EC = 0x25 DABT (current EL), IL = 32 bits\r\n   SET = 0, FnV = 0\r\n   EA = 0, S1PTW = 0\r\n   FSC = 0x06 level 2 translation fault\r\n Data abort info\r\n   ISV = 0, ISS = 0x00000046, ISS2 = 0x00000000\r\n   CM = 0, WnR = 1, TnD = 0, TagAccess = 0\r\n   GCS = 0, Overlay = 0, DirtyBit = 0, Xs = 0\r\n user pgtable 4k pages, 48-bit VAs, pgdp=000000088a863000\r\n [000000000000078] pgd=080000088a842003, p4d=080000088a842003, pud=0800000884bf5003, pmd=0000000000000000\r\n Internal error Oops 0000000096000046 [#1] PREEMPT SMP\r\n snip>\r\n pstate 60000005 (nZCv daif -PAN -UAO -TCO -DIT -SSBS BTYPE=--)\r\n pc  panthor_gpuva_sm_step_remap+0xe4/0x330 [panthor]\r\n lr  panthor_gpuva_sm_step_remap+0x6c/0x330 [panthor]\r\n sp  ffff800085d43970\r\n x29 ffff800085d43970 x28 ffff00080363e440 x27 ffff0008090c6000\r\n x26 0000000000000030 x25 ffff800085d439f8 x24 ffff00080d402000\r\n x23 ffff800085d43b60 x22 ffff800085d439e0 x21 ffff00080abdb180\r\n x20 0000000000000000 x19 0000000000000000 x18 0000000000000010\r\n x17 6e656c202c303030 x16 3666666666646466 x15 393d61766f69202c\r\n x14 312d3d7361203a70 x13 303030323d6e656c x12 ffff80008324bf58\r\n x11 0000000000000003 x10 0000000000000002 x9  ffff8000801a6a9c\r\n x8  ffff00080360b300 x7  0000000000000000 x6  000000088aa35fc7\r\n x5  fff1000080000000 x4  ffff8000842ddd30 x3  0000000000000001\r\n x2  0000000100000000 x1  0000000000000001 x0  0000000000000078\r\n Call trace\r\n  panthor_gpuva_sm_step_remap+0xe4/0x330 [panthor]\r\n  op_remap_cb.isra.22+0x50/0x80\r\n  __drm_gpuvm_sm_unmap+0x10c/0x1c8\r\n  drm_gpuvm_sm_unmap+0x40/0x60\r\n  panthor_vm_exec_op+0xb4/0x3d0 [panthor]\r\n  panthor_vm_bind_exec_sync_op+0x154/0x278 [panthor]\r\n  panthor_ioctl_vm_bind+0x160/0x4a0 [panthor]\r\n  drm_ioctl_kernel+0xbc/0x138\r\n  drm_ioctl+0x240/0x500\r\n  __arm64_sys_ioctl+0xb0/0xf8\r\n  invoke_syscall+0x4c/0x110\r\n  el0_svc_common.constprop.1+0x98/0xf8\r\n  do_el0_svc+0x24/0x38\r\n  el0_svc+0x40/0xf8\r\n  el0t_64_sync_handler+0xa0/0xc8\r\n  el0t_64_sync+0x174/0x178 | Severity UNKNOWN  ]]></description>\r\n      <pubDate>Thu, 04 Dec 2025 16:16:00 GMT</pubDate>\r\n      <link>https//nvd.nist.gov/vuln/detail/CVE-2025-40225</link>\r\n      <guid>CVE-2025-40225</guid>\r\n    </item>\r\n    <item>\r\n      <title>CVE-2025-40226 In the Linux kernel, the following vulnerability has been resolved\r\n\r\nfirmware arm_scmi Account for...</title>\r\n      <description>![CDATA[In the Linux kernel, the following vulnerability has been resolved\r\n\r\nfirmware arm_scmi Account for failed debug initialization\r\n\r\nWhen the SCMI debug subsystem fails to initialize, the related debug root\r\nwill be missing, and the underlying descriptor will be NULL.\r\n\r\nHandle this fault condition in the SCMI debug helpers that maintain\r\nmetrics counters. | Severity UNKNOWN  ]]></description>\r\n      <pubDate>Thu, 04 Dec 2025 16:16:00 GMT</pubDate>\r\n      <link>https//nvd.nist.gov/vuln/detail/CVE-2025-40226</link>\r\n      <guid>CVE-2025-40226</guid>\r\n    </item>\r\n    <item>\r\n      <title>CVE-2025-40227 In the Linux kernel, the following vulnerability has been resolved\r\n\r\nmm/damon/sysfs dealloc commit ...</title>\r\n      <description>![CDATA[In the Linux kernel, the following vulnerability has been resolved\r\n\r\nmm/damon/sysfs dealloc commit test ctx always\r\n\r\nThe damon_ctx for testing online DAMON parameters commit inputs is\r\ndeallocated only when the test fails.  This means memory is leaked for\r\nevery successful online DAMON parameters commit.  Fix the leak by always\r\ndeallocating it. | Severity UNKNOWN  ]]></description>\r\n      <pubDate>Thu, 04 Dec 2025 16:16:00 GMT</pubDate>\r\n      <link>https//nvd.nist.gov/vuln/detail/CVE-2025-40227</link>\r\n      <guid>CVE-2025-40227</guid>\r\n    </item>\r\n    <item>\r\n      <title>CVE-2025-40228 In the Linux kernel, the following vulnerability has been resolved\r\n\r\nmm/damon/sysfs catch commit te...</title>\r\n      <description>![CDATA[In the Linux kernel, the following vulnerability has been resolved\r\n\r\nmm/damon/sysfs catch commit test ctx alloc failure\r\n\r\nPatch series \"mm/damon/sysfs fix commit test damon_ctx [de]allocation\".\r\n\r\nDAMON sysfs interface dynamically allocates and uses a damon_ctx object\r\nfor testing if given inputs for online DAMON parameters update is valid.\r\nThe object is being used without an allocation failure check, and leaked\r\nwhen the test succeeds.  Fix the two bugs.\r\n\r\n\r\nThis patch (of 2)\r\n\r\nThe damon_ctx for testing online DAMON parameters commit inputs is used\r\nwithout its allocation failure check.  This could result in an invalid\r\nmemory access.  Fix it by directly returning an error when the allocation\r\nfailed. | Severity UNKNOWN  ]]></description>\r\n      <pubDate>Thu, 04 Dec 2025 16:16:00 GMT</pubDate>\r\n      <link>https//nvd.nist.gov/vuln/detail/CVE-2025-40228</link>\r\n      <guid>CVE-2025-40228</guid>\r\n    </item>\r\n    <item>\r\n      <title>CVE-2025-40229 In the Linux kernel, the following vulnerability has been resolved\r\n\r\nmm/damon/core fix potential me...</title>\r\n      <description>![CDATA[In the Linux kernel, the following vulnerability has been resolved\r\n\r\nmm/damon/core fix potential memory leak by cleaning ops_filter in damon_destroy_scheme\r\n\r\nCurrently, damon_destroy_scheme() only cleans up the filter list but\r\nleaves ops_filter untouched, which could lead to memory leaks when a\r\nscheme is destroyed.\r\n\r\nThis patch ensures both filter and ops_filter are properly freed in\r\ndamon_destroy_scheme(), preventing potential memory leaks. | Severity UNKNOWN  ]]></description>\r\n      <pubDate>Thu, 04 Dec 2025 16:16:00 GMT</pubDate>\r\n      <link>https//nvd.nist.gov/vuln/detail/CVE-2025-40229</link>\r\n      <guid>CVE-2025-40229</guid>\r\n    </item>\r\n    <item>\r\n      <title>CVE-2025-40230 In the Linux kernel, the following vulnerability has been resolved\r\n\r\nmm prevent poison consumption ...</title>\r\n      <description>![CDATA[In the Linux kernel, the following vulnerability has been resolved\r\n\r\nmm prevent poison consumption when splitting THP\r\n\r\nWhen performing memory error injection on a THP (Transparent Huge Page)\r\nmapped to userspace on an x86 server, the kernel panics with the following\r\ntrace.  The expected behavior is to terminate the affected process instead\r\nof panicking the kernel, as the x86 Machine Check code can recover from an\r\nin-userspace #MC.\r\n\r\n  mce [Hardware Error] CPU 0 Machine Check Exception f Bank 3 bd80000000070134\r\n  mce [Hardware Error] RIP 10ffffffff8372f8bc> {memchr_inv+0x4c/0xf0}\r\n  mce [Hardware Error] TSC afff7bbff88a ADDR 1d301b000 MISC 80 PPIN 1e741e77539027db\r\n  mce [Hardware Error] PROCESSOR 0d06d0 TIME 1758093249 SOCKET 0 APIC 0 microcode 80000320\r\n  mce [Hardware Error] Run the above through 'mcelog --ascii'\r\n  mce [Hardware Error] Machine check Data load in unrecoverable area of kernel\r\n  Kernel panic - not syncing Fatal local machine check\r\n\r\nThe root cause of this panic is that handling a memory failure triggered\r\nby an in-userspace #MC necessitates splitting the THP.  The splitting\r\nprocess employs a mechanism, implemented in\r\ntry_to_map_unused_to_zeropage(), which reads the pages in the THP to\r\nidentify zero-filled pages.  However, reading the pages in the THP results\r\nin a second in-kernel #MC, occurring before the initial memory_failure()\r\ncompletes, ultimately leading to a kernel panic.  See the kernel panic\r\ncall trace on the two #MCs.\r\n\r\n  First Machine Check occurs // [1]\r\n    memory_failure()         // [2]\r\n      try_to_split_thp_page()\r\n        split_huge_page()\r\n          split_huge_page_to_list_to_order()\r\n            __folio_split()  // [3]\r\n              remap_page()\r\n                remove_migration_ptes()\r\n                  remove_migration_pte()\r\n                    try_to_map_unused_to_zeropage()  // [4]\r\n                      memchr_inv()                   // [5]\r\n                        Second Machine Check occurs  // [6]\r\n                          Kernel panic\r\n\r\n[1] Triggered by accessing a hardware-poisoned THP in userspace, which is\r\n    typically recoverable by terminating the affected process.\r\n\r\n[2] Call folio_set_has_hwpoisoned() before try_to_split_thp_page().\r\n\r\n[3] Pass the RMP_USE_SHARED_ZEROPAGE remap flag to remap_page().\r\n\r\n[4] Try to map the unused THP to zeropage.\r\n\r\n[5] Re-access pages in the hw-poisoned THP in the kernel.\r\n\r\n[6] Triggered in-kernel, leading to a panic kernel.\r\n\r\nIn Step[2], memory_failure() sets the poisoned flag on the page in the THP\r\nby TestSetPageHWPoison() before calling try_to_split_thp_page().\r\n\r\nAs suggested by David Hildenbrand, fix this panic by not accessing to the\r\npoisoned page in the THP during zeropage identification, while continuing\r\nto scan unaffected pages in the THP for possible zeropage mapping.  This\r\nprevents a second in-kernel #MC that would cause kernel panic in Step[4].\r\n\r\nThanks to Andrew Zaborowski for his initial work on fixing this issue. | Severity UNKNOWN  ]]></description>\r\n      <pubDate>Thu, 04 Dec 2025 16:16:00 GMT</pubDate>\r\n      <link>https//nvd.nist.gov/vuln/detail/CVE-2025-40230</link>\r\n      <guid>CVE-2025-40230</guid>\r\n    </item>\r\n    <item>\r\n      <title>CVE-2025-40231 In the Linux kernel, the following vulnerability has been resolved\r\n\r\nvsock fix lock inversion in vs...</title>\r\n      <description>![CDATA[In the Linux kernel, the following vulnerability has been resolved\r\n\r\nvsock fix lock inversion in vsock_assign_transport()\r\n\r\nSyzbot reported a potential lock inversion deadlock between\r\nvsock_register_mutex and sk_lock-AF_VSOCK when vsock_linger() is called.\r\n\r\nThe issue was introduced by commit 687aa0c5581b (\"vsock Fix\r\ntransport_* TOCTOU\") which added vsock_register_mutex locking in\r\nvsock_assign_transport() around the transport->release() call, that can\r\ncall vsock_linger(). vsock_assign_transport() can be called with sk_lock\r\nheld. vsock_linger() calls sk_wait_event() that temporarily releases and\r\nre-acquires sk_lock. During this window, if another thread hold\r\nvsock_register_mutex while trying to acquire sk_lock, a circular\r\ndependency is created.\r\n\r\nFix this by releasing vsock_register_mutex before calling\r\ntransport->release() and vsock_deassign_transport(). This is safe\r\nbecause we don't need to hold vsock_register_mutex while releasing the\r\nold transport, and we ensure the new transport won't disappear by\r\nobtaining a module reference first via try_module_get(). | Severity UNKNOWN  ]]></description>\r\n      <pubDate>Thu, 04 Dec 2025 16:16:00 GMT</pubDate>\r\n      <link>https//nvd.nist.gov/vuln/detail/CVE-2025-40231</link>\r\n      <guid>CVE-2025-40231</guid>\r\n    </item>\r\n    <item>\r\n      <title>CVE-2025-40232 In the Linux kernel, the following vulnerability has been resolved\r\n\r\nrv Fully convert enabled_monit...</title>\r\n      <description>![CDATA[In the Linux kernel, the following vulnerability has been resolved\r\n\r\nrv Fully convert enabled_monitors to use list_head as iterator\r\n\r\nThe callbacks in enabled_monitors_seq_ops are inconsistent. Some treat the\r\niterator as struct rv_monitor *, while others treat the iterator as struct\r\nlist_head *.\r\n\r\nThis causes a wrong type cast and crashes the system as reported by Nathan.\r\n\r\nConvert everything to use struct list_head * as iterator. This also makes\r\nenabled_monitors consistent with available_monitors. | Severity UNKNOWN  ]]></description>\r\n      <pubDate>Thu, 04 Dec 2025 16:16:00 GMT</pubDate>\r\n      <link>https//nvd.nist.gov/vuln/detail/CVE-2025-40232</link>\r\n      <guid>CVE-2025-40232</guid>\r\n    </item>\r\n    <item>\r\n      <title>CVE-2025-40233 In the Linux kernel, the following vulnerability has been resolved\r\n\r\nocfs2 clear extent cache after...</title>\r\n      <description>![CDATA[In the Linux kernel, the following vulnerability has been resolved\r\n\r\nocfs2 clear extent cache after moving/defragmenting extents\r\n\r\nThe extent map cache can become stale when extents are moved or\r\ndefragmented, causing subsequent operations to see outdated extent flags. \r\nThis triggers a BUG_ON in ocfs2_refcount_cal_cow_clusters().\r\n\r\nThe problem occurs when\r\n1. copy_file_range() creates a reflinked extent with OCFS2_EXT_REFCOUNTED\r\n2. ioctl(FITRIM) triggers ocfs2_move_extents()\r\n3. __ocfs2_move_extents_range() reads and caches the extent (flags=0x2)\r\n4. ocfs2_move_extent()/ocfs2_defrag_extent() calls __ocfs2_move_extent()\r\n   which clears OCFS2_EXT_REFCOUNTED flag on disk (flags=0x0)\r\n5. The extent map cache is not invalidated after the move\r\n6. Later write() operations read stale cached flags (0x2) but disk has\r\n   updated flags (0x0), causing a mismatch\r\n7. BUG_ON(!(rec->e_flags  OCFS2_EXT_REFCOUNTED)) triggers\r\n\r\nFix by clearing the extent map cache after each extent move/defrag\r\noperation in __ocfs2_move_extents_range().  This ensures subsequent\r\noperations read fresh extent data from disk. | Severity UNKNOWN  ]]></description>\r\n      <pubDate>Thu, 04 Dec 2025 16:16:00 GMT</pubDate>\r\n      <link>https//nvd.nist.gov/vuln/detail/CVE-2025-40233</link>\r\n      <guid>CVE-2025-40233</guid>\r\n    </item>\r\n    <item>\r\n      <title>CVE-2025-40234 In the Linux kernel, the following vulnerability has been resolved\r\n\r\nplatform/x86 alienware-wmi-wma...</title>\r\n      <description>![CDATA[In the Linux kernel, the following vulnerability has been resolved\r\n\r\nplatform/x86 alienware-wmi-wmax Fix NULL pointer dereference in sleep handlers\r\n\r\nDevices without the AWCC interface don't initialize `awcc`. Add a check\r\nbefore dereferencing it in sleep handlers. | Severity UNKNOWN  ]]></description>\r\n      <pubDate>Thu, 04 Dec 2025 16:16:00 GMT</pubDate>\r\n      <link>https//nvd.nist.gov/vuln/detail/CVE-2025-40234</link>\r\n      <guid>CVE-2025-40234</guid>\r\n    </item>\r\n    <item>\r\n      <title>CVE-2025-40235 In the Linux kernel, the following vulnerability has been resolved\r\n\r\nbtrfs directly free partially ...</title>\r\n      <description>![CDATA[In the Linux kernel, the following vulnerability has been resolved\r\n\r\nbtrfs directly free partially initialized fs_info in btrfs_check_leaked_roots()\r\n\r\nIf fs_info->super_copy or fs_info->super_for_commit allocated failed in\r\nbtrfs_get_tree_subvol(), then no need to call btrfs_free_fs_info().\r\nOtherwise btrfs_check_leaked_roots() would access NULL pointer because\r\nfs_info->allocated_roots had not been initialised.\r\n\r\nsyzkaller reported the following information\r\n  ------------[ cut here ]------------\r\n  BUG unable to handle page fault for address fffffffffffffbb0\r\n  #PF supervisor read access in kernel mode\r\n  #PF error_code(0x0000) - not-present page\r\n  PGD 64c9067 P4D 64c9067 PUD 64cb067 PMD 0\r\n  Oops Oops 0000 [#1] SMP KASAN PTI\r\n  CPU 0 UID 0 PID 1402 Comm syz.1.35 Not tainted 6.15.8 #4 PREEMPT(lazy)\r\n  Hardware name QEMU Standard PC (i440FX + PIIX, 1996), (...)\r\n  RIP 0010arch_atomic_read arch/x86/include/asm/atomic.h23 [inline]\r\n  RIP 0010raw_atomic_read include/linux/atomic/atomic-arch-fallback.h457 [inline]\r\n  RIP 0010atomic_read include/linux/atomic/atomic-instrumented.h33 [inline]\r\n  RIP 0010refcount_read include/linux/refcount.h170 [inline]\r\n  RIP 0010btrfs_check_leaked_roots+0x18f/0x2c0 fs/btrfs/disk-io.c1230\r\n  [...]\r\n  Call Trace\r\n   TASK>\r\n   btrfs_free_fs_info+0x310/0x410 fs/btrfs/disk-io.c1280\r\n   btrfs_get_tree_subvol+0x592/0x6b0 fs/btrfs/super.c2029\r\n   btrfs_get_tree+0x63/0x80 fs/btrfs/super.c2097\r\n   vfs_get_tree+0x98/0x320 fs/super.c1759\r\n   do_new_mount+0x357/0x660 fs/namespace.c3899\r\n   path_mount+0x716/0x19c0 fs/namespace.c4226\r\n   do_mount fs/namespace.c4239 [inline]\r\n   __do_sys_mount fs/namespace.c4450 [inline]\r\n   __se_sys_mount fs/namespace.c4427 [inline]\r\n   __x64_sys_mount+0x28c/0x310 fs/namespace.c4427\r\n   do_syscall_x64 arch/x86/entry/syscall_64.c63 [inline]\r\n   do_syscall_64+0x92/0x180 arch/x86/entry/syscall_64.c94\r\n   entry_SYSCALL_64_after_hwframe+0x76/0x7e\r\n  RIP 00330x7f032eaffa8d\r\n  [...] | Severity UNKNOWN  ]]></description>\r\n      <pubDate>Thu, 04 Dec 2025 16:16:00 GMT</pubDate>\r\n      <link>https//nvd.nist.gov/vuln/detail/CVE-2025-40235</link>\r\n      <guid>CVE-2025-40235</guid>\r\n    </item>\r\n    <item>\r\n      <title>CVE-2025-40236 In the Linux kernel, the following vulnerability has been resolved\r\n\r\nvirtio-net zero unused hash fi...</title>\r\n      <description>![CDATA[In the Linux kernel, the following vulnerability has been resolved\r\n\r\nvirtio-net zero unused hash fields\r\n\r\nWhen GSO tunnel is negotiated virtio_net_hdr_tnl_from_skb() tries to\r\ninitialize the tunnel metadata but forget to zero unused rxhash\r\nfields. This may leak information to another side. Fixing this by\r\nzeroing the unused hash fields. | Severity UNKNOWN  ]]></description>\r\n      <pubDate>Thu, 04 Dec 2025 16:16:00 GMT</pubDate>\r\n      <link>https//nvd.nist.gov/vuln/detail/CVE-2025-40236</link>\r\n      <guid>CVE-2025-40236</guid>\r\n    </item>\r\n    <item>\r\n      <title>CVE-2025-40237 In the Linux kernel, the following vulnerability has been resolved\r\n\r\nfs/notify call exportfs_encode...</title>\r\n      <description>![CDATA[In the Linux kernel, the following vulnerability has been resolved\r\n\r\nfs/notify call exportfs_encode_fid with s_umount\r\n\r\nCalling intotify_show_fdinfo() on fd watching an overlayfs inode, while\r\nthe overlayfs is being unmounted, can lead to dereferencing NULL ptr.\r\n\r\nThis issue was found by syzkaller.\r\n\r\nRace Condition Diagram\r\n\r\nThread 1                           Thread 2\r\n--------                           --------\r\n\r\ngeneric_shutdown_super()\r\n shrink_dcache_for_umount\r\n  sb->s_root = NULL\r\n\r\n                    |\r\n                    |             vfs_read()\r\n                    |              inotify_fdinfo()\r\n                    |               * inode get from mark *\r\n                    |               show_mark_fhandle(m, inode)\r\n                    |                exportfs_encode_fid(inode, ..)\r\n                    |                 ovl_encode_fh(inode, ..)\r\n                    |                  ovl_check_encode_origin(inode)\r\n                    |                   * deref i_sb->s_root *\r\n                    |\r\n                    |\r\n                    v\r\n fsnotify_sb_delete(sb)\r\n\r\nWhich then leads to\r\n\r\n[   32.133461] Oops general protection fault, probably for non-canonical address 0xdffffc0000000006 0000 [#1] SMP DEBUG_PAGEALLOC KASAN NOPTI\r\n[   32.134438] KASAN null-ptr-deref in range [0x0000000000000030-0x0000000000000037]\r\n[   32.135032] CPU 1 UID 0 PID 4468 Comm systemd-coredum Not tainted 6.17.0-rc6 #22 PREEMPT(none)\r\n\r\nsnip registers, unreliable trace>\r\n\r\n[   32.143353] Call Trace\r\n[   32.143732]  ovl_encode_fh+0xd5/0x170\r\n[   32.144031]  exportfs_encode_inode_fh+0x12f/0x300\r\n[   32.144425]  show_mark_fhandle+0xbe/0x1f0\r\n[   32.145805]  inotify_fdinfo+0x226/0x2d0\r\n[   32.146442]  inotify_show_fdinfo+0x1c5/0x350\r\n[   32.147168]  seq_show+0x530/0x6f0\r\n[   32.147449]  seq_read_iter+0x503/0x12a0\r\n[   32.148419]  seq_read+0x31f/0x410\r\n[   32.150714]  vfs_read+0x1f0/0x9e0\r\n[   32.152297]  ksys_read+0x125/0x240\r\n\r\nIOW ovl_check_encode_origin derefs inode->i_sb->s_root, after it was set\r\nto NULL in the unmount path.\r\n\r\nFix it by protecting calling exportfs_encode_fid() from\r\nshow_mark_fhandle() with s_umount lock.\r\n\r\nThis form of fix was suggested by Amir in [1].\r\n\r\n[1] https//lore.kernel.org/all/CAOQ4uxhbDwhb+2Brs1UdkoF0a3NSdBAOQPNfEHjahrgoKJpLEw@mail.gmail.com/ | Severity UNKNOWN  ]]></description>\r\n      <pubDate>Thu, 04 Dec 2025 16:16:00 GMT</pubDate>\r\n      <link>https//nvd.nist.gov/vuln/detail/CVE-2025-40237</link>\r\n      <guid>CVE-2025-40237</guid>\r\n    </item>\r\n    <item>\r\n      <title>CVE-2025-40238 In the Linux kernel, the following vulnerability has been resolved\r\n\r\nnet/mlx5 Fix IPsec cleanup ove...</title>\r\n      <description>![CDATA[In the Linux kernel, the following vulnerability has been resolved\r\n\r\nnet/mlx5 Fix IPsec cleanup over MPV device\r\n\r\nWhen we do mlx5e_detach_netdev() we eventually disable blocking events\r\nnotifier, among those events are IPsec MPV events from IB to core.\r\n\r\nSo before disabling those blocking events, make sure to also unregister\r\nthe devcom device and mark all this device operations as complete,\r\nin order to prevent the other device from using invalid netdev\r\nduring future devcom events which could cause the trace below.\r\n\r\nBUG kernel NULL pointer dereference, address 0000000000000010\r\nPGD 146427067 P4D 146427067 PUD 146488067 PMD 0\r\nOops Oops 0000 [#1] SMP\r\nCPU 1 UID 0 PID 7735 Comm devlink Tainted GW 6.12.0-rc6_for_upstream_min_debug_2024_11_08_00_46 #1\r\nTainted [W]=WARN\r\nHardware name QEMU Standard PC (Q35 + ICH9, 2009), BIOS rel-1.13.0-0-gf21b5a4aeb02-prebuilt.qemu.org 04/01/2014\r\nRIP 0010mlx5_devcom_comp_set_ready+0x5/0x40 [mlx5_core]\r\nCode 00 01 48 83 05 23 32 1e 00 01 41 b8 ed ff ff ff e9 60 ff ff ff 48 83 05 00 32 1e 00 01 eb e3 66 0f 1f 44 00 00 0f 1f 44 00 00 48> 8b 47 10 48 83 05 5f 32 1e 00 01 48 8b 50 40 48 85 d2 74 05 40\r\nRSP 0018ffff88811a5c35f8 EFLAGS 00010206\r\nRAX ffff888106e8ab80 RBX ffff888107d7e200 RCX ffff88810d6f0a00\r\nRDX ffff88810d6f0a00 RSI 0000000000000001 RDI 0000000000000000\r\nRBP ffff88811a17e620 R08 0000000000000040 R09 0000000000000000\r\nR10 ffff88811a5c3618 R11 0000000de85d51bd R12 ffff88811a17e600\r\nR13 ffff88810d6f0a00 R14 0000000000000000 R15 ffff8881034bda80\r\nFS  00007f27bdf89180(0000) GSffff88852c880000(0000) knlGS0000000000000000\r\nCS  0010 DS 0000 ES 0000 CR0 0000000080050033\r\nCR2 0000000000000010 CR3 000000010f159005 CR4 0000000000372eb0\r\nDR0 0000000000000000 DR1 0000000000000000 DR2 0000000000000000\r\nDR3 0000000000000000 DR6 00000000fffe0ff0 DR7 0000000000000400\r\nCall Trace\r\n TASK>\r\n ? __die+0x20/0x60\r\n ? page_fault_oops+0x150/0x3e0\r\n ? exc_page_fault+0x74/0x130\r\n ? asm_exc_page_fault+0x22/0x30\r\n ? mlx5_devcom_comp_set_ready+0x5/0x40 [mlx5_core]\r\n mlx5e_devcom_event_mpv+0x42/0x60 [mlx5_core]\r\n mlx5_devcom_send_event+0x8c/0x170 [mlx5_core]\r\n blocking_event+0x17b/0x230 [mlx5_core]\r\n notifier_call_chain+0x35/0xa0\r\n blocking_notifier_call_chain+0x3d/0x60\r\n mlx5_blocking_notifier_call_chain+0x22/0x30 [mlx5_core]\r\n mlx5_core_mp_event_replay+0x12/0x20 [mlx5_core]\r\n mlx5_ib_bind_slave_port+0x228/0x2c0 [mlx5_ib]\r\n mlx5_ib_stage_init_init+0x664/0x9d0 [mlx5_ib]\r\n ? idr_alloc_cyclic+0x50/0xb0\r\n ? __kmalloc_cache_noprof+0x167/0x340\r\n ? __kmalloc_noprof+0x1a7/0x430\r\n __mlx5_ib_add+0x34/0xd0 [mlx5_ib]\r\n mlx5r_probe+0xe9/0x310 [mlx5_ib]\r\n ? kernfs_add_one+0x107/0x150\r\n ? __mlx5_ib_add+0xd0/0xd0 [mlx5_ib]\r\n auxiliary_bus_probe+0x3e/0x90\r\n really_probe+0xc5/0x3a0\r\n ? driver_probe_device+0x90/0x90\r\n __driver_probe_device+0x80/0x160\r\n driver_probe_device+0x1e/0x90\r\n __device_attach_driver+0x7d/0x100\r\n bus_for_each_drv+0x80/0xd0\r\n __device_attach+0xbc/0x1f0\r\n bus_probe_device+0x86/0xa0\r\n device_add+0x62d/0x830\r\n __auxiliary_device_add+0x3b/0xa0\r\n ? auxiliary_device_init+0x41/0x90\r\n add_adev+0xd1/0x150 [mlx5_core]\r\n mlx5_rescan_drivers_locked+0x21c/0x300 [mlx5_core]\r\n esw_mode_change+0x6c/0xc0 [mlx5_core]\r\n mlx5_devlink_eswitch_mode_set+0x21e/0x640 [mlx5_core]\r\n devlink_nl_eswitch_set_doit+0x60/0xe0\r\n genl_family_rcv_msg_doit+0xd0/0x120\r\n genl_rcv_msg+0x180/0x2b0\r\n ? devlink_get_from_attrs_lock+0x170/0x170\r\n ? devlink_nl_eswitch_get_doit+0x290/0x290\r\n ? devlink_nl_pre_doit_port_optional+0x50/0x50\r\n ? genl_family_rcv_msg_dumpit+0xf0/0xf0\r\n netlink_rcv_skb+0x54/0x100\r\n genl_rcv+0x24/0x40\r\n netlink_unicast+0x1fc/0x2d0\r\n netlink_sendmsg+0x1e4/0x410\r\n __sock_sendmsg+0x38/0x60\r\n ? sockfd_lookup_light+0x12/0x60\r\n __sys_sendto+0x105/0x160\r\n ? __sys_recvmsg+0x4e/0x90\r\n __x64_sys_sendto+0x20/0x30\r\n do_syscall_64+0x4c/0x100\r\n entry_SYSCALL_64_after_hwframe+0x4b/0x53\r\nRIP 00330x7f27bc91b13a\r\nCode bb 66 2e 0f 1f 84 00 00 00 00 00 0f 1f 44 00 00 8b 05 fa 96 2c 00 45 89 c9 4c 63 d1 48 63 ff 85 c0 75 15 b8 2c 00 00 00 0f 05 48> 3d 00 f0 ff ff \r\n---truncated--- | Severity UNKNOWN  ]]></description>\r\n      <pubDate>Thu, 04 Dec 2025 16:16:00 GMT</pubDate>\r\n      <link>https//nvd.nist.gov/vuln/detail/CVE-2025-40238</link>\r\n      <guid>CVE-2025-40238</guid>\r\n    </item>\r\n    <item>\r\n      <title>CVE-2025-40239 In the Linux kernel, the following vulnerability has been resolved\r\n\r\nnet phy micrel always set sh...</title>\r\n      <description>![CDATA[In the Linux kernel, the following vulnerability has been resolved\r\n\r\nnet phy micrel always set shared->phydev for LAN8814\r\n\r\nCurrently, during the LAN8814 PTP probe shared->phydev is only set if PTP\r\nclock gets actually set, otherwise the function will return before setting\r\nit.\r\n\r\nThis is an issue as shared->phydev is unconditionally being used when IRQ\r\nis being handled, especially in lan8814_gpio_process_cap and since it was\r\nnot set it will cause a NULL pointer exception and crash the kernel.\r\n\r\nSo, simply always set shared->phydev to avoid the NULL pointer exception. | Severity UNKNOWN  ]]></description>\r\n      <pubDate>Thu, 04 Dec 2025 16:16:00 GMT</pubDate>\r\n      <link>https//nvd.nist.gov/vuln/detail/CVE-2025-40239</link>\r\n      <guid>CVE-2025-40239</guid>\r\n    </item>\r\n    <item>\r\n      <title>CVE-2025-40240 In the Linux kernel, the following vulnerability has been resolved\r\n\r\nsctp avoid NULL dereference wh...</title>\r\n      <description>![CDATA[In the Linux kernel, the following vulnerability has been resolved\r\n\r\nsctp avoid NULL dereference when chunk data buffer is missing\r\n\r\nchunk->skb pointer is dereferenced in the if-block where it's supposed\r\nto be NULL only.\r\n\r\nchunk->skb can only be NULL if chunk->head_skb is not. Check for frag_list\r\ninstead and do it just before replacing chunk->skb. We're sure that\r\notherwise chunk->skb is non-NULL because of outer if() condition. | Severity UNKNOWN  ]]></description>\r\n      <pubDate>Thu, 04 Dec 2025 16:16:00 GMT</pubDate>\r\n      <link>https//nvd.nist.gov/vuln/detail/CVE-2025-40240</link>\r\n      <guid>CVE-2025-40240</guid>\r\n    </item>\r\n    <item>\r\n      <title>CVE-2025-40241 In the Linux kernel, the following vulnerability has been resolved\r\n\r\nerofs fix crafted invalid case...</title>\r\n      <description>![CDATA[In the Linux kernel, the following vulnerability has been resolved\r\n\r\nerofs fix crafted invalid cases for encoded extents\r\n\r\nRobert recently reported two corrupted images that can cause system\r\ncrashes, which are related to the new encoded extents introduced\r\nin Linux 6.15\r\n\r\n  - The first one [1] has plen != 0 (e.g. plen == 0x2000000) but\r\n    (plen  Z_EROFS_EXTENT_PLEN_MASK) == 0. It is used to represent\r\n    special extents such as sparse extents (!EROFS_MAP_MAPPED), but\r\n    previously only plen == 0 was handled\r\n\r\n  - The second one [2] has pa 0xffffffffffdcffed and plen 0xb4000,\r\n    then \"cur [0xfffffffffffff000] += bvec.bv_len [0x1000]\" in\r\n    \"} while ((cur += bvec.bv_len)  end)\" wraps around, causing an\r\n    out-of-bound access of pcl->compressed_bvecs[] in\r\n    z_erofs_submit_queue().  EROFS only supports 48-bit physical block\r\n    addresses (up to 1EiB for 4k blocks), so add a sanity check to\r\n    enforce this. | Severity UNKNOWN  ]]></description>\r\n      <pubDate>Thu, 04 Dec 2025 16:16:00 GMT</pubDate>\r\n      <link>https//nvd.nist.gov/vuln/detail/CVE-2025-40241</link>\r\n      <guid>CVE-2025-40241</guid>\r\n    </item>\r\n    <item>\r\n      <title>CVE-2025-40242 In the Linux kernel, the following vulnerability has been resolved\r\n\r\ngfs2 Fix unlikely race in gdlm...</title>\r\n      <description>![CDATA[In the Linux kernel, the following vulnerability has been resolved\r\n\r\ngfs2 Fix unlikely race in gdlm_put_lock\r\n\r\nIn gdlm_put_lock(), there is a small window of time in which the\r\nDFL_UNMOUNT flag has been set but the lockspace hasn't been released,\r\nyet.  In that window, dlm may still call gdlm_ast() and gdlm_bast().\r\nTo prevent it from dereferencing freed glock objects, only free the\r\nglock if the lockspace has actually been released. | Severity UNKNOWN  ]]></description>\r\n      <pubDate>Thu, 04 Dec 2025 16:16:00 GMT</pubDate>\r\n      <link>https//nvd.nist.gov/vuln/detail/CVE-2025-40242</link>\r\n      <guid>CVE-2025-40242</guid>\r\n    </item>\r\n    <item>\r\n      <title>CVE-2025-40243 In the Linux kernel, the following vulnerability has been resolved\r\n\r\nhfs fix KMSAN uninit-value iss...</title>\r\n      <description>![CDATA[In the Linux kernel, the following vulnerability has been resolved\r\n\r\nhfs fix KMSAN uninit-value issue in hfs_find_set_zero_bits()\r\n\r\nThe syzbot reported issue in hfs_find_set_zero_bits()\r\n\r\n=====================================================\r\nBUG KMSAN uninit-value in hfs_find_set_zero_bits+0x74d/0xb60 fs/hfs/bitmap.c45\r\n hfs_find_set_zero_bits+0x74d/0xb60 fs/hfs/bitmap.c45\r\n hfs_vbm_search_free+0x13c/0x5b0 fs/hfs/bitmap.c151\r\n hfs_extend_file+0x6a5/0x1b00 fs/hfs/extent.c408\r\n hfs_get_block+0x435/0x1150 fs/hfs/extent.c353\r\n __block_write_begin_int+0xa76/0x3030 fs/buffer.c2151\r\n block_write_begin fs/buffer.c2262 [inline]\r\n cont_write_begin+0x10e1/0x1bc0 fs/buffer.c2601\r\n hfs_write_begin+0x85/0x130 fs/hfs/inode.c52\r\n cont_expand_zero fs/buffer.c2528 [inline]\r\n cont_write_begin+0x35a/0x1bc0 fs/buffer.c2591\r\n hfs_write_begin+0x85/0x130 fs/hfs/inode.c52\r\n hfs_file_truncate+0x1d6/0xe60 fs/hfs/extent.c494\r\n hfs_inode_setattr+0x964/0xaa0 fs/hfs/inode.c654\r\n notify_change+0x1993/0x1aa0 fs/attr.c552\r\n do_truncate+0x28f/0x310 fs/open.c68\r\n do_ftruncate+0x698/0x730 fs/open.c195\r\n do_sys_ftruncate fs/open.c210 [inline]\r\n __do_sys_ftruncate fs/open.c215 [inline]\r\n __se_sys_ftruncate fs/open.c213 [inline]\r\n __x64_sys_ftruncate+0x11b/0x250 fs/open.c213\r\n x64_sys_call+0xfe3/0x3db0 arch/x86/include/generated/asm/syscalls_64.h78\r\n do_syscall_x64 arch/x86/entry/syscall_64.c63 [inline]\r\n do_syscall_64+0xd9/0x210 arch/x86/entry/syscall_64.c94\r\n entry_SYSCALL_64_after_hwframe+0x77/0x7f\r\n\r\nUninit was created at\r\n slab_post_alloc_hook mm/slub.c4154 [inline]\r\n slab_alloc_node mm/slub.c4197 [inline]\r\n __kmalloc_cache_noprof+0x7f7/0xed0 mm/slub.c4354\r\n kmalloc_noprof include/linux/slab.h905 [inline]\r\n hfs_mdb_get+0x1cc8/0x2a90 fs/hfs/mdb.c175\r\n hfs_fill_super+0x3d0/0xb80 fs/hfs/super.c337\r\n get_tree_bdev_flags+0x6e3/0x920 fs/super.c1681\r\n get_tree_bdev+0x38/0x50 fs/super.c1704\r\n hfs_get_tree+0x35/0x40 fs/hfs/super.c388\r\n vfs_get_tree+0xb0/0x5c0 fs/super.c1804\r\n do_new_mount+0x738/0x1610 fs/namespace.c3902\r\n path_mount+0x6db/0x1e90 fs/namespace.c4226\r\n do_mount fs/namespace.c4239 [inline]\r\n __do_sys_mount fs/namespace.c4450 [inline]\r\n __se_sys_mount+0x6eb/0x7d0 fs/namespace.c4427\r\n __x64_sys_mount+0xe4/0x150 fs/namespace.c4427\r\n x64_sys_call+0xfa7/0x3db0 arch/x86/include/generated/asm/syscalls_64.h166\r\n do_syscall_x64 arch/x86/entry/syscall_64.c63 [inline]\r\n do_syscall_64+0xd9/0x210 arch/x86/entry/syscall_64.c94\r\n entry_SYSCALL_64_after_hwframe+0x77/0x7f\r\n\r\nCPU 1 UID 0 PID 12609 Comm syz.1.2692 Not tainted 6.16.0-syzkaller #0 PREEMPT(none)\r\nHardware name Google Google Compute Engine/Google Compute Engine, BIOS Google 07/12/2025\r\n=====================================================\r\n\r\nThe HFS_SB(sb)->bitmap buffer is allocated in hfs_mdb_get()\r\n\r\nHFS_SB(sb)->bitmap = kmalloc(8192, GFP_KERNEL)\r\n\r\nFinally, it can trigger the reported issue because kmalloc()\r\ndoesn't clear the allocated memory. If allocated memory contains\r\nonly zeros, then everything will work pretty fine.\r\nBut if the allocated memory contains the \"garbage\", then\r\nit can affect the bitmap operations and it triggers\r\nthe reported issue.\r\n\r\nThis patch simply exchanges the kmalloc() on kzalloc()\r\nwith the goal to guarantee the correctness of bitmap operations.\r\nBecause, newly created allocation bitmap should have all\r\navailable blocks free. Potentially, initialization bitmap's read\r\noperation could not fill the whole allocated memory and\r\n\"garbage\" in the not initialized memory will be the reason of\r\nvolume coruptions and file system driver bugs. | Severity UNKNOWN  ]]></description>\r\n      <pubDate>Thu, 04 Dec 2025 16:16:00 GMT</pubDate>\r\n      <link>https//nvd.nist.gov/vuln/detail/CVE-2025-40243</link>\r\n      <guid>CVE-2025-40243</guid>\r\n    </item>\r\n    <item>\r\n      <title>CVE-2025-40244 In the Linux kernel, the following vulnerability has been resolved\r\n\r\nhfsplus fix KMSAN uninit-value...</title>\r\n      <description>![CDATA[In the Linux kernel, the following vulnerability has been resolved\r\n\r\nhfsplus fix KMSAN uninit-value issue in __hfsplus_ext_cache_extent()\r\n\r\nThe syzbot reported issue in __hfsplus_ext_cache_extent()\r\n\r\n[   70.194323][ T9350] BUG KMSAN uninit-value in __hfsplus_ext_cache_extent+0x7d0/0x990\r\n[   70.195022][ T9350]  __hfsplus_ext_cache_extent+0x7d0/0x990\r\n[   70.195530][ T9350]  hfsplus_file_extend+0x74f/0x1cf0\r\n[   70.195998][ T9350]  hfsplus_get_block+0xe16/0x17b0\r\n[   70.196458][ T9350]  __block_write_begin_int+0x962/0x2ce0\r\n[   70.196959][ T9350]  cont_write_begin+0x1000/0x1950\r\n[   70.197416][ T9350]  hfsplus_write_begin+0x85/0x130\r\n[   70.197873][ T9350]  generic_perform_write+0x3e8/0x1060\r\n[   70.198374][ T9350]  __generic_file_write_iter+0x215/0x460\r\n[   70.198892][ T9350]  generic_file_write_iter+0x109/0x5e0\r\n[   70.199393][ T9350]  vfs_write+0xb0f/0x14e0\r\n[   70.199771][ T9350]  ksys_write+0x23e/0x490\r\n[   70.200149][ T9350]  __x64_sys_write+0x97/0xf0\r\n[   70.200570][ T9350]  x64_sys_call+0x3015/0x3cf0\r\n[   70.201065][ T9350]  do_syscall_64+0xd9/0x1d0\r\n[   70.201506][ T9350]  entry_SYSCALL_64_after_hwframe+0x77/0x7f\r\n[   70.202054][ T9350]\r\n[   70.202279][ T9350] Uninit was created at\r\n[   70.202693][ T9350]  __kmalloc_noprof+0x621/0xf80\r\n[   70.203149][ T9350]  hfsplus_find_init+0x8d/0x1d0\r\n[   70.203602][ T9350]  hfsplus_file_extend+0x6ca/0x1cf0\r\n[   70.204087][ T9350]  hfsplus_get_block+0xe16/0x17b0\r\n[   70.204561][ T9350]  __block_write_begin_int+0x962/0x2ce0\r\n[   70.205074][ T9350]  cont_write_begin+0x1000/0x1950\r\n[   70.205547][ T9350]  hfsplus_write_begin+0x85/0x130\r\n[   70.206017][ T9350]  generic_perform_write+0x3e8/0x1060\r\n[   70.206519][ T9350]  __generic_file_write_iter+0x215/0x460\r\n[   70.207042][ T9350]  generic_file_write_iter+0x109/0x5e0\r\n[   70.207552][ T9350]  vfs_write+0xb0f/0x14e0\r\n[   70.207961][ T9350]  ksys_write+0x23e/0x490\r\n[   70.208375][ T9350]  __x64_sys_write+0x97/0xf0\r\n[   70.208810][ T9350]  x64_sys_call+0x3015/0x3cf0\r\n[   70.209255][ T9350]  do_syscall_64+0xd9/0x1d0\r\n[   70.209680][ T9350]  entry_SYSCALL_64_after_hwframe+0x77/0x7f\r\n[   70.210230][ T9350]\r\n[   70.210454][ T9350] CPU 2 UID 0 PID 9350 Comm repro Not tainted 6.12.0-rc5 #5\r\n[   70.211174][ T9350] Hardware name QEMU Ubuntu 24.04 PC (i440FX + PIIX, 1996), BIOS 1.16.3-debian-1.16.3-2 04/01/2014\r\n[   70.212115][ T9350] =====================================================\r\n[   70.212734][ T9350] Disabling lock debugging due to kernel taint\r\n[   70.213284][ T9350] Kernel panic - not syncing kmsan.panic set ...\r\n[   70.213858][ T9350] CPU 2 UID 0 PID 9350 Comm repro Tainted G    B              6.12.0-rc5 #5\r\n[   70.214679][ T9350] Tainted [B]=BAD_PAGE\r\n[   70.215057][ T9350] Hardware name QEMU Ubuntu 24.04 PC (i440FX + PIIX, 1996), BIOS 1.16.3-debian-1.16.3-2 04/01/2014\r\n[   70.215999][ T9350] Call Trace\r\n[   70.216309][ T9350]  TASK>\r\n[   70.216585][ T9350]  dump_stack_lvl+0x1fd/0x2b0\r\n[   70.217025][ T9350]  dump_stack+0x1e/0x30\r\n[   70.217421][ T9350]  panic+0x502/0xca0\r\n[   70.217803][ T9350]  ? kmsan_get_metadata+0x13e/0x1c0\r\n\r\n[   70.218294][ Message fromT sy9350]  kmsan_report+0x296/slogd@syzkaller 0x2aat Aug 18 2211058 ...\r\n kernel\r\n[   70.213284][ T9350] Kernel panic - not syncing kmsan.panic [   70.220179][ T9350]  ? kmsan_get_metadata+0x13e/0x1c0\r\nset ...\r\n[   70.221254][ T9350]  ? __msan_warning+0x96/0x120\r\n[   70.222066][ T9350]  ? __hfsplus_ext_cache_extent+0x7d0/0x990\r\n[   70.223023][ T9350]  ? hfsplus_file_extend+0x74f/0x1cf0\r\n[   70.224120][ T9350]  ? hfsplus_get_block+0xe16/0x17b0\r\n[   70.224946][ T9350]  ? __block_write_begin_int+0x962/0x2ce0\r\n[   70.225756][ T9350]  ? cont_write_begin+0x1000/0x1950\r\n[   70.226337][ T9350]  ? hfsplus_write_begin+0x85/0x130\r\n[   70.226852][ T9350]  ? generic_perform_write+0x3e8/0x1060\r\n[   70.227405][ T9350]  ? __generic_file_write_iter+0x215/0x460\r\n[   70.227979][ T9350]  ? generic_file_write_iter+0x109/0x5e0\r\n[   70.228540][ T9350]  ? vfs_write+0xb0f/0x14e0\r\n[   70.228997][ T9350]  ? ksys_write+0x23e/0x490\r\n---truncated--- | Severity UNKNOWN  ]]></description>\r\n      <pubDate>Thu, 04 Dec 2025 16:16:00 GMT</pubDate>\r\n      <link>https//nvd.nist.gov/vuln/detail/CVE-2025-40244</link>\r\n      <guid>CVE-2025-40244</guid>\r\n    </item>\r\n    <item>\r\n      <title>CVE-2025-40245 In the Linux kernel, the following vulnerability has been resolved\r\n\r\nnios2 ensure that memblock.cur...</title>\r\n      <description>![CDATA[In the Linux kernel, the following vulnerability has been resolved\r\n\r\nnios2 ensure that memblock.current_limit is set when setting pfn limits\r\n\r\nOn nios2, with CONFIG_FLATMEM set, the kernel relies on\r\nmemblock_get_current_limit() to determine the limits of mem_map, in\r\nparticular for max_low_pfn.\r\nUnfortunately, memblock.current_limit is only default initialized to\r\nMEMBLOCK_ALLOC_ANYWHERE at this point of the bootup, potentially leading\r\nto situations where max_low_pfn can erroneously exceed the value of\r\nmax_pfn and, thus, the valid range of available DRAM.\r\n\r\nThis can in turn cause kernel-level paging failures, e.g.\r\n\r\n[   76.900000] Unable to handle kernel paging request at virtual address 20303000\r\n[   76.900000] ea = c0080890, ra = c000462c, cause = 14\r\n[   76.900000] Kernel panic - not syncing Oops\r\n[   76.900000] ---[ end Kernel panic - not syncing Oops ]---\r\n\r\nThis patch fixes this by pre-calculating memblock.current_limit\r\nbased on the upper limits of the available memory ranges via\r\nadjust_lowmem_bounds, a simplified version of the equivalent\r\nimplementation within the arm architecture. | Severity UNKNOWN  ]]></description>\r\n      <pubDate>Thu, 04 Dec 2025 16:16:00 GMT</pubDate>\r\n      <link>https//nvd.nist.gov/vuln/detail/CVE-2025-40245</link>\r\n      <guid>CVE-2025-40245</guid>\r\n    </item>\r\n    <item>\r\n      <title>CVE-2025-40246 In the Linux kernel, the following vulnerability has been resolved\r\n\r\nxfs fix out of bounds memory r...</title>\r\n      <description>![CDATA[In the Linux kernel, the following vulnerability has been resolved\r\n\r\nxfs fix out of bounds memory read error in symlink repair\r\n\r\nxfs/286 produced this report on my test fleet\r\n\r\n ==================================================================\r\n BUG KFENCE out-of-bounds read in memcpy_orig+0x54/0x110\r\n\r\n Out-of-bounds read at 0xffff88843fe9e038 (184B right of kfence-#184)\r\n  memcpy_orig+0x54/0x110\r\n  xrep_symlink_salvage_inline+0xb3/0xf0 [xfs]\r\n  xrep_symlink_salvage+0x100/0x110 [xfs]\r\n  xrep_symlink+0x2e/0x80 [xfs]\r\n  xrep_attempt+0x61/0x1f0 [xfs]\r\n  xfs_scrub_metadata+0x34f/0x5c0 [xfs]\r\n  xfs_ioc_scrubv_metadata+0x387/0x560 [xfs]\r\n  xfs_file_ioctl+0xe23/0x10e0 [xfs]\r\n  __x64_sys_ioctl+0x76/0xc0\r\n  do_syscall_64+0x4e/0x1e0\r\n  entry_SYSCALL_64_after_hwframe+0x4b/0x53\r\n\r\n kfence-#184 0xffff88843fe9df80-0xffff88843fe9dfea, size=107, cache=kmalloc-128\r\n\r\n allocated by task 3470 on cpu 1 at 263329.131592s (192823.508886s ago)\r\n  xfs_init_local_fork+0x79/0xe0 [xfs]\r\n  xfs_iformat_local+0xa4/0x170 [xfs]\r\n  xfs_iformat_data_fork+0x148/0x180 [xfs]\r\n  xfs_inode_from_disk+0x2cd/0x480 [xfs]\r\n  xfs_iget+0x450/0xd60 [xfs]\r\n  xfs_bulkstat_one_int+0x6b/0x510 [xfs]\r\n  xfs_bulkstat_iwalk+0x1e/0x30 [xfs]\r\n  xfs_iwalk_ag_recs+0xdf/0x150 [xfs]\r\n  xfs_iwalk_run_callbacks+0xb9/0x190 [xfs]\r\n  xfs_iwalk_ag+0x1dc/0x2f0 [xfs]\r\n  xfs_iwalk_args.constprop.0+0x6a/0x120 [xfs]\r\n  xfs_iwalk+0xa4/0xd0 [xfs]\r\n  xfs_bulkstat+0xfa/0x170 [xfs]\r\n  xfs_ioc_fsbulkstat.isra.0+0x13a/0x230 [xfs]\r\n  xfs_file_ioctl+0xbf2/0x10e0 [xfs]\r\n  __x64_sys_ioctl+0x76/0xc0\r\n  do_syscall_64+0x4e/0x1e0\r\n  entry_SYSCALL_64_after_hwframe+0x4b/0x53\r\n\r\n CPU 1 UID 0 PID 1300113 Comm xfs_scrub Not tainted 6.18.0-rc4-djwx #rc4 PREEMPT(lazy)  3d744dd94e92690f00a04398d2bd8631dcef1954\r\n Hardware name QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.16.0-4.module+el8.8.0+21164+ed375313 04/01/2014\r\n ==================================================================\r\n\r\nOn further analysis, I realized that the second parameter to min() is\r\nnot correct.  xfs_iforkif_bytes is the size of the xfs_iforkif_data\r\nbuffer.  if_bytes can be smaller than the data fork size because\r\n\r\n(a) the forkoff code tries to keep the data area as large as possible\r\n(b) for symbolic links, if_bytes is the ondisk file size + 1\r\n(c) forkoff is always a multiple of 8.\r\n\r\nCase in point for a single-byte symlink target, forkoff will be\r\n8 but the buffer will only be 2 bytes long.\r\n\r\nIn other words, the logic here is wrong and we walk off the end of the\r\nincore buffer.  Fix that. | Severity UNKNOWN  ]]></description>\r\n      <pubDate>Thu, 04 Dec 2025 16:16:00 GMT</pubDate>\r\n      <link>https//nvd.nist.gov/vuln/detail/CVE-2025-40246</link>\r\n      <guid>CVE-2025-40246</guid>\r\n    </item>\r\n    <item>\r\n      <title>CVE-2025-40247 In the Linux kernel, the following vulnerability has been resolved\r\n\r\ndrm/msm Fix pgtable prealloc e...</title>\r\n      <description>![CDATA[In the Linux kernel, the following vulnerability has been resolved\r\n\r\ndrm/msm Fix pgtable prealloc error path\r\n\r\nThe following splat was reported\r\n\r\n    Unable to handle kernel NULL pointer dereference at virtual address 0000000000000010\r\n    Mem abort info\r\n      ESR = 0x0000000096000004\r\n      EC = 0x25 DABT (current EL), IL = 32 bits\r\n      SET = 0, FnV = 0\r\n      EA = 0, S1PTW = 0\r\n      FSC = 0x04 level 0 translation fault\r\n    Data abort info\r\n      ISV = 0, ISS = 0x00000004, ISS2 = 0x00000000\r\n      CM = 0, WnR = 0, TnD = 0, TagAccess = 0\r\n      GCS = 0, Overlay = 0, DirtyBit = 0, Xs = 0\r\n    user pgtable 4k pages, 48-bit VAs, pgdp=00000008d0fd8000\r\n    [0000000000000010] pgd=0000000000000000, p4d=0000000000000000\r\n    Internal error Oops 0000000096000004 [#1]  SMP\r\n    CPU 5 UID 1000 PID 149076 Comm Xwayland Tainted G S                  6.16.0-rc2-00809-g0b6974bb4134-dirty #367 PREEMPT\r\n    Tainted [S]=CPU_OUT_OF_SPEC\r\n    Hardware name Qualcomm Technologies, Inc. SM8650 HDK (DT)\r\n    pstate 83400005 (Nzcv daif +PAN -UAO +TCO +DIT -SSBS BTYPE=--)\r\n    pc  build_detached_freelist+0x28/0x224\r\n    lr  kmem_cache_free_bulk.part.0+0x38/0x244\r\n    sp  ffff000a508c7a20\r\n    x29 ffff000a508c7a20 x28 ffff000a508c7d50 x27 ffffc4e49d16f350\r\n    x26 0000000000000058 x25 00000000fffffffc x24 0000000000000000\r\n    x23 ffff00098c4e1450 x22 00000000fffffffc x21 0000000000000000\r\n    x20 ffff000a508c7af8 x19 0000000000000002 x18 00000000000003e8\r\n    x17 ffff000809523850 x16 ffff000809523820 x15 0000000000401640\r\n    x14 ffff000809371140 x13 0000000000000130 x12 ffff0008b5711e30\r\n    x11 00000000001058fa x10 0000000000000a80 x9  ffff000a508c7940\r\n    x8  ffff000809371ba0 x7  781fffe033087fff x6  0000000000000000\r\n    x5  ffff0008003cd000 x4  781fffe033083fff x3  ffff000a508c7af8\r\n    x2  fffffdffc0000000 x1  0001000000000000 x0  ffff0008001a6a00\r\n    Call trace\r\n     build_detached_freelist+0x28/0x224 (P)\r\n     kmem_cache_free_bulk.part.0+0x38/0x244\r\n     kmem_cache_free_bulk+0x10/0x1c\r\n     msm_iommu_pagetable_prealloc_cleanup+0x3c/0xd0\r\n     msm_vma_job_free+0x30/0x240\r\n     msm_ioctl_vm_bind+0x1d0/0x9a0\r\n     drm_ioctl_kernel+0x84/0x104\r\n     drm_ioctl+0x358/0x4d4\r\n     __arm64_sys_ioctl+0x8c/0xe0\r\n     invoke_syscall+0x44/0x100\r\n     el0_svc_common.constprop.0+0x3c/0xe0\r\n     do_el0_svc+0x18/0x20\r\n     el0_svc+0x30/0x100\r\n     el0t_64_sync_handler+0x104/0x130\r\n     el0t_64_sync+0x170/0x174\r\n    Code aa0203f5 b26287e2 f2dfbfe2 aa0303f4 (f8737ab6)\r\n    ---[ end trace 0000000000000000 ]---\r\n\r\nSince msm_vma_job_free() is called directly from the ioctl, this looks\r\nlike an error path cleanup issue.  Which I think results from\r\nprealloc_cleanup() called without a preceding successful\r\nprealloc_allocate() call.  So handle that case better.\r\n\r\nPatchwork https//patchwork.freedesktop.org/patch/678677/ | Severity UNKNOWN  ]]></description>\r\n      <pubDate>Thu, 04 Dec 2025 16:16:00 GMT</pubDate>\r\n      <link>https//nvd.nist.gov/vuln/detail/CVE-2025-40247</link>\r\n      <guid>CVE-2025-40247</guid>\r\n    </item>\r\n    <item>\r\n      <title>CVE-2025-40248 In the Linux kernel, the following vulnerability has been resolved\r\n\r\nvsock Ignore signal/timeout on...</title>\r\n      <description>![CDATA[In the Linux kernel, the following vulnerability has been resolved\r\n\r\nvsock Ignore signal/timeout on connect() if already established\r\n\r\nDuring connect(), acting on a signal/timeout by disconnecting an already\r\nestablished socket leads to several issues\r\n\r\n1. connect() invoking vsock_transport_cancel_pkt() ->\r\n   virtio_transport_purge_skbs() may race with sendmsg() invoking\r\n   virtio_transport_get_credit(). This results in a permanently elevated\r\n   `vvs->bytes_unsent`. Which, in turn, confuses the SOCK_LINGER handling.\r\n\r\n2. connect() resetting a connected socket's state may race with socket\r\n   being placed in a sockmap. A disconnected socket remaining in a sockmap\r\n   breaks sockmap's assumptions. And gives rise to WARNs.\r\n\r\n3. connect() transitioning SS_CONNECTED -> SS_UNCONNECTED allows for a\r\n   transport change/drop after TCP_ESTABLISHED. Which poses a problem for\r\n   any simultaneous sendmsg() or connect() and may result in a\r\n   use-after-free/null-ptr-deref.\r\n\r\nDo not disconnect socket on signal/timeout. Keep the logic for unconnected\r\nsockets they don't linger, can't be placed in a sockmap, are rejected by\r\nsendmsg().\r\n\r\n[1] https//lore.kernel.org/netdev/e07fd95c-9a38-4eea-9638-133e38c2ec9b@rbox.co/\r\n[2] https//lore.kernel.org/netdev/20250317-vsock-trans-signal-race-v4-0-fc8837f3f1d4@rbox.co/\r\n[3] https//lore.kernel.org/netdev/60f1b7db-3099-4f6a-875e-af9f6ef194f6@rbox.co/ | Severity UNKNOWN  ]]></description>\r\n      <pubDate>Thu, 04 Dec 2025 16:16:00 GMT</pubDate>\r\n      <link>https//nvd.nist.gov/vuln/detail/CVE-2025-40248</link>\r\n      <guid>CVE-2025-40248</guid>\r\n    </item>\r\n    <item>\r\n      <title>CVE-2025-40249 In the Linux kernel, the following vulnerability has been resolved\r\n\r\ngpio cdev make sure the cdev ...</title>\r\n      <description>![CDATA[In the Linux kernel, the following vulnerability has been resolved\r\n\r\ngpio cdev make sure the cdev fd is still active before emitting events\r\n\r\nWith the final call to fput() on a file descriptor, the release action\r\nmay be deferred and scheduled on a work queue. The reference count of\r\nthat descriptor is still zero and it must not be used. It's possible\r\nthat a GPIO change, we want to notify the user-space about, happens\r\nAFTER the reference count on the file descriptor associated with the\r\ncharacter device went down to zero but BEFORE the .release() callback\r\nwas called from the workqueue and so BEFORE we unregistered from the\r\nnotifier.\r\n\r\nUsing the regular get_file() routine in this situation triggers the\r\nfollowing warning\r\n\r\n  struct filef_count incremented from zero use-after-free condition present!\r\n\r\nSo use the get_file_active() variant that will return NULL on file\r\ndescriptors that have been or are being released. | Severity UNKNOWN  ]]></description>\r\n      <pubDate>Thu, 04 Dec 2025 16:16:00 GMT</pubDate>\r\n      <link>https//nvd.nist.gov/vuln/detail/CVE-2025-40249</link>\r\n      <guid>CVE-2025-40249</guid>\r\n    </item>\r\n    <item>\r\n      <title>CVE-2025-40250 In the Linux kernel, the following vulnerability has been resolved\r\n\r\nnet/mlx5 Clean up only new IRQ...</title>\r\n      <description>![CDATA[In the Linux kernel, the following vulnerability has been resolved\r\n\r\nnet/mlx5 Clean up only new IRQ glue on request_irq() failure\r\n\r\nThe mlx5_irq_alloc() function can inadvertently free the entire rmap\r\nand end up in a crash[1] when the other threads tries to access this,\r\nwhen request_irq() fails due to exhausted IRQ vectors. This commit\r\nmodifies the cleanup to remove only the specific IRQ mapping that was\r\njust added.\r\n\r\nThis prevents removal of other valid mappings and ensures precise\r\ncleanup of the failed IRQ allocation's associated glue object.\r\n\r\nNote This error is observed when both fwctl and rds configs are enabled.\r\n\r\n[1]\r\nmlx5_core 00000500.0 Successfully registered panic handler for port 1\r\nmlx5_core 00000500.0 mlx5_irq_alloc293(pid 66740) Failed to\r\nrequest irq. err = -28\r\ninfiniband mlx5_0 mlx5_ib_test_wc290(pid 66740) Error -28 while\r\ntrying to test write-combining support\r\nmlx5_core 00000500.0 Successfully unregistered panic handler for port 1\r\nmlx5_core 00000600.0 Successfully registered panic handler for port 1\r\nmlx5_core 00000600.0 mlx5_irq_alloc293(pid 66740) Failed to\r\nrequest irq. err = -28\r\ninfiniband mlx5_0 mlx5_ib_test_wc290(pid 66740) Error -28 while\r\ntrying to test write-combining support\r\nmlx5_core 00000600.0 Successfully unregistered panic handler for port 1\r\nmlx5_core 00000300.0 mlx5_irq_alloc293(pid 28895) Failed to\r\nrequest irq. err = -28\r\nmlx5_core 00000500.0 mlx5_irq_alloc293(pid 28895) Failed to\r\nrequest irq. err = -28\r\ngeneral protection fault, probably for non-canonical address\r\n0xe277a58fde16f291 0000 [#1] SMP NOPTI\r\n\r\nRIP 0010free_irq_cpu_rmap+0x23/0x7d\r\nCall Trace\r\n   TASK>\r\n   ? show_trace_log_lvl+0x1d6/0x2f9\r\n   ? show_trace_log_lvl+0x1d6/0x2f9\r\n   ? mlx5_irq_alloc.cold+0x5d/0xf3 [mlx5_core]\r\n   ? __die_body.cold+0x8/0xa\r\n   ? die_addr+0x39/0x53\r\n   ? exc_general_protection+0x1c4/0x3e9\r\n   ? dev_vprintk_emit+0x5f/0x90\r\n   ? asm_exc_general_protection+0x22/0x27\r\n   ? free_irq_cpu_rmap+0x23/0x7d\r\n   mlx5_irq_alloc.cold+0x5d/0xf3 [mlx5_core]\r\n   irq_pool_request_vector+0x7d/0x90 [mlx5_core]\r\n   mlx5_irq_request+0x2e/0xe0 [mlx5_core]\r\n   mlx5_irq_request_vector+0xad/0xf7 [mlx5_core]\r\n   comp_irq_request_pci+0x64/0xf0 [mlx5_core]\r\n   create_comp_eq+0x71/0x385 [mlx5_core]\r\n   ? mlx5e_open_xdpsq+0x11c/0x230 [mlx5_core]\r\n   mlx5_comp_eqn_get+0x72/0x90 [mlx5_core]\r\n   ? xas_load+0x8/0x91\r\n   mlx5_comp_irqn_get+0x40/0x90 [mlx5_core]\r\n   mlx5e_open_channel+0x7d/0x3c7 [mlx5_core]\r\n   mlx5e_open_channels+0xad/0x250 [mlx5_core]\r\n   mlx5e_open_locked+0x3e/0x110 [mlx5_core]\r\n   mlx5e_open+0x23/0x70 [mlx5_core]\r\n   __dev_open+0xf1/0x1a5\r\n   __dev_change_flags+0x1e1/0x249\r\n   dev_change_flags+0x21/0x5c\r\n   do_setlink+0x28b/0xcc4\r\n   ? __nla_parse+0x22/0x3d\r\n   ? inet6_validate_link_af+0x6b/0x108\r\n   ? cpumask_next+0x1f/0x35\r\n   ? __snmp6_fill_stats64.constprop.0+0x66/0x107\r\n   ? __nla_validate_parse+0x48/0x1e6\r\n   __rtnl_newlink+0x5ff/0xa57\r\n   ? kmem_cache_alloc_trace+0x164/0x2ce\r\n   rtnl_newlink+0x44/0x6e\r\n   rtnetlink_rcv_msg+0x2bb/0x362\r\n   ? __netlink_sendskb+0x4c/0x6c\r\n   ? netlink_unicast+0x28f/0x2ce\r\n   ? rtnl_calcit.isra.0+0x150/0x146\r\n   netlink_rcv_skb+0x5f/0x112\r\n   netlink_unicast+0x213/0x2ce\r\n   netlink_sendmsg+0x24f/0x4d9\r\n   __sock_sendmsg+0x65/0x6a\r\n   ____sys_sendmsg+0x28f/0x2c9\r\n   ? import_iovec+0x17/0x2b\r\n   ___sys_sendmsg+0x97/0xe0\r\n   __sys_sendmsg+0x81/0xd8\r\n   do_syscall_64+0x35/0x87\r\n   entry_SYSCALL_64_after_hwframe+0x6e/0x0\r\nRIP 00330x7fc328603727\r\nCode c3 66 90 41 54 41 89 d4 55 48 89 f5 53 89 fb 48 83 ec 10 e8 0b ed\r\nff ff 44 89 e2 48 89 ee 89 df 41 89 c0 b8 2e 00 00 00 0f 05 48> 3d 00\r\nf0 ff ff 77 35 44 89 c7 48 89 44 24 08 e8 44 ed ff ff 48\r\nRSP 002b00007ffe8eb3f1a0 EFLAGS 00000293 ORIG_RAX 000000000000002e\r\nRAX ffffffffffffffda RBX 000000000000000d RCX 00007fc328603727\r\nRDX 0000000000000000 RSI 00007ffe8eb3f1f0 RDI 000000000000000d\r\nRBP 00007ffe8eb3f1f0 R08 0000000000000000 R09 0000000000000000\r\nR10 0000000000000000 R11 0000000000000293 R12 0000000000000000\r\nR13 00000000000\r\n---truncated--- | Severity UNKNOWN  ]]></description>\r\n      <pubDate>Thu, 04 Dec 2025 16:16:00 GMT</pubDate>\r\n      <link>https//nvd.nist.gov/vuln/detail/CVE-2025-40250</link>\r\n      <guid>CVE-2025-40250</guid>\r\n    </item>\r\n    <item>\r\n      <title>CVE-2025-40251 In the Linux kernel, the following vulnerability has been resolved\r\n\r\ndevlink rate Unset parent poi...</title>\r\n      <description>![CDATA[In the Linux kernel, the following vulnerability has been resolved\r\n\r\ndevlink rate Unset parent pointer in devl_rate_nodes_destroy\r\n\r\nThe function devl_rate_nodes_destroy is documented to \"Unset parent for\r\nall rate objects\". However, it was only calling the driver-specific\r\n`rate_leaf_parent_set` or `rate_node_parent_set` ops and decrementing\r\nthe parent's refcount, without actually setting the\r\n`devlink_rate->parent` pointer to NULL.\r\n\r\nThis leaves a dangling pointer in the `devlink_rate` struct, which cause\r\nrefcount error in netdevsim[1] and mlx5[2]. In addition, this is\r\ninconsistent with the behavior of `devlink_nl_rate_parent_node_set`,\r\nwhere the parent pointer is correctly cleared.\r\n\r\nThis patch fixes the issue by explicitly setting `devlink_rate->parent`\r\nto NULL after notifying the driver, thus fulfilling the function's\r\ndocumented behavior for all rate objects.\r\n\r\n[1]\r\nrepro steps\r\necho 1 > /sys/bus/netdevsim/new_device\r\ndevlink dev eswitch set netdevsim/netdevsim1 mode switchdev\r\necho 1 > /sys/bus/netdevsim/devices/netdevsim1/sriov_numvfs\r\ndevlink port function rate add netdevsim/netdevsim1/test_node\r\ndevlink port function rate set netdevsim/netdevsim1/128 parent test_node\r\necho 1 > /sys/bus/netdevsim/del_device\r\n\r\ndmesg\r\nrefcount_t decrement hit 0 leaking memory.\r\nWARNING CPU 8 PID 1530 at lib/refcount.c31 refcount_warn_saturate+0x42/0xe0\r\nCPU 8 UID 0 PID 1530 Comm bash Not tainted 6.18.0-rc4+ #1 NONE\r\nHardware name QEMU Standard PC (Q35 + ICH9, 2009), BIOS rel-1.16.0-0-gd239552ce722-prebuilt.qemu.org 04/01/2014\r\nRIP 0010refcount_warn_saturate+0x42/0xe0\r\nCall Trace\r\n TASK>\r\n devl_rate_leaf_destroy+0x8d/0x90\r\n __nsim_dev_port_del+0x6c/0x70 [netdevsim]\r\n nsim_dev_reload_destroy+0x11c/0x140 [netdevsim]\r\n nsim_drv_remove+0x2b/0xb0 [netdevsim]\r\n device_release_driver_internal+0x194/0x1f0\r\n bus_remove_device+0xc6/0x130\r\n device_del+0x159/0x3c0\r\n device_unregister+0x1a/0x60\r\n del_device_store+0x111/0x170 [netdevsim]\r\n kernfs_fop_write_iter+0x12e/0x1e0\r\n vfs_write+0x215/0x3d0\r\n ksys_write+0x5f/0xd0\r\n do_syscall_64+0x55/0x10f0\r\n entry_SYSCALL_64_after_hwframe+0x4b/0x53\r\n\r\n[2]\r\ndevlink dev eswitch set pci/00000800.0 mode switchdev\r\ndevlink port add pci/00000800.0 flavour pcisf pfnum 0 sfnum 1000\r\ndevlink port function rate add pci/00000800.0/group1\r\ndevlink port function rate set pci/00000800.0/32768 parent group1\r\nmodprobe -r mlx5_ib mlx5_fwctl mlx5_core\r\n\r\ndmesg\r\nrefcount_t decrement hit 0 leaking memory.\r\nWARNING CPU 7 PID 16151 at lib/refcount.c31 refcount_warn_saturate+0x42/0xe0\r\nCPU 7 UID 0 PID 16151 Comm bash Not tainted 6.17.0-rc7_for_upstream_min_debug_2025_10_02_12_44 #1 NONE\r\nHardware name QEMU Standard PC (Q35 + ICH9, 2009), BIOS rel-1.16.3-0-ga6ed6b701f0a-prebuilt.qemu.org 04/01/2014\r\nRIP 0010refcount_warn_saturate+0x42/0xe0\r\nCall Trace\r\n TASK>\r\n devl_rate_leaf_destroy+0x8d/0x90\r\n mlx5_esw_offloads_devlink_port_unregister+0x33/0x60 [mlx5_core]\r\n mlx5_esw_offloads_unload_rep+0x3f/0x50 [mlx5_core]\r\n mlx5_eswitch_unload_sf_vport+0x40/0x90 [mlx5_core]\r\n mlx5_sf_esw_event+0xc4/0x120 [mlx5_core]\r\n notifier_call_chain+0x33/0xa0\r\n blocking_notifier_call_chain+0x3b/0x50\r\n mlx5_eswitch_disable_locked+0x50/0x110 [mlx5_core]\r\n mlx5_eswitch_disable+0x63/0x90 [mlx5_core]\r\n mlx5_unload+0x1d/0x170 [mlx5_core]\r\n mlx5_uninit_one+0xa2/0x130 [mlx5_core]\r\n remove_one+0x78/0xd0 [mlx5_core]\r\n pci_device_remove+0x39/0xa0\r\n device_release_driver_internal+0x194/0x1f0\r\n unbind_store+0x99/0xa0\r\n kernfs_fop_write_iter+0x12e/0x1e0\r\n vfs_write+0x215/0x3d0\r\n ksys_write+0x5f/0xd0\r\n do_syscall_64+0x53/0x1f0\r\n entry_SYSCALL_64_after_hwframe+0x4b/0x53 | Severity UNKNOWN  ]]></description>\r\n      <pubDate>Thu, 04 Dec 2025 16:16:00 GMT</pubDate>\r\n      <link>https//nvd.nist.gov/vuln/detail/CVE-2025-40251</link>\r\n      <guid>CVE-2025-40251</guid>\r\n    </item>\r\n    <item>\r\n      <title>CVE-2025-40252 In the Linux kernel, the following vulnerability has been resolved\r\n\r\nnet qlogic/qede fix potential...</title>\r\n      <description>![CDATA[In the Linux kernel, the following vulnerability has been resolved\r\n\r\nnet qlogic/qede fix potential out-of-bounds read in qede_tpa_cont() and qede_tpa_end()\r\n\r\nThe loops in 'qede_tpa_cont()' and 'qede_tpa_end()', iterate\r\nover 'cqe->len_list[]' using only a zero-length terminator as\r\nthe stopping condition. If the terminator was missing or\r\nmalformed, the loop could run past the end of the fixed-size array.\r\n\r\nAdd an explicit bound check using ARRAY_SIZE() in both loops to prevent\r\na potential out-of-bounds access.\r\n\r\nFound by Linux Verification Center (linuxtesting.org) with SVACE. | Severity UNKNOWN  ]]></description>\r\n      <pubDate>Thu, 04 Dec 2025 16:16:00 GMT</pubDate>\r\n      <link>https//nvd.nist.gov/vuln/detail/CVE-2025-40252</link>\r\n      <guid>CVE-2025-40252</guid>\r\n    </item>\r\n    <item>\r\n      <title>CVE-2025-40253 In the Linux kernel, the following vulnerability has been resolved\r\n\r\ns390/ctcm Fix double-kfree\r\n\r\nTh...</title>\r\n      <description>![CDATA[In the Linux kernel, the following vulnerability has been resolved\r\n\r\ns390/ctcm Fix double-kfree\r\n\r\nThe function 'mpc_rcvd_sweep_req(mpcginfo)' is called conditionally\r\nfrom function 'ctcmpc_unpack_skb'. It frees passed mpcginfo.\r\nAfter that a call to function 'kfree' in function 'ctcmpc_unpack_skb'\r\nfrees it again.\r\n\r\nRemove 'kfree' call in function 'mpc_rcvd_sweep_req(mpcginfo)'.\r\n\r\nBug detected by the clang static analyzer. | Severity UNKNOWN  ]]></description>\r\n      <pubDate>Thu, 04 Dec 2025 16:16:00 GMT</pubDate>\r\n      <link>https//nvd.nist.gov/vuln/detail/CVE-2025-40253</link>\r\n      <guid>CVE-2025-40253</guid>\r\n    </item>\r\n    <item>\r\n      <title>CVE-2025-40254 In the Linux kernel, the following vulnerability has been resolved\r\n\r\nnet openvswitch remove never-...</title>\r\n      <description>![CDATA[In the Linux kernel, the following vulnerability has been resolved\r\n\r\nnet openvswitch remove never-working support for setting nsh fields\r\n\r\nThe validation of the set(nsh(...)) action is completely wrong.\r\nIt runs through the nsh_key_put_from_nlattr() function that is the\r\nsame function that validates NSH keys for the flow match and the\r\npush_nsh() action.  However, the set(nsh(...)) has a very different\r\nmemory layout.  Nested attributes in there are doubled in size in\r\ncase of the masked set().  That makes proper validation impossible.\r\n\r\nThere is also confusion in the code between the 'masked' flag, that\r\nsays that the nested attributes are doubled in size containing both\r\nthe value and the mask, and the 'is_mask' that says that the value\r\nwe're parsing is the mask.  This is causing kernel crash on trying to\r\nwrite into mask part of the match with SW_FLOW_KEY_PUT() during\r\nvalidation, while validate_nsh() doesn't allocate any memory for it\r\n\r\n  BUG kernel NULL pointer dereference, address 0000000000000018\r\n  #PF supervisor read access in kernel mode\r\n  #PF error_code(0x0000) - not-present page\r\n  PGD 1c2383067 P4D 1c2383067 PUD 20b703067 PMD 0\r\n  Oops Oops 0000 [#1] SMP NOPTI\r\n  CPU 8 UID 0 Kdump loaded Not tainted 6.17.0-rc4+ #107 PREEMPT(voluntary)\r\n  RIP 0010nsh_key_put_from_nlattr+0x19d/0x610 [openvswitch]\r\n  Call Trace\r\n   TASK>\r\n   validate_nsh+0x60/0x90 [openvswitch]\r\n   validate_set.constprop.0+0x270/0x3c0 [openvswitch]\r\n   __ovs_nla_copy_actions+0x477/0x860 [openvswitch]\r\n   ovs_nla_copy_actions+0x8d/0x100 [openvswitch]\r\n   ovs_packet_cmd_execute+0x1cc/0x310 [openvswitch]\r\n   genl_family_rcv_msg_doit+0xdb/0x130\r\n   genl_family_rcv_msg+0x14b/0x220\r\n   genl_rcv_msg+0x47/0xa0\r\n   netlink_rcv_skb+0x53/0x100\r\n   genl_rcv+0x24/0x40\r\n   netlink_unicast+0x280/0x3b0\r\n   netlink_sendmsg+0x1f7/0x430\r\n   ____sys_sendmsg+0x36b/0x3a0\r\n   ___sys_sendmsg+0x87/0xd0\r\n   __sys_sendmsg+0x6d/0xd0\r\n   do_syscall_64+0x7b/0x2c0\r\n   entry_SYSCALL_64_after_hwframe+0x76/0x7e\r\n\r\nThe third issue with this process is that while trying to convert\r\nthe non-masked set into masked one, validate_set() copies and doubles\r\nthe size of the OVS_KEY_ATTR_NSH as if it didn't have any nested\r\nattributes.  It should be copying each nested attribute and doubling\r\nthem in size independently.  And the process must be properly reversed\r\nduring the conversion back from masked to a non-masked variant during\r\nthe flow dump.\r\n\r\nIn the end, the only two outcomes of trying to use this action are\r\neither validation failure or a kernel crash.  And if somehow someone\r\nmanages to install a flow with such an action, it will most definitely\r\nnot do what it is supposed to, since all the keys and the masks are\r\nmixed up.\r\n\r\nFixing all the issues is a complex task as it requires re-writing\r\nmost of the validation code.\r\n\r\nGiven that and the fact that this functionality never worked since\r\nintroduction, let's just remove it altogether.  It's better to\r\nre-introduce it later with a proper implementation instead of trying\r\nto fix it in stable releases. | Severity UNKNOWN  ]]></description>\r\n      <pubDate>Thu, 04 Dec 2025 16:16:00 GMT</pubDate>\r\n      <link>https//nvd.nist.gov/vuln/detail/CVE-2025-40254</link>\r\n      <guid>CVE-2025-40254</guid>\r\n    </item>\r\n    <item>\r\n      <title>CVE-2025-40255 In the Linux kernel, the following vulnerability has been resolved\r\n\r\nnet core prevent NULL deref i...</title>\r\n      <description>![CDATA[In the Linux kernel, the following vulnerability has been resolved\r\n\r\nnet core prevent NULL deref in generic_hwtstamp_ioctl_lower()\r\n\r\nThe ethtool tsconfig Netlink path can trigger a null pointer\r\ndereference. A call chain such as\r\n\r\n  tsconfig_prepare_data() ->\r\n  dev_get_hwtstamp_phylib() ->\r\n  vlan_hwtstamp_get() ->\r\n  generic_hwtstamp_get_lower() ->\r\n  generic_hwtstamp_ioctl_lower()\r\n\r\nresults in generic_hwtstamp_ioctl_lower() being called with\r\nkernel_cfg->ifr as NULL.\r\n\r\nThe generic_hwtstamp_ioctl_lower() function does not expect\r\na NULL ifr and dereferences it, leading to a system crash.\r\n\r\nFix this by adding a NULL check for kernel_cfg->ifr in\r\ngeneric_hwtstamp_ioctl_lower(). If ifr is NULL, return -EINVAL. | Severity UNKNOWN  ]]></description>\r\n      <pubDate>Thu, 04 Dec 2025 16:16:00 GMT</pubDate>\r\n      <link>https//nvd.nist.gov/vuln/detail/CVE-2025-40255</link>\r\n      <guid>CVE-2025-40255</guid>\r\n    </item>\r\n    <item>\r\n      <title>CVE-2025-40256 In the Linux kernel, the following vulnerability has been resolved\r\n\r\nxfrm also call xfrm_state_dele...</title>\r\n      <description>![CDATA[In the Linux kernel, the following vulnerability has been resolved\r\n\r\nxfrm also call xfrm_state_delete_tunnel at destroy time for states that were never added\r\n\r\nIn commit b441cf3f8c4b (\"xfrm delete x->tunnel as we delete x\"), I\r\nmissed the case where state creation fails between full\r\ninitialization (->init_state has been called) and being inserted on\r\nthe lists.\r\n\r\nIn this situation, ->init_state has been called, so for IPcomp\r\ntunnels, the fallback tunnel has been created and added onto the\r\nlists, but the user state never gets added, because we fail before\r\nthat. The user state doesn't go through __xfrm_state_delete, so we\r\ndon't call xfrm_state_delete_tunnel for those states, and we end up\r\nleaking the FB tunnel.\r\n\r\nThere are several codepaths affected by this the add/update paths, in\r\nboth net/key and xfrm, and the migrate code (xfrm_migrate,\r\nxfrm_state_migrate). A \"proper\" rollback of the init_state work would\r\nprobably be doable in the add/update code, but for migrate it gets\r\nmore complicated as multiple states may be involved.\r\n\r\nAt some point, the new (not-inserted) state will be destroyed, so call\r\nxfrm_state_delete_tunnel during xfrm_state_gc_destroy. Most states\r\nwill have their fallback tunnel cleaned up during __xfrm_state_delete,\r\nwhich solves the issue that b441cf3f8c4b (and other patches before it)\r\naimed at. All states (including FB tunnels) will be removed from the\r\nlists once xfrm_state_fini has called flush_work(xfrm_state_gc_work). | Severity UNKNOWN  ]]></description>\r\n      <pubDate>Thu, 04 Dec 2025 16:16:00 GMT</pubDate>\r\n      <link>https//nvd.nist.gov/vuln/detail/CVE-2025-40256</link>\r\n      <guid>CVE-2025-40256</guid>\r\n    </item>\r\n    <item>\r\n      <title>CVE-2025-40257 In the Linux kernel, the following vulnerability has been resolved\r\n\r\nmptcp fix a race in mptcp_pm_d...</title>\r\n      <description>![CDATA[In the Linux kernel, the following vulnerability has been resolved\r\n\r\nmptcp fix a race in mptcp_pm_del_add_timer()\r\n\r\nmptcp_pm_del_add_timer() can call sk_stop_timer_sync(sk, entry->add_timer)\r\nwhile another might have free entry already, as reported by syzbot.\r\n\r\nAdd RCU protection to fix this issue.\r\n\r\nAlso change confusing add_timer variable with stop_timer boolean.\r\n\r\nsyzbot report\r\n\r\nBUG KASAN slab-use-after-free in __timer_delete_sync+0x372/0x3f0 kernel/time/timer.c1616\r\nRead of size 4 at addr ffff8880311e4150 by task kworker/11/44\r\n\r\nCPU 1 UID 0 PID 44 Comm kworker/11 Not tainted syzkaller #0 PREEMPT_{RT,(full)}\r\nHardware name Google Google Compute Engine/Google Compute Engine, BIOS Google 10/02/2025\r\nWorkqueue events mptcp_worker\r\nCall Trace\r\n TASK>\r\n  dump_stack_lvl+0x189/0x250 lib/dump_stack.c120\r\n  print_address_description mm/kasan/report.c378 [inline]\r\n  print_report+0xca/0x240 mm/kasan/report.c482\r\n  kasan_report+0x118/0x150 mm/kasan/report.c595\r\n  __timer_delete_sync+0x372/0x3f0 kernel/time/timer.c1616\r\n  sk_stop_timer_sync+0x1b/0x90 net/core/sock.c3631\r\n  mptcp_pm_del_add_timer+0x283/0x310 net/mptcp/pm.c362\r\n  mptcp_incoming_options+0x1357/0x1f60 net/mptcp/options.c1174\r\n  tcp_data_queue+0xca/0x6450 net/ipv4/tcp_input.c5361\r\n  tcp_rcv_established+0x1335/0x2670 net/ipv4/tcp_input.c6441\r\n  tcp_v4_do_rcv+0x98b/0xbf0 net/ipv4/tcp_ipv4.c1931\r\n  tcp_v4_rcv+0x252a/0x2dc0 net/ipv4/tcp_ipv4.c2374\r\n  ip_protocol_deliver_rcu+0x221/0x440 net/ipv4/ip_input.c205\r\n  ip_local_deliver_finish+0x3bb/0x6f0 net/ipv4/ip_input.c239\r\n  NF_HOOK+0x30c/0x3a0 include/linux/netfilter.h318\r\n  NF_HOOK+0x30c/0x3a0 include/linux/netfilter.h318\r\n  __netif_receive_skb_one_core net/core/dev.c6079 [inline]\r\n  __netif_receive_skb+0x143/0x380 net/core/dev.c6192\r\n  process_backlog+0x31e/0x900 net/core/dev.c6544\r\n  __napi_poll+0xb6/0x540 net/core/dev.c7594\r\n  napi_poll net/core/dev.c7657 [inline]\r\n  net_rx_action+0x5f7/0xda0 net/core/dev.c7784\r\n  handle_softirqs+0x22f/0x710 kernel/softirq.c622\r\n  __do_softirq kernel/softirq.c656 [inline]\r\n  __local_bh_enable_ip+0x1a0/0x2e0 kernel/softirq.c302\r\n  mptcp_pm_send_ack net/mptcp/pm.c210 [inline]\r\n mptcp_pm_addr_send_ack+0x41f/0x500 net/mptcp/pm.c-1\r\n  mptcp_pm_worker+0x174/0x320 net/mptcp/pm.c1002\r\n  mptcp_worker+0xd5/0x1170 net/mptcp/protocol.c2762\r\n  process_one_work kernel/workqueue.c3263 [inline]\r\n  process_scheduled_works+0xae1/0x17b0 kernel/workqueue.c3346\r\n  worker_thread+0x8a0/0xda0 kernel/workqueue.c3427\r\n  kthread+0x711/0x8a0 kernel/kthread.c463\r\n  ret_from_fork+0x4bc/0x870 arch/x86/kernel/process.c158\r\n  ret_from_fork_asm+0x1a/0x30 arch/x86/entry/entry_64.S245\r\n /TASK>\r\n\r\nAllocated by task 44\r\n  kasan_save_stack mm/kasan/common.c56 [inline]\r\n  kasan_save_track+0x3e/0x80 mm/kasan/common.c77\r\n  poison_kmalloc_redzone mm/kasan/common.c400 [inline]\r\n  __kasan_kmalloc+0x93/0xb0 mm/kasan/common.c417\r\n  kasan_kmalloc include/linux/kasan.h262 [inline]\r\n  __kmalloc_cache_noprof+0x1ef/0x6c0 mm/slub.c5748\r\n  kmalloc_noprof include/linux/slab.h957 [inline]\r\n  mptcp_pm_alloc_anno_list+0x104/0x460 net/mptcp/pm.c385\r\n  mptcp_pm_create_subflow_or_signal_addr+0xf9d/0x1360 net/mptcp/pm_kernel.c355\r\n  mptcp_pm_nl_fully_established net/mptcp/pm_kernel.c409 [inline]\r\n  __mptcp_pm_kernel_worker+0x417/0x1ef0 net/mptcp/pm_kernel.c1529\r\n  mptcp_pm_worker+0x1ee/0x320 net/mptcp/pm.c1008\r\n  mptcp_worker+0xd5/0x1170 net/mptcp/protocol.c2762\r\n  process_one_work kernel/workqueue.c3263 [inline]\r\n  process_scheduled_works+0xae1/0x17b0 kernel/workqueue.c3346\r\n  worker_thread+0x8a0/0xda0 kernel/workqueue.c3427\r\n  kthread+0x711/0x8a0 kernel/kthread.c463\r\n  ret_from_fork+0x4bc/0x870 arch/x86/kernel/process.c158\r\n  ret_from_fork_asm+0x1a/0x30 arch/x86/entry/entry_64.S245\r\n\r\nFreed by task 6630\r\n  kasan_save_stack mm/kasan/common.c56 [inline]\r\n  kasan_save_track+0x3e/0x80 mm/kasan/common.c77\r\n  __kasan_save_free_info+0x46/0x50 mm/kasan/generic.c587\r\n  kasan_save_free_info mm/kasan/kasan.h406 [inline]\r\n  poison_slab_object m\r\n---truncated--- | Severity UNKNOWN  ]]></description>\r\n      <pubDate>Thu, 04 Dec 2025 16:16:00 GMT</pubDate>\r\n      <link>https//nvd.nist.gov/vuln/detail/CVE-2025-40257</link>\r\n      <guid>CVE-2025-40257</guid>\r\n    </item>\r\n    <item>\r\n      <title>CVE-2025-40258 In the Linux kernel, the following vulnerability has been resolved\r\n\r\nmptcp fix race condition in mp...</title>\r\n      <description>![CDATA[In the Linux kernel, the following vulnerability has been resolved\r\n\r\nmptcp fix race condition in mptcp_schedule_work()\r\n\r\nsyzbot reported use-after-free in mptcp_schedule_work() [1]\r\n\r\nIssue here is that mptcp_schedule_work() schedules a work,\r\nthen gets a refcount on sk->sk_refcnt if the work was scheduled.\r\nThis refcount will be released by mptcp_worker().\r\n\r\n[A] if (schedule_work(...)) {\r\n[B]     sock_hold(sk)\r\n        return true\r\n    }\r\n\r\nProblem is that mptcp_worker() can run immediately and complete before [B]\r\n\r\nWe need instead \r\n\r\n    sock_hold(sk)\r\n    if (schedule_work(...))\r\n        return true\r\n    sock_put(sk)\r\n\r\n[1]\r\nrefcount_t addition on 0 use-after-free.\r\n WARNING CPU 1 PID 29 at lib/refcount.c25 refcount_warn_saturate+0xfa/0x1d0 lib/refcount.c25\r\nCall Trace\r\n TASK>\r\n __refcount_add include/linux/refcount.h-1 [inline]\r\n  __refcount_inc include/linux/refcount.h366 [inline]\r\n  refcount_inc include/linux/refcount.h383 [inline]\r\n  sock_hold include/net/sock.h816 [inline]\r\n  mptcp_schedule_work+0x164/0x1a0 net/mptcp/protocol.c943\r\n  mptcp_tout_timer+0x21/0xa0 net/mptcp/protocol.c2316\r\n  call_timer_fn+0x17e/0x5f0 kernel/time/timer.c1747\r\n  expire_timers kernel/time/timer.c1798 [inline]\r\n  __run_timers kernel/time/timer.c2372 [inline]\r\n  __run_timer_base+0x648/0x970 kernel/time/timer.c2384\r\n  run_timer_base kernel/time/timer.c2393 [inline]\r\n  run_timer_softirq+0xb7/0x180 kernel/time/timer.c2403\r\n  handle_softirqs+0x22f/0x710 kernel/softirq.c622\r\n  __do_softirq kernel/softirq.c656 [inline]\r\n  run_ktimerd+0xcf/0x190 kernel/softirq.c1138\r\n  smpboot_thread_fn+0x542/0xa60 kernel/smpboot.c160\r\n  kthread+0x711/0x8a0 kernel/kthread.c463\r\n  ret_from_fork+0x4bc/0x870 arch/x86/kernel/process.c158\r\n  ret_from_fork_asm+0x1a/0x30 arch/x86/entry/entry_64.S245 | Severity UNKNOWN  ]]></description>\r\n      <pubDate>Thu, 04 Dec 2025 16:16:00 GMT</pubDate>\r\n      <link>https//nvd.nist.gov/vuln/detail/CVE-2025-40258</link>\r\n      <guid>CVE-2025-40258</guid>\r\n    </item>\r\n    <item>\r\n      <title>CVE-2025-40259 In the Linux kernel, the following vulnerability has been resolved\r\n\r\nscsi sg Do not sleep in atomi...</title>\r\n      <description>![CDATA[In the Linux kernel, the following vulnerability has been resolved\r\n\r\nscsi sg Do not sleep in atomic context\r\n\r\nsg_finish_rem_req() calls blk_rq_unmap_user(). The latter function may\r\nsleep. Hence, call sg_finish_rem_req() with interrupts enabled instead\r\nof disabled. | Severity UNKNOWN  ]]></description>\r\n      <pubDate>Thu, 04 Dec 2025 16:16:00 GMT</pubDate>\r\n      <link>https//nvd.nist.gov/vuln/detail/CVE-2025-40259</link>\r\n      <guid>CVE-2025-40259</guid>\r\n    </item>\r\n    <item>\r\n      <title>CVE-2025-40260 In the Linux kernel, the following vulnerability has been resolved\r\n\r\nsched_ext Fix scx_enable() cra...</title>\r\n      <description>![CDATA[In the Linux kernel, the following vulnerability has been resolved\r\n\r\nsched_ext Fix scx_enable() crash on helper kthread creation failure\r\n\r\nA crash was observed when the sched_ext selftests runner was\r\nterminated with Ctrl+\\ while test 15 was running\r\n\r\nNIP [c00000000028fa58] scx_enable.constprop.0+0x358/0x12b0\r\nLR [c00000000028fa2c] scx_enable.constprop.0+0x32c/0x12b0\r\nCall Trace\r\nscx_enable.constprop.0+0x32c/0x12b0 (unreliable)\r\nbpf_struct_ops_link_create+0x18c/0x22c\r\n__sys_bpf+0x23f8/0x3044\r\nsys_bpf+0x2c/0x6c\r\nsystem_call_exception+0x124/0x320\r\nsystem_call_vectored_common+0x15c/0x2ec\r\n\r\nkthread_run_worker() returns an ERR_PTR() on failure rather than NULL,\r\nbut the current code in scx_alloc_and_add_sched() only checks for a NULL\r\nhelper. Incase of failure on SIGQUIT, the error is not handled in\r\nscx_alloc_and_add_sched() and scx_enable() ends up dereferencing an\r\nerror pointer.\r\n\r\nError handling is fixed in scx_alloc_and_add_sched() to propagate\r\nPTR_ERR() into ret, so that scx_enable() jumps to the existing error\r\npath, avoiding random dereference on failure. | Severity UNKNOWN  ]]></description>\r\n      <pubDate>Thu, 04 Dec 2025 16:16:00 GMT</pubDate>\r\n      <link>https//nvd.nist.gov/vuln/detail/CVE-2025-40260</link>\r\n      <guid>CVE-2025-40260</guid>\r\n    </item>\r\n    <item>\r\n      <title>CVE-2025-40261 In the Linux kernel, the following vulnerability has been resolved\r\n\r\nnvme nvme-fc Ensure ->ioerr_w...</title>\r\n      <description>![CDATA[In the Linux kernel, the following vulnerability has been resolved\r\n\r\nnvme nvme-fc Ensure ->ioerr_work is cancelled in nvme_fc_delete_ctrl()\r\n\r\nnvme_fc_delete_assocation() waits for pending I/O to complete before\r\nreturning, and an error can cause ->ioerr_work to be queued after\r\ncancel_work_sync() had been called.  Move the call to cancel_work_sync() to\r\nbe after nvme_fc_delete_association() to ensure ->ioerr_work is not running\r\nwhen the nvme_fc_ctrl object is freed.  Otherwise the following can occur\r\n\r\n[ 1135.911754] list_del corruption, ff2d24c8093f31f8->next is NULL\r\n[ 1135.917705] ------------[ cut here ]------------\r\n[ 1135.922336] kernel BUG at lib/list_debug.c52!\r\n[ 1135.926784] Oops invalid opcode 0000 [#1] SMP NOPTI\r\n[ 1135.931851] CPU 48 UID 0 PID 726 Comm kworker/u44923 Kdump loaded Not tainted 6.12.0 #1 PREEMPT(voluntary)\r\n[ 1135.943490] Hardware name Dell Inc. PowerEdge R660/0HGTK9, BIOS 2.5.4 01/16/2025\r\n[ 1135.950969] Workqueue  0x0 (nvme-wq)\r\n[ 1135.954673] RIP 0010__list_del_entry_valid_or_report.cold+0xf/0x6f\r\n[ 1135.961041] Code c7 c7 98 68 72 94 e8 26 45 fe ff 0f 0b 48 c7 c7 70 68 72 94 e8 18 45 fe ff 0f 0b 48 89 fe 48 c7 c7 80 69 72 94 e8 07 45 fe ff 0f> 0b 48 89 d1 48 c7 c7 a0 6a 72 94 48 89 c2 e8 f3 44 fe ff 0f 0b\r\n[ 1135.979788] RSP 0018ff579b19482d3e50 EFLAGS 00010046\r\n[ 1135.985015] RAX 0000000000000033 RBX ff2d24c8093f31f0 RCX 0000000000000000\r\n[ 1135.992148] RDX 0000000000000000 RSI ff2d24d6bfa1d0c0 RDI ff2d24d6bfa1d0c0\r\n[ 1135.999278] RBP ff2d24c8093f31f8 R08 0000000000000000 R09 ffffffff951e2b08\r\n[ 1136.006413] R10 ffffffff95122ac8 R11 0000000000000003 R12 ff2d24c78697c100\r\n[ 1136.013546] R13 fffffffffffffff8 R14 0000000000000000 R15 ff2d24c78697c0c0\r\n[ 1136.020677] FS  0000000000000000(0000) GSff2d24d6bfa00000(0000) knlGS0000000000000000\r\n[ 1136.028765] CS  0010 DS 0000 ES 0000 CR0 0000000080050033\r\n[ 1136.034510] CR2 00007fd207f90b80 CR3 000000163ea22003 CR4 0000000000f73ef0\r\n[ 1136.041641] DR0 0000000000000000 DR1 0000000000000000 DR2 0000000000000000\r\n[ 1136.048776] DR3 0000000000000000 DR6 00000000fffe07f0 DR7 0000000000000400\r\n[ 1136.055910] PKRU 55555554\r\n[ 1136.058623] Call Trace\r\n[ 1136.061074]  TASK>\r\n[ 1136.063179]  ? show_trace_log_lvl+0x1b0/0x2f0\r\n[ 1136.067540]  ? show_trace_log_lvl+0x1b0/0x2f0\r\n[ 1136.071898]  ? move_linked_works+0x4a/0xa0\r\n[ 1136.075998]  ? __list_del_entry_valid_or_report.cold+0xf/0x6f\r\n[ 1136.081744]  ? __die_body.cold+0x8/0x12\r\n[ 1136.085584]  ? die+0x2e/0x50\r\n[ 1136.088469]  ? do_trap+0xca/0x110\r\n[ 1136.091789]  ? do_error_trap+0x65/0x80\r\n[ 1136.095543]  ? __list_del_entry_valid_or_report.cold+0xf/0x6f\r\n[ 1136.101289]  ? exc_invalid_op+0x50/0x70\r\n[ 1136.105127]  ? __list_del_entry_valid_or_report.cold+0xf/0x6f\r\n[ 1136.110874]  ? asm_exc_invalid_op+0x1a/0x20\r\n[ 1136.115059]  ? __list_del_entry_valid_or_report.cold+0xf/0x6f\r\n[ 1136.120806]  move_linked_works+0x4a/0xa0\r\n[ 1136.124733]  worker_thread+0x216/0x3a0\r\n[ 1136.128485]  ? __pfx_worker_thread+0x10/0x10\r\n[ 1136.132758]  kthread+0xfa/0x240\r\n[ 1136.135904]  ? __pfx_kthread+0x10/0x10\r\n[ 1136.139657]  ret_from_fork+0x31/0x50\r\n[ 1136.143236]  ? __pfx_kthread+0x10/0x10\r\n[ 1136.146988]  ret_from_fork_asm+0x1a/0x30\r\n[ 1136.150915]  /TASK> | Severity UNKNOWN  ]]></description>\r\n      <pubDate>Thu, 04 Dec 2025 16:16:00 GMT</pubDate>\r\n      <link>https//nvd.nist.gov/vuln/detail/CVE-2025-40261</link>\r\n      <guid>CVE-2025-40261</guid>\r\n    </item>\r\n    <item>\r\n      <title>CVE-2025-40262 In the Linux kernel, the following vulnerability has been resolved\r\n\r\nInput imx_sc_key - fix memory ...</title>\r\n      <description>![CDATA[In the Linux kernel, the following vulnerability has been resolved\r\n\r\nInput imx_sc_key - fix memory corruption on unload\r\n\r\nThis is supposed to be \"priv\" but we accidentally pass \"priv\" which is\r\nan address in the stack and so it will lead to memory corruption when\r\nthe imx_sc_key_action() function is called.  Remove the . | Severity UNKNOWN  ]]></description>\r\n      <pubDate>Thu, 04 Dec 2025 16:16:00 GMT</pubDate>\r\n      <link>https//nvd.nist.gov/vuln/detail/CVE-2025-40262</link>\r\n      <guid>CVE-2025-40262</guid>\r\n    </item>\r\n    <item>\r\n      <title>CVE-2025-40263 In the Linux kernel, the following vulnerability has been resolved\r\n\r\nInput cros_ec_keyb - fix an in...</title>\r\n      <description>![CDATA[In the Linux kernel, the following vulnerability has been resolved\r\n\r\nInput cros_ec_keyb - fix an invalid memory access\r\n\r\nIf cros_ec_keyb_register_matrix() isn't called (due to\r\n`buttons_switches_only`) in cros_ec_keyb_probe(), `ckdev->idev` remains\r\nNULL.  An invalid memory access is observed in cros_ec_keyb_process()\r\nwhen receiving an EC_MKBP_EVENT_KEY_MATRIX event in cros_ec_keyb_work()\r\nin such case.\r\n\r\n  Unable to handle kernel read from unreadable memory at virtual address 0000000000000028\r\n  ...\r\n  x3  0000000000000000 x2  0000000000000000\r\n  x1  0000000000000000 x0  0000000000000000\r\n  Call trace\r\n  input_event\r\n  cros_ec_keyb_work\r\n  blocking_notifier_call_chain\r\n  ec_irq_thread\r\n\r\nIt's still unknown about why the kernel receives such malformed event,\r\nin any cases, the kernel shouldn't access `ckdev->idev` and friends if\r\nthe driver doesn't intend to initialize them. | Severity UNKNOWN  ]]></description>\r\n      <pubDate>Thu, 04 Dec 2025 16:16:00 GMT</pubDate>\r\n      <link>https//nvd.nist.gov/vuln/detail/CVE-2025-40263</link>\r\n      <guid>CVE-2025-40263</guid>\r\n    </item>\r\n    <item>\r\n      <title>CVE-2025-40264 In the Linux kernel, the following vulnerability has been resolved\r\n\r\nbe2net pass wrb_params in case...</title>\r\n      <description>![CDATA[In the Linux kernel, the following vulnerability has been resolved\r\n\r\nbe2net pass wrb_params in case of OS2BMC\r\n\r\nbe_insert_vlan_in_pkt() is called with the wrb_params argument being NULL\r\nat be_send_pkt_to_bmc() call site.  This may lead to dereferencing a NULL\r\npointer when processing a workaround for specific packet, as commit\r\nbc0c3405abbb (\"be2net fix a Tx stall bug caused by a specific ipv6\r\npacket\") states.\r\n\r\nThe correct way would be to pass the wrb_params from be_xmit(). | Severity UNKNOWN  ]]></description>\r\n      <pubDate>Thu, 04 Dec 2025 16:16:00 GMT</pubDate>\r\n      <link>https//nvd.nist.gov/vuln/detail/CVE-2025-40264</link>\r\n      <guid>CVE-2025-40264</guid>\r\n    </item>\r\n    <item>\r\n      <title>CVE-2025-40265 In the Linux kernel, the following vulnerability has been resolved\r\n\r\nvfat fix missing sb_min_blocks...</title>\r\n      <description>![CDATA[In the Linux kernel, the following vulnerability has been resolved\r\n\r\nvfat fix missing sb_min_blocksize() return value checks\r\n\r\nWhen emulating an nvme device on qemu with both logical_block_size and\r\nphysical_block_size set to 8 KiB, but without format, a kernel panic\r\nwas triggered during the early boot stage while attempting to mount a\r\nvfat filesystem.\r\n\r\n[95553.682035] EXT4-fs (nvme0n1) unable to set blocksize\r\n[95553.684326] EXT4-fs (nvme0n1) unable to set blocksize\r\n[95553.686501] EXT4-fs (nvme0n1) unable to set blocksize\r\n[95553.696448] ISOFS unsupported/invalid hardware sector size 8192\r\n[95553.697117] ------------[ cut here ]------------\r\n[95553.697567] kernel BUG at fs/buffer.c1582!\r\n[95553.697984] Oops invalid opcode 0000 [#1] SMP NOPTI\r\n[95553.698602] CPU 0 UID 0 PID 7212 Comm mount Kdump loaded Not tainted 6.18.0-rc2+ #38 PREEMPT(voluntary)\r\n[95553.699511] Hardware name QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.16.3-0-ga6ed6b701f0a-prebuilt.qemu.org 04/01/2014\r\n[95553.700534] RIP 0010folio_alloc_buffers+0x1bb/0x1c0\r\n[95553.701018] Code 48 8b 15 e8 93 18 02 65 48 89 35 e0 93 18 02 48 83 c4 10 5b 41 5c 41 5d 41 5e 41 5f 5d 31 d2 31 c9 31 f6 31 ff c3 cc cc cc cc 0f> 0b 90 66 90 90 90 90 90 90 90 90 90 90 90 90 90 90 90 90 90 0f\r\n[95553.702648] RSP 0018ffffd1b0c676f990 EFLAGS 00010246\r\n[95553.703132] RAX ffff8cfc4176d820 RBX 0000000000508c48 RCX 0000000000000001\r\n[95553.703805] RDX 0000000000002000 RSI 0000000000000000 RDI 0000000000000000\r\n[95553.704481] RBP ffffd1b0c676f9c8 R08 0000000000000000 R09 0000000000000000\r\n[95553.705148] R10 0000000000000000 R11 0000000000000000 R12 0000000000000001\r\n[95553.705816] R13 0000000000002000 R14 fffff8bc8257e800 R15 0000000000000000\r\n[95553.706483] FS  000072ee77315840(0000) GSffff8cfdd2c8d000(0000) knlGS0000000000000000\r\n[95553.707248] CS  0010 DS 0000 ES 0000 CR0 0000000080050033\r\n[95553.707782] CR2 00007d8f2a9e5a20 CR3 0000000039d0c006 CR4 0000000000772ef0\r\n[95553.708439] PKRU 55555554\r\n[95553.708734] Call Trace\r\n[95553.709015]  TASK>\r\n[95553.709266]  __getblk_slow+0xd2/0x230\r\n[95553.709641]  ? find_get_block_common+0x8b/0x530\r\n[95553.710084]  bdev_getblk+0x77/0xa0\r\n[95553.710449]  __bread_gfp+0x22/0x140\r\n[95553.710810]  fat_fill_super+0x23a/0xfc0\r\n[95553.711216]  ? __pfx_setup+0x10/0x10\r\n[95553.711580]  ? __pfx_vfat_fill_super+0x10/0x10\r\n[95553.712014]  vfat_fill_super+0x15/0x30\r\n[95553.712401]  get_tree_bdev_flags+0x141/0x1e0\r\n[95553.712817]  get_tree_bdev+0x10/0x20\r\n[95553.713177]  vfat_get_tree+0x15/0x20\r\n[95553.713550]  vfs_get_tree+0x2a/0x100\r\n[95553.713910]  vfs_cmd_create+0x62/0xf0\r\n[95553.714273]  __do_sys_fsconfig+0x4e7/0x660\r\n[95553.714669]  __x64_sys_fsconfig+0x20/0x40\r\n[95553.715062]  x64_sys_call+0x21ee/0x26a0\r\n[95553.715453]  do_syscall_64+0x80/0x670\r\n[95553.715816]  ? __fs_parse+0x65/0x1e0\r\n[95553.716172]  ? fat_parse_param+0x103/0x4b0\r\n[95553.716587]  ? vfs_parse_fs_param_source+0x21/0xa0\r\n[95553.717034]  ? __do_sys_fsconfig+0x3d9/0x660\r\n[95553.717548]  ? __x64_sys_fsconfig+0x20/0x40\r\n[95553.717957]  ? x64_sys_call+0x21ee/0x26a0\r\n[95553.718360]  ? do_syscall_64+0xb8/0x670\r\n[95553.718734]  ? __x64_sys_fsconfig+0x20/0x40\r\n[95553.719141]  ? x64_sys_call+0x21ee/0x26a0\r\n[95553.719545]  ? do_syscall_64+0xb8/0x670\r\n[95553.719922]  ? x64_sys_call+0x1405/0x26a0\r\n[95553.720317]  ? do_syscall_64+0xb8/0x670\r\n[95553.720702]  ? __x64_sys_close+0x3e/0x90\r\n[95553.721080]  ? x64_sys_call+0x1b5e/0x26a0\r\n[95553.721478]  ? do_syscall_64+0xb8/0x670\r\n[95553.721841]  ? irqentry_exit+0x43/0x50\r\n[95553.722211]  ? exc_page_fault+0x90/0x1b0\r\n[95553.722681]  entry_SYSCALL_64_after_hwframe+0x76/0x7e\r\n[95553.723166] RIP 00330x72ee774f3afe\r\n[95553.723562] Code 73 01 c3 48 8b 0d 0a 33 0f 00 f7 d8 64 89 01 48 83 c8 ff c3 0f 1f 84 00 00 00 00 00 f3 0f 1e fa 49 89 ca b8 af 01 00 00 0f 05 48> 3d 01 f0 ff ff 73 01 c3 48 8b 0d da 32 0f 00 f7 d8 64 89 01 48\r\n[95553.725188] RSP 002b00007ffe97148978 EFLAGS 00000246 ORIG_RAX 00000000000001af\r\n[95553.725892] RAX ffffffffffffffda RBX \r\n---truncated--- | Severity UNKNOWN  ]]></description>\r\n      <pubDate>Thu, 04 Dec 2025 16:16:00 GMT</pubDate>\r\n      <link>https//nvd.nist.gov/vuln/detail/CVE-2025-40265</link>\r\n      <guid>CVE-2025-40265</guid>\r\n    </item>\r\n    <item>\r\n      <title>CVE-2025-40266 In the Linux kernel, the following vulnerability has been resolved\r\n\r\nKVM arm64 Check the untrusted...</title>\r\n      <description>![CDATA[In the Linux kernel, the following vulnerability has been resolved\r\n\r\nKVM arm64 Check the untrusted offset in FF-A memory share\r\n\r\nVerify the offset to prevent OOB access in the hypervisor\r\nFF-A buffer in case an untrusted large enough value\r\n[U32_MAX - sizeof(struct ffa_composite_mem_region) + 1, U32_MAX]\r\nis set from the host kernel. | Severity UNKNOWN  ]]></description>\r\n      <pubDate>Thu, 04 Dec 2025 16:16:00 GMT</pubDate>\r\n      <link>https//nvd.nist.gov/vuln/detail/CVE-2025-40266</link>\r\n      <guid>CVE-2025-40266</guid>\r\n    </item>\r\n    <item>\r\n      <title>CVE-2025-54158 Missing authentication for critical function vulnerability in BeeDrive in Synology BeeDrive for desk...</title>\r\n      <description>![CDATA[Missing authentication for critical function vulnerability in BeeDrive in Synology BeeDrive for desktop before 1.4.2-13960 allows local users to execute arbitrary code via unspecified vectors. | CVSS Score 7.8 (HIGH)  ]]>  </description>\r\n      <pubDate>Thu, 04 Dec 2025 16:16:00 GMT</pubDate>\r\n      <link>https//nvd.nist.gov/vuln/detail/CVE-2025-54158</link>\r\n      <guid>CVE-2025-54158</guid>\r\n    </item>\r\n  </channel>\r\n</rss>"
}