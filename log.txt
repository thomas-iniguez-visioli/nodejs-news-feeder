[
  {
    title: 'CVE-2025-14024 Rejected reason ** REJECT ** DO NOT USE THIS CANDIDATE NUMBER. Reason This candidate was issued in...',
    link: 'https//nvd.nist.gov/vuln/detail/CVE-2025-14024',
    pubDate: 'Thu, 04 Dec 2025 16:16:00 GMT',
    content: 'Rejected reason ** REJECT ** DO NOT USE THIS CANDIDATE NUMBER. Reason This candidate was issued in error. Notes All references and descriptions in this candidate have been removed to prevent accidental usage. | Severity UNKNOWN  ',
    contentSnippet: 'Rejected reason ** REJECT ** DO NOT USE THIS CANDIDATE NUMBER. Reason This candidate was issued in error. Notes All references and descriptions in this candidate have been removed to prevent accidental usage. | Severity UNKNOWN',
    guid: 'CVE-2025-14024',
    isoDate: '2025-12-04T16:16:00.000Z'
  },
  {
    title: 'CVE-2025-40222 In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'tty serial sh-sci fix RSCI F...',
    link: 'https//nvd.nist.gov/vuln/detail/CVE-2025-40222',
    pubDate: 'Thu, 04 Dec 2025 16:16:00 GMT',
    content: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'tty serial sh-sci fix RSCI FIFO overrun handling\n' +
      '\n' +
      'The receive error handling code is shared between RSCI and all other\n' +
      'SCIF port types, but the RSCI overrun_reg is specified as a memory\n' +
      'offset, while for other SCIF types it is an enum value used to index\n' +
      'into the sci_port_params->regs array, as mentioned above the\n' +
      'sci_serial_in() function.\n' +
      '\n' +
      'For RSCI, the overrun_reg is CSR (0x48), causing the sci_getreg() call\n' +
      'inside the sci_handle_fifo_overrun() function to index outside the\n' +
      'bounds of the regs array, which currently has a size of 20, as specified\n' +
      'by SCI_NR_REGS.\n' +
      '\n' +
      "Because of this, we end up accessing memory outside of RSCI's\n" +
      'rsci_port_params structure, which, when interpreted as a plat_sci_reg,\n' +
      'happens to have a non-zero size, causing the following WARN when\n' +
      'sci_serial_in() is called, as the accidental size does not match the\n' +
      'supported register sizes.\n' +
      '\n' +
      'The existence of the overrun_reg needs to be checked because\n' +
      'SCIx_SH3_SCIF_REGTYPE has overrun_reg set to SCLSR, but SCLSR is not\n' +
      'present in the regs array.\n' +
      '\n' +
      "Avoid calling sci_getreg() for port types which don't use standard\n" +
      'register handling.\n' +
      '\n' +
      'Use the ops->read_reg() and ops->write_reg() functions to properly read\n' +
      'and write registers for RSCI, and change the type of the status variable\n' +
      'to accommodate the 32-bit CSR register.\n' +
      '\n' +
      'sci_getreg() and sci_serial_in() are also called with overrun_reg in the\n' +
      'sci_mpxed_interrupt() interrupt handler, but that code path is not used\n' +
      'for RSCI, as it does not have a muxed interrupt.\n' +
      '\n' +
      '------------[ cut here ]------------\n' +
      'Invalid register access\n' +
      'WARNING CPU 0 PID 0 at drivers/tty/serial/sh-sci.c522 sci_serial_in+0x38/0xac\n' +
      'Modules linked in renesas_usbhs at24 rzt2h_adc industrialio_adc sha256 cfg80211 bluetooth ecdh_generic ecc rfkill fuse drm backlight ipv6\n' +
      'CPU 0 UID 0 PID 0 Comm swapper/0 Not tainted 6.17.0-rc1+ #30 PREEMPT\n' +
      'Hardware name Renesas RZ/T2H EVK Board based on r9a09g077m44 (DT)\n' +
      'pstate 604000c5 (nZCv daIF +PAN -UAO -TCO -DIT -SSBS BTYPE=--)\n' +
      'pc  sci_serial_in+0x38/0xac\n' +
      'lr  sci_serial_in+0x38/0xac\n' +
      'sp  ffff800080003e80\n' +
      'x29 ffff800080003e80 x28 ffff800082195b80 x27 000000000000000d\n' +
      'x26 ffff8000821956d0 x25 0000000000000000 x24 ffff800082195b80\n' +
      'x23 ffff000180e0d800 x22 0000000000000010 x21 0000000000000000\n' +
      'x20 0000000000000010 x19 ffff000180e72000 x18 000000000000000a\n' +
      'x17 ffff8002bcee7000 x16 ffff800080000000 x15 0720072007200720\n' +
      'x14 0720072007200720 x13 0720072007200720 x12 0720072007200720\n' +
      'x11 0000000000000058 x10 0000000000000018 x9  ffff8000821a6a48\n' +
      'x8  0000000000057fa8 x7  0000000000000406 x6  ffff8000821fea48\n' +
      'x5  ffff00033ef88408 x4  ffff8002bcee7000 x3  ffff800082195b80\n' +
      'x2  0000000000000000 x1  0000000000000000 x0  ffff800082195b80\n' +
      'Call trace\n' +
      ' sci_serial_in+0x38/0xac (P)\n' +
      ' sci_handle_fifo_overrun.isra.0+0x70/0x134\n' +
      ' sci_er_interrupt+0x50/0x39c\n' +
      ' __handle_irq_event_percpu+0x48/0x140\n' +
      ' handle_irq_event+0x44/0xb0\n' +
      ' handle_fasteoi_irq+0xf4/0x1a0\n' +
      ' handle_irq_desc+0x34/0x58\n' +
      ' generic_handle_domain_irq+0x1c/0x28\n' +
      ' gic_handle_irq+0x4c/0x140\n' +
      ' call_on_irq_stack+0x30/0x48\n' +
      ' do_interrupt_handler+0x80/0x84\n' +
      ' el1_interrupt+0x34/0x68\n' +
      ' el1h_64_irq_handler+0x18/0x24\n' +
      ' el1h_64_irq+0x6c/0x70\n' +
      ' default_idle_call+0x28/0x58 (P)\n' +
      ' do_idle+0x1f8/0x250\n' +
      ' cpu_startup_entry+0x34/0x3c\n' +
      ' rest_init+0xd8/0xe0\n' +
      ' console_on_rootfs+0x0/0x6c\n' +
      ' __primary_switched+0x88/0x90\n' +
      '---[ end trace 0000000000000000 ]--- | Severity UNKNOWN  ',
    contentSnippet: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'tty serial sh-sci fix RSCI FIFO overrun handling\n' +
      '\n' +
      'The receive error handling code is shared between RSCI and all other\n' +
      'SCIF port types, but the RSCI overrun_reg is specified as a memory\n' +
      'offset, while for other SCIF types it is an enum value used to index\n' +
      'into the sci_port_params->regs array, as mentioned above the\n' +
      'sci_serial_in() function.\n' +
      '\n' +
      'For RSCI, the overrun_reg is CSR (0x48), causing the sci_getreg() call\n' +
      'inside the sci_handle_fifo_overrun() function to index outside the\n' +
      'bounds of the regs array, which currently has a size of 20, as specified\n' +
      'by SCI_NR_REGS.\n' +
      '\n' +
      "Because of this, we end up accessing memory outside of RSCI's\n" +
      'rsci_port_params structure, which, when interpreted as a plat_sci_reg,\n' +
      'happens to have a non-zero size, causing the following WARN when\n' +
      'sci_serial_in() is called, as the accidental size does not match the\n' +
      'supported register sizes.\n' +
      '\n' +
      'The existence of the overrun_reg needs to be checked because\n' +
      'SCIx_SH3_SCIF_REGTYPE has overrun_reg set to SCLSR, but SCLSR is not\n' +
      'present in the regs array.\n' +
      '\n' +
      "Avoid calling sci_getreg() for port types which don't use standard\n" +
      'register handling.\n' +
      '\n' +
      'Use the ops->read_reg() and ops->write_reg() functions to properly read\n' +
      'and write registers for RSCI, and change the type of the status variable\n' +
      'to accommodate the 32-bit CSR register.\n' +
      '\n' +
      'sci_getreg() and sci_serial_in() are also called with overrun_reg in the\n' +
      'sci_mpxed_interrupt() interrupt handler, but that code path is not used\n' +
      'for RSCI, as it does not have a muxed interrupt.\n' +
      '\n' +
      '------------[ cut here ]------------\n' +
      'Invalid register access\n' +
      'WARNING CPU 0 PID 0 at drivers/tty/serial/sh-sci.c522 sci_serial_in+0x38/0xac\n' +
      'Modules linked in renesas_usbhs at24 rzt2h_adc industrialio_adc sha256 cfg80211 bluetooth ecdh_generic ecc rfkill fuse drm backlight ipv6\n' +
      'CPU 0 UID 0 PID 0 Comm swapper/0 Not tainted 6.17.0-rc1+ #30 PREEMPT\n' +
      'Hardware name Renesas RZ/T2H EVK Board based on r9a09g077m44 (DT)\n' +
      'pstate 604000c5 (nZCv daIF +PAN -UAO -TCO -DIT -SSBS BTYPE=--)\n' +
      'pc  sci_serial_in+0x38/0xac\n' +
      'lr  sci_serial_in+0x38/0xac\n' +
      'sp  ffff800080003e80\n' +
      'x29 ffff800080003e80 x28 ffff800082195b80 x27 000000000000000d\n' +
      'x26 ffff8000821956d0 x25 0000000000000000 x24 ffff800082195b80\n' +
      'x23 ffff000180e0d800 x22 0000000000000010 x21 0000000000000000\n' +
      'x20 0000000000000010 x19 ffff000180e72000 x18 000000000000000a\n' +
      'x17 ffff8002bcee7000 x16 ffff800080000000 x15 0720072007200720\n' +
      'x14 0720072007200720 x13 0720072007200720 x12 0720072007200720\n' +
      'x11 0000000000000058 x10 0000000000000018 x9  ffff8000821a6a48\n' +
      'x8  0000000000057fa8 x7  0000000000000406 x6  ffff8000821fea48\n' +
      'x5  ffff00033ef88408 x4  ffff8002bcee7000 x3  ffff800082195b80\n' +
      'x2  0000000000000000 x1  0000000000000000 x0  ffff800082195b80\n' +
      'Call trace\n' +
      ' sci_serial_in+0x38/0xac (P)\n' +
      ' sci_handle_fifo_overrun.isra.0+0x70/0x134\n' +
      ' sci_er_interrupt+0x50/0x39c\n' +
      ' __handle_irq_event_percpu+0x48/0x140\n' +
      ' handle_irq_event+0x44/0xb0\n' +
      ' handle_fasteoi_irq+0xf4/0x1a0\n' +
      ' handle_irq_desc+0x34/0x58\n' +
      ' generic_handle_domain_irq+0x1c/0x28\n' +
      ' gic_handle_irq+0x4c/0x140\n' +
      ' call_on_irq_stack+0x30/0x48\n' +
      ' do_interrupt_handler+0x80/0x84\n' +
      ' el1_interrupt+0x34/0x68\n' +
      ' el1h_64_irq_handler+0x18/0x24\n' +
      ' el1h_64_irq+0x6c/0x70\n' +
      ' default_idle_call+0x28/0x58 (P)\n' +
      ' do_idle+0x1f8/0x250\n' +
      ' cpu_startup_entry+0x34/0x3c\n' +
      ' rest_init+0xd8/0xe0\n' +
      ' console_on_rootfs+0x0/0x6c\n' +
      ' __primary_switched+0x88/0x90\n' +
      '---[ end trace 0000000000000000 ]--- | Severity UNKNOWN',
    guid: 'CVE-2025-40222',
    isoDate: '2025-12-04T16:16:00.000Z'
  },
  {
    title: 'CVE-2025-40223 In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'most usb Fix use-after-free i...',
    link: 'https//nvd.nist.gov/vuln/detail/CVE-2025-40223',
    pubDate: 'Thu, 04 Dec 2025 16:16:00 GMT',
    content: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'most usb Fix use-after-free in hdm_disconnect\n' +
      '\n' +
      'hdm_disconnect() calls most_deregister_interface(), which eventually\n' +
      'unregisters the MOST interface device with device_unregister(iface->dev).\n' +
      'If that drops the last reference, the device core may call release_mdev()\n' +
      'immediately while hdm_disconnect() is still executing.\n' +
      '\n' +
      'The old code also freed several mdev-owned allocations in\n' +
      'hdm_disconnect() and then performed additional put_device() calls.\n' +
      'Depending on refcount order, this could lead to use-after-free or\n' +
      'double-free when release_mdev() ran (or when unregister paths also\n' +
      'performed puts).\n' +
      '\n' +
      'Fix by moving the frees of mdev-owned allocations into release_mdev(),\n' +
      'so they happen exactly once when the device is truly released, and by\n' +
      'dropping the extra put_device() calls in hdm_disconnect() that are\n' +
      'redundant after device_unregister() and most_deregister_interface().\n' +
      '\n' +
      'This addresses the KASAN slab-use-after-free reported by syzbot in\n' +
      'hdm_disconnect(). See report and stack traces in the bug link below. | Severity UNKNOWN  ',
    contentSnippet: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'most usb Fix use-after-free in hdm_disconnect\n' +
      '\n' +
      'hdm_disconnect() calls most_deregister_interface(), which eventually\n' +
      'unregisters the MOST interface device with device_unregister(iface->dev).\n' +
      'If that drops the last reference, the device core may call release_mdev()\n' +
      'immediately while hdm_disconnect() is still executing.\n' +
      '\n' +
      'The old code also freed several mdev-owned allocations in\n' +
      'hdm_disconnect() and then performed additional put_device() calls.\n' +
      'Depending on refcount order, this could lead to use-after-free or\n' +
      'double-free when release_mdev() ran (or when unregister paths also\n' +
      'performed puts).\n' +
      '\n' +
      'Fix by moving the frees of mdev-owned allocations into release_mdev(),\n' +
      'so they happen exactly once when the device is truly released, and by\n' +
      'dropping the extra put_device() calls in hdm_disconnect() that are\n' +
      'redundant after device_unregister() and most_deregister_interface().\n' +
      '\n' +
      'This addresses the KASAN slab-use-after-free reported by syzbot in\n' +
      'hdm_disconnect(). See report and stack traces in the bug link below. | Severity UNKNOWN',
    guid: 'CVE-2025-40223',
    isoDate: '2025-12-04T16:16:00.000Z'
  },
  {
    title: 'CVE-2025-40224 In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'hwmon (cgbc-hwmon) Add missing...',
    link: 'https//nvd.nist.gov/vuln/detail/CVE-2025-40224',
    pubDate: 'Thu, 04 Dec 2025 16:16:00 GMT',
    content: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'hwmon (cgbc-hwmon) Add missing NULL check after devm_kzalloc()\n' +
      '\n' +
      'The driver allocates memory for sensor data using devm_kzalloc(), but\n' +
      'did not check if the allocation succeeded. In case of memory allocation\n' +
      'failure, dereferencing the NULL pointer would lead to a kernel crash.\n' +
      '\n' +
      'Add a NULL pointer check and return -ENOMEM to handle allocation failure\n' +
      'properly. | Severity UNKNOWN  ',
    contentSnippet: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'hwmon (cgbc-hwmon) Add missing NULL check after devm_kzalloc()\n' +
      '\n' +
      'The driver allocates memory for sensor data using devm_kzalloc(), but\n' +
      'did not check if the allocation succeeded. In case of memory allocation\n' +
      'failure, dereferencing the NULL pointer would lead to a kernel crash.\n' +
      '\n' +
      'Add a NULL pointer check and return -ENOMEM to handle allocation failure\n' +
      'properly. | Severity UNKNOWN',
    guid: 'CVE-2025-40224',
    isoDate: '2025-12-04T16:16:00.000Z'
  },
  {
    title: 'CVE-2025-40225 In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'drm/panthor Fix kernel panic o...',
    link: 'https//nvd.nist.gov/vuln/detail/CVE-2025-40225',
    pubDate: 'Thu, 04 Dec 2025 16:16:00 GMT',
    content: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'drm/panthor Fix kernel panic on partial unmap of a GPU VA region\n' +
      '\n' +
      'This commit address a kernel panic issue that can happen if Userspace\n' +
      'tries to partially unmap a GPU virtual region (aka drm_gpuva).\n' +
      'The VM_BIND interface allows partial unmapping of a BO.\n' +
      '\n' +
      'Panthor driver pre-allocates memory for the new drm_gpuva structures\n' +
      'that would be needed for the map/unmap operation, done using drm_gpuvm\n' +
      'layer. It expected that only one new drm_gpuva would be needed on umap\n' +
      "but a partial unmap can require 2 new drm_gpuva and that's why it\n" +
      'ended up doing a NULL pointer dereference causing a kernel panic.\n' +
      '\n' +
      'Following dump was seen when partial unmap was exercised.\n' +
      ' Unable to handle kernel NULL pointer dereference at virtual address 0000000000000078\n' +
      ' Mem abort info\n' +
      '   ESR = 0x0000000096000046\n' +
      '   EC = 0x25 DABT (current EL), IL = 32 bits\n' +
      '   SET = 0, FnV = 0\n' +
      '   EA = 0, S1PTW = 0\n' +
      '   FSC = 0x06 level 2 translation fault\n' +
      ' Data abort info\n' +
      '   ISV = 0, ISS = 0x00000046, ISS2 = 0x00000000\n' +
      '   CM = 0, WnR = 1, TnD = 0, TagAccess = 0\n' +
      '   GCS = 0, Overlay = 0, DirtyBit = 0, Xs = 0\n' +
      ' user pgtable 4k pages, 48-bit VAs, pgdp=000000088a863000\n' +
      ' [000000000000078] pgd=080000088a842003, p4d=080000088a842003, pud=0800000884bf5003, pmd=0000000000000000\n' +
      ' Internal error Oops 0000000096000046 [#1] PREEMPT SMP\n' +
      ' snip>\n' +
      ' pstate 60000005 (nZCv daif -PAN -UAO -TCO -DIT -SSBS BTYPE=--)\n' +
      ' pc  panthor_gpuva_sm_step_remap+0xe4/0x330 [panthor]\n' +
      ' lr  panthor_gpuva_sm_step_remap+0x6c/0x330 [panthor]\n' +
      ' sp  ffff800085d43970\n' +
      ' x29 ffff800085d43970 x28 ffff00080363e440 x27 ffff0008090c6000\n' +
      ' x26 0000000000000030 x25 ffff800085d439f8 x24 ffff00080d402000\n' +
      ' x23 ffff800085d43b60 x22 ffff800085d439e0 x21 ffff00080abdb180\n' +
      ' x20 0000000000000000 x19 0000000000000000 x18 0000000000000010\n' +
      ' x17 6e656c202c303030 x16 3666666666646466 x15 393d61766f69202c\n' +
      ' x14 312d3d7361203a70 x13 303030323d6e656c x12 ffff80008324bf58\n' +
      ' x11 0000000000000003 x10 0000000000000002 x9  ffff8000801a6a9c\n' +
      ' x8  ffff00080360b300 x7  0000000000000000 x6  000000088aa35fc7\n' +
      ' x5  fff1000080000000 x4  ffff8000842ddd30 x3  0000000000000001\n' +
      ' x2  0000000100000000 x1  0000000000000001 x0  0000000000000078\n' +
      ' Call trace\n' +
      '  panthor_gpuva_sm_step_remap+0xe4/0x330 [panthor]\n' +
      '  op_remap_cb.isra.22+0x50/0x80\n' +
      '  __drm_gpuvm_sm_unmap+0x10c/0x1c8\n' +
      '  drm_gpuvm_sm_unmap+0x40/0x60\n' +
      '  panthor_vm_exec_op+0xb4/0x3d0 [panthor]\n' +
      '  panthor_vm_bind_exec_sync_op+0x154/0x278 [panthor]\n' +
      '  panthor_ioctl_vm_bind+0x160/0x4a0 [panthor]\n' +
      '  drm_ioctl_kernel+0xbc/0x138\n' +
      '  drm_ioctl+0x240/0x500\n' +
      '  __arm64_sys_ioctl+0xb0/0xf8\n' +
      '  invoke_syscall+0x4c/0x110\n' +
      '  el0_svc_common.constprop.1+0x98/0xf8\n' +
      '  do_el0_svc+0x24/0x38\n' +
      '  el0_svc+0x40/0xf8\n' +
      '  el0t_64_sync_handler+0xa0/0xc8\n' +
      '  el0t_64_sync+0x174/0x178 | Severity UNKNOWN  ',
    contentSnippet: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'drm/panthor Fix kernel panic on partial unmap of a GPU VA region\n' +
      '\n' +
      'This commit address a kernel panic issue that can happen if Userspace\n' +
      'tries to partially unmap a GPU virtual region (aka drm_gpuva).\n' +
      'The VM_BIND interface allows partial unmapping of a BO.\n' +
      '\n' +
      'Panthor driver pre-allocates memory for the new drm_gpuva structures\n' +
      'that would be needed for the map/unmap operation, done using drm_gpuvm\n' +
      'layer. It expected that only one new drm_gpuva would be needed on umap\n' +
      "but a partial unmap can require 2 new drm_gpuva and that's why it\n" +
      'ended up doing a NULL pointer dereference causing a kernel panic.\n' +
      '\n' +
      'Following dump was seen when partial unmap was exercised.\n' +
      ' Unable to handle kernel NULL pointer dereference at virtual address 0000000000000078\n' +
      ' Mem abort info\n' +
      '   ESR = 0x0000000096000046\n' +
      '   EC = 0x25 DABT (current EL), IL = 32 bits\n' +
      '   SET = 0, FnV = 0\n' +
      '   EA = 0, S1PTW = 0\n' +
      '   FSC = 0x06 level 2 translation fault\n' +
      ' Data abort info\n' +
      '   ISV = 0, ISS = 0x00000046, ISS2 = 0x00000000\n' +
      '   CM = 0, WnR = 1, TnD = 0, TagAccess = 0\n' +
      '   GCS = 0, Overlay = 0, DirtyBit = 0, Xs = 0\n' +
      ' user pgtable 4k pages, 48-bit VAs, pgdp=000000088a863000\n' +
      ' [000000000000078] pgd=080000088a842003, p4d=080000088a842003, pud=0800000884bf5003, pmd=0000000000000000\n' +
      ' Internal error Oops 0000000096000046 [#1] PREEMPT SMP\n' +
      ' snip>\n' +
      ' pstate 60000005 (nZCv daif -PAN -UAO -TCO -DIT -SSBS BTYPE=--)\n' +
      ' pc  panthor_gpuva_sm_step_remap+0xe4/0x330 [panthor]\n' +
      ' lr  panthor_gpuva_sm_step_remap+0x6c/0x330 [panthor]\n' +
      ' sp  ffff800085d43970\n' +
      ' x29 ffff800085d43970 x28 ffff00080363e440 x27 ffff0008090c6000\n' +
      ' x26 0000000000000030 x25 ffff800085d439f8 x24 ffff00080d402000\n' +
      ' x23 ffff800085d43b60 x22 ffff800085d439e0 x21 ffff00080abdb180\n' +
      ' x20 0000000000000000 x19 0000000000000000 x18 0000000000000010\n' +
      ' x17 6e656c202c303030 x16 3666666666646466 x15 393d61766f69202c\n' +
      ' x14 312d3d7361203a70 x13 303030323d6e656c x12 ffff80008324bf58\n' +
      ' x11 0000000000000003 x10 0000000000000002 x9  ffff8000801a6a9c\n' +
      ' x8  ffff00080360b300 x7  0000000000000000 x6  000000088aa35fc7\n' +
      ' x5  fff1000080000000 x4  ffff8000842ddd30 x3  0000000000000001\n' +
      ' x2  0000000100000000 x1  0000000000000001 x0  0000000000000078\n' +
      ' Call trace\n' +
      '  panthor_gpuva_sm_step_remap+0xe4/0x330 [panthor]\n' +
      '  op_remap_cb.isra.22+0x50/0x80\n' +
      '  __drm_gpuvm_sm_unmap+0x10c/0x1c8\n' +
      '  drm_gpuvm_sm_unmap+0x40/0x60\n' +
      '  panthor_vm_exec_op+0xb4/0x3d0 [panthor]\n' +
      '  panthor_vm_bind_exec_sync_op+0x154/0x278 [panthor]\n' +
      '  panthor_ioctl_vm_bind+0x160/0x4a0 [panthor]\n' +
      '  drm_ioctl_kernel+0xbc/0x138\n' +
      '  drm_ioctl+0x240/0x500\n' +
      '  __arm64_sys_ioctl+0xb0/0xf8\n' +
      '  invoke_syscall+0x4c/0x110\n' +
      '  el0_svc_common.constprop.1+0x98/0xf8\n' +
      '  do_el0_svc+0x24/0x38\n' +
      '  el0_svc+0x40/0xf8\n' +
      '  el0t_64_sync_handler+0xa0/0xc8\n' +
      '  el0t_64_sync+0x174/0x178 | Severity UNKNOWN',
    guid: 'CVE-2025-40225',
    isoDate: '2025-12-04T16:16:00.000Z'
  },
  {
    title: 'CVE-2025-40226 In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'firmware arm_scmi Account for...',
    link: 'https//nvd.nist.gov/vuln/detail/CVE-2025-40226',
    pubDate: 'Thu, 04 Dec 2025 16:16:00 GMT',
    content: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'firmware arm_scmi Account for failed debug initialization\n' +
      '\n' +
      'When the SCMI debug subsystem fails to initialize, the related debug root\n' +
      'will be missing, and the underlying descriptor will be NULL.\n' +
      '\n' +
      'Handle this fault condition in the SCMI debug helpers that maintain\n' +
      'metrics counters. | Severity UNKNOWN  ',
    contentSnippet: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'firmware arm_scmi Account for failed debug initialization\n' +
      '\n' +
      'When the SCMI debug subsystem fails to initialize, the related debug root\n' +
      'will be missing, and the underlying descriptor will be NULL.\n' +
      '\n' +
      'Handle this fault condition in the SCMI debug helpers that maintain\n' +
      'metrics counters. | Severity UNKNOWN',
    guid: 'CVE-2025-40226',
    isoDate: '2025-12-04T16:16:00.000Z'
  },
  {
    title: 'CVE-2025-40227 In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'mm/damon/sysfs dealloc commit ...',
    link: 'https//nvd.nist.gov/vuln/detail/CVE-2025-40227',
    pubDate: 'Thu, 04 Dec 2025 16:16:00 GMT',
    content: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'mm/damon/sysfs dealloc commit test ctx always\n' +
      '\n' +
      'The damon_ctx for testing online DAMON parameters commit inputs is\n' +
      'deallocated only when the test fails.  This means memory is leaked for\n' +
      'every successful online DAMON parameters commit.  Fix the leak by always\n' +
      'deallocating it. | Severity UNKNOWN  ',
    contentSnippet: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'mm/damon/sysfs dealloc commit test ctx always\n' +
      '\n' +
      'The damon_ctx for testing online DAMON parameters commit inputs is\n' +
      'deallocated only when the test fails.  This means memory is leaked for\n' +
      'every successful online DAMON parameters commit.  Fix the leak by always\n' +
      'deallocating it. | Severity UNKNOWN',
    guid: 'CVE-2025-40227',
    isoDate: '2025-12-04T16:16:00.000Z'
  },
  {
    title: 'CVE-2025-40228 In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'mm/damon/sysfs catch commit te...',
    link: 'https//nvd.nist.gov/vuln/detail/CVE-2025-40228',
    pubDate: 'Thu, 04 Dec 2025 16:16:00 GMT',
    content: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'mm/damon/sysfs catch commit test ctx alloc failure\n' +
      '\n' +
      'Patch series "mm/damon/sysfs fix commit test damon_ctx [de]allocation".\n' +
      '\n' +
      'DAMON sysfs interface dynamically allocates and uses a damon_ctx object\n' +
      'for testing if given inputs for online DAMON parameters update is valid.\n' +
      'The object is being used without an allocation failure check, and leaked\n' +
      'when the test succeeds.  Fix the two bugs.\n' +
      '\n' +
      '\n' +
      'This patch (of 2)\n' +
      '\n' +
      'The damon_ctx for testing online DAMON parameters commit inputs is used\n' +
      'without its allocation failure check.  This could result in an invalid\n' +
      'memory access.  Fix it by directly returning an error when the allocation\n' +
      'failed. | Severity UNKNOWN  ',
    contentSnippet: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'mm/damon/sysfs catch commit test ctx alloc failure\n' +
      '\n' +
      'Patch series "mm/damon/sysfs fix commit test damon_ctx [de]allocation".\n' +
      '\n' +
      'DAMON sysfs interface dynamically allocates and uses a damon_ctx object\n' +
      'for testing if given inputs for online DAMON parameters update is valid.\n' +
      'The object is being used without an allocation failure check, and leaked\n' +
      'when the test succeeds.  Fix the two bugs.\n' +
      '\n' +
      '\n' +
      'This patch (of 2)\n' +
      '\n' +
      'The damon_ctx for testing online DAMON parameters commit inputs is used\n' +
      'without its allocation failure check.  This could result in an invalid\n' +
      'memory access.  Fix it by directly returning an error when the allocation\n' +
      'failed. | Severity UNKNOWN',
    guid: 'CVE-2025-40228',
    isoDate: '2025-12-04T16:16:00.000Z'
  },
  {
    title: 'CVE-2025-40229 In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'mm/damon/core fix potential me...',
    link: 'https//nvd.nist.gov/vuln/detail/CVE-2025-40229',
    pubDate: 'Thu, 04 Dec 2025 16:16:00 GMT',
    content: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'mm/damon/core fix potential memory leak by cleaning ops_filter in damon_destroy_scheme\n' +
      '\n' +
      'Currently, damon_destroy_scheme() only cleans up the filter list but\n' +
      'leaves ops_filter untouched, which could lead to memory leaks when a\n' +
      'scheme is destroyed.\n' +
      '\n' +
      'This patch ensures both filter and ops_filter are properly freed in\n' +
      'damon_destroy_scheme(), preventing potential memory leaks. | Severity UNKNOWN  ',
    contentSnippet: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'mm/damon/core fix potential memory leak by cleaning ops_filter in damon_destroy_scheme\n' +
      '\n' +
      'Currently, damon_destroy_scheme() only cleans up the filter list but\n' +
      'leaves ops_filter untouched, which could lead to memory leaks when a\n' +
      'scheme is destroyed.\n' +
      '\n' +
      'This patch ensures both filter and ops_filter are properly freed in\n' +
      'damon_destroy_scheme(), preventing potential memory leaks. | Severity UNKNOWN',
    guid: 'CVE-2025-40229',
    isoDate: '2025-12-04T16:16:00.000Z'
  },
  {
    title: 'CVE-2025-40230 In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'mm prevent poison consumption ...',
    link: 'https//nvd.nist.gov/vuln/detail/CVE-2025-40230',
    pubDate: 'Thu, 04 Dec 2025 16:16:00 GMT',
    content: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'mm prevent poison consumption when splitting THP\n' +
      '\n' +
      'When performing memory error injection on a THP (Transparent Huge Page)\n' +
      'mapped to userspace on an x86 server, the kernel panics with the following\n' +
      'trace.  The expected behavior is to terminate the affected process instead\n' +
      'of panicking the kernel, as the x86 Machine Check code can recover from an\n' +
      'in-userspace #MC.\n' +
      '\n' +
      '  mce [Hardware Error] CPU 0 Machine Check Exception f Bank 3 bd80000000070134\n' +
      '  mce [Hardware Error] RIP 10ffffffff8372f8bc> {memchr_inv+0x4c/0xf0}\n' +
      '  mce [Hardware Error] TSC afff7bbff88a ADDR 1d301b000 MISC 80 PPIN 1e741e77539027db\n' +
      '  mce [Hardware Error] PROCESSOR 0d06d0 TIME 1758093249 SOCKET 0 APIC 0 microcode 80000320\n' +
      "  mce [Hardware Error] Run the above through 'mcelog --ascii'\n" +
      '  mce [Hardware Error] Machine check Data load in unrecoverable area of kernel\n' +
      '  Kernel panic - not syncing Fatal local machine check\n' +
      '\n' +
      'The root cause of this panic is that handling a memory failure triggered\n' +
      'by an in-userspace #MC necessitates splitting the THP.  The splitting\n' +
      'process employs a mechanism, implemented in\n' +
      'try_to_map_unused_to_zeropage(), which reads the pages in the THP to\n' +
      'identify zero-filled pages.  However, reading the pages in the THP results\n' +
      'in a second in-kernel #MC, occurring before the initial memory_failure()\n' +
      'completes, ultimately leading to a kernel panic.  See the kernel panic\n' +
      'call trace on the two #MCs.\n' +
      '\n' +
      '  First Machine Check occurs // [1]\n' +
      '    memory_failure()         // [2]\n' +
      '      try_to_split_thp_page()\n' +
      '        split_huge_page()\n' +
      '          split_huge_page_to_list_to_order()\n' +
      '            __folio_split()  // [3]\n' +
      '              remap_page()\n' +
      '                remove_migration_ptes()\n' +
      '                  remove_migration_pte()\n' +
      '                    try_to_map_unused_to_zeropage()  // [4]\n' +
      '                      memchr_inv()                   // [5]\n' +
      '                        Second Machine Check occurs  // [6]\n' +
      '                          Kernel panic\n' +
      '\n' +
      '[1] Triggered by accessing a hardware-poisoned THP in userspace, which is\n' +
      '    typically recoverable by terminating the affected process.\n' +
      '\n' +
      '[2] Call folio_set_has_hwpoisoned() before try_to_split_thp_page().\n' +
      '\n' +
      '[3] Pass the RMP_USE_SHARED_ZEROPAGE remap flag to remap_page().\n' +
      '\n' +
      '[4] Try to map the unused THP to zeropage.\n' +
      '\n' +
      '[5] Re-access pages in the hw-poisoned THP in the kernel.\n' +
      '\n' +
      '[6] Triggered in-kernel, leading to a panic kernel.\n' +
      '\n' +
      'In Step[2], memory_failure() sets the poisoned flag on the page in the THP\n' +
      'by TestSetPageHWPoison() before calling try_to_split_thp_page().\n' +
      '\n' +
      'As suggested by David Hildenbrand, fix this panic by not accessing to the\n' +
      'poisoned page in the THP during zeropage identification, while continuing\n' +
      'to scan unaffected pages in the THP for possible zeropage mapping.  This\n' +
      'prevents a second in-kernel #MC that would cause kernel panic in Step[4].\n' +
      '\n' +
      'Thanks to Andrew Zaborowski for his initial work on fixing this issue. | Severity UNKNOWN  ',
    contentSnippet: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'mm prevent poison consumption when splitting THP\n' +
      '\n' +
      'When performing memory error injection on a THP (Transparent Huge Page)\n' +
      'mapped to userspace on an x86 server, the kernel panics with the following\n' +
      'trace.  The expected behavior is to terminate the affected process instead\n' +
      'of panicking the kernel, as the x86 Machine Check code can recover from an\n' +
      'in-userspace #MC.\n' +
      '\n' +
      '  mce [Hardware Error] CPU 0 Machine Check Exception f Bank 3 bd80000000070134\n' +
      '  mce [Hardware Error] RIP 10ffffffff8372f8bc> {memchr_inv+0x4c/0xf0}\n' +
      '  mce [Hardware Error] TSC afff7bbff88a ADDR 1d301b000 MISC 80 PPIN 1e741e77539027db\n' +
      '  mce [Hardware Error] PROCESSOR 0d06d0 TIME 1758093249 SOCKET 0 APIC 0 microcode 80000320\n' +
      "  mce [Hardware Error] Run the above through 'mcelog --ascii'\n" +
      '  mce [Hardware Error] Machine check Data load in unrecoverable area of kernel\n' +
      '  Kernel panic - not syncing Fatal local machine check\n' +
      '\n' +
      'The root cause of this panic is that handling a memory failure triggered\n' +
      'by an in-userspace #MC necessitates splitting the THP.  The splitting\n' +
      'process employs a mechanism, implemented in\n' +
      'try_to_map_unused_to_zeropage(), which reads the pages in the THP to\n' +
      'identify zero-filled pages.  However, reading the pages in the THP results\n' +
      'in a second in-kernel #MC, occurring before the initial memory_failure()\n' +
      'completes, ultimately leading to a kernel panic.  See the kernel panic\n' +
      'call trace on the two #MCs.\n' +
      '\n' +
      '  First Machine Check occurs // [1]\n' +
      '    memory_failure()         // [2]\n' +
      '      try_to_split_thp_page()\n' +
      '        split_huge_page()\n' +
      '          split_huge_page_to_list_to_order()\n' +
      '            __folio_split()  // [3]\n' +
      '              remap_page()\n' +
      '                remove_migration_ptes()\n' +
      '                  remove_migration_pte()\n' +
      '                    try_to_map_unused_to_zeropage()  // [4]\n' +
      '                      memchr_inv()                   // [5]\n' +
      '                        Second Machine Check occurs  // [6]\n' +
      '                          Kernel panic\n' +
      '\n' +
      '[1] Triggered by accessing a hardware-poisoned THP in userspace, which is\n' +
      '    typically recoverable by terminating the affected process.\n' +
      '\n' +
      '[2] Call folio_set_has_hwpoisoned() before try_to_split_thp_page().\n' +
      '\n' +
      '[3] Pass the RMP_USE_SHARED_ZEROPAGE remap flag to remap_page().\n' +
      '\n' +
      '[4] Try to map the unused THP to zeropage.\n' +
      '\n' +
      '[5] Re-access pages in the hw-poisoned THP in the kernel.\n' +
      '\n' +
      '[6] Triggered in-kernel, leading to a panic kernel.\n' +
      '\n' +
      'In Step[2], memory_failure() sets the poisoned flag on the page in the THP\n' +
      'by TestSetPageHWPoison() before calling try_to_split_thp_page().\n' +
      '\n' +
      'As suggested by David Hildenbrand, fix this panic by not accessing to the\n' +
      'poisoned page in the THP during zeropage identification, while continuing\n' +
      'to scan unaffected pages in the THP for possible zeropage mapping.  This\n' +
      'prevents a second in-kernel #MC that would cause kernel panic in Step[4].\n' +
      '\n' +
      'Thanks to Andrew Zaborowski for his initial work on fixing this issue. | Severity UNKNOWN',
    guid: 'CVE-2025-40230',
    isoDate: '2025-12-04T16:16:00.000Z'
  },
  {
    title: 'CVE-2025-40231 In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'vsock fix lock inversion in vs...',
    link: 'https//nvd.nist.gov/vuln/detail/CVE-2025-40231',
    pubDate: 'Thu, 04 Dec 2025 16:16:00 GMT',
    content: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'vsock fix lock inversion in vsock_assign_transport()\n' +
      '\n' +
      'Syzbot reported a potential lock inversion deadlock between\n' +
      'vsock_register_mutex and sk_lock-AF_VSOCK when vsock_linger() is called.\n' +
      '\n' +
      'The issue was introduced by commit 687aa0c5581b ("vsock Fix\n' +
      'transport_* TOCTOU") which added vsock_register_mutex locking in\n' +
      'vsock_assign_transport() around the transport->release() call, that can\n' +
      'call vsock_linger(). vsock_assign_transport() can be called with sk_lock\n' +
      'held. vsock_linger() calls sk_wait_event() that temporarily releases and\n' +
      're-acquires sk_lock. During this window, if another thread hold\n' +
      'vsock_register_mutex while trying to acquire sk_lock, a circular\n' +
      'dependency is created.\n' +
      '\n' +
      'Fix this by releasing vsock_register_mutex before calling\n' +
      'transport->release() and vsock_deassign_transport(). This is safe\n' +
      "because we don't need to hold vsock_register_mutex while releasing the\n" +
      "old transport, and we ensure the new transport won't disappear by\n" +
      'obtaining a module reference first via try_module_get(). | Severity UNKNOWN  ',
    contentSnippet: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'vsock fix lock inversion in vsock_assign_transport()\n' +
      '\n' +
      'Syzbot reported a potential lock inversion deadlock between\n' +
      'vsock_register_mutex and sk_lock-AF_VSOCK when vsock_linger() is called.\n' +
      '\n' +
      'The issue was introduced by commit 687aa0c5581b ("vsock Fix\n' +
      'transport_* TOCTOU") which added vsock_register_mutex locking in\n' +
      'vsock_assign_transport() around the transport->release() call, that can\n' +
      'call vsock_linger(). vsock_assign_transport() can be called with sk_lock\n' +
      'held. vsock_linger() calls sk_wait_event() that temporarily releases and\n' +
      're-acquires sk_lock. During this window, if another thread hold\n' +
      'vsock_register_mutex while trying to acquire sk_lock, a circular\n' +
      'dependency is created.\n' +
      '\n' +
      'Fix this by releasing vsock_register_mutex before calling\n' +
      'transport->release() and vsock_deassign_transport(). This is safe\n' +
      "because we don't need to hold vsock_register_mutex while releasing the\n" +
      "old transport, and we ensure the new transport won't disappear by\n" +
      'obtaining a module reference first via try_module_get(). | Severity UNKNOWN',
    guid: 'CVE-2025-40231',
    isoDate: '2025-12-04T16:16:00.000Z'
  },
  {
    title: 'CVE-2025-40232 In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'rv Fully convert enabled_monit...',
    link: 'https//nvd.nist.gov/vuln/detail/CVE-2025-40232',
    pubDate: 'Thu, 04 Dec 2025 16:16:00 GMT',
    content: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'rv Fully convert enabled_monitors to use list_head as iterator\n' +
      '\n' +
      'The callbacks in enabled_monitors_seq_ops are inconsistent. Some treat the\n' +
      'iterator as struct rv_monitor *, while others treat the iterator as struct\n' +
      'list_head *.\n' +
      '\n' +
      'This causes a wrong type cast and crashes the system as reported by Nathan.\n' +
      '\n' +
      'Convert everything to use struct list_head * as iterator. This also makes\n' +
      'enabled_monitors consistent with available_monitors. | Severity UNKNOWN  ',
    contentSnippet: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'rv Fully convert enabled_monitors to use list_head as iterator\n' +
      '\n' +
      'The callbacks in enabled_monitors_seq_ops are inconsistent. Some treat the\n' +
      'iterator as struct rv_monitor *, while others treat the iterator as struct\n' +
      'list_head *.\n' +
      '\n' +
      'This causes a wrong type cast and crashes the system as reported by Nathan.\n' +
      '\n' +
      'Convert everything to use struct list_head * as iterator. This also makes\n' +
      'enabled_monitors consistent with available_monitors. | Severity UNKNOWN',
    guid: 'CVE-2025-40232',
    isoDate: '2025-12-04T16:16:00.000Z'
  },
  {
    title: 'CVE-2025-40233 In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'ocfs2 clear extent cache after...',
    link: 'https//nvd.nist.gov/vuln/detail/CVE-2025-40233',
    pubDate: 'Thu, 04 Dec 2025 16:16:00 GMT',
    content: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'ocfs2 clear extent cache after moving/defragmenting extents\n' +
      '\n' +
      'The extent map cache can become stale when extents are moved or\n' +
      'defragmented, causing subsequent operations to see outdated extent flags. \n' +
      'This triggers a BUG_ON in ocfs2_refcount_cal_cow_clusters().\n' +
      '\n' +
      'The problem occurs when\n' +
      '1. copy_file_range() creates a reflinked extent with OCFS2_EXT_REFCOUNTED\n' +
      '2. ioctl(FITRIM) triggers ocfs2_move_extents()\n' +
      '3. __ocfs2_move_extents_range() reads and caches the extent (flags=0x2)\n' +
      '4. ocfs2_move_extent()/ocfs2_defrag_extent() calls __ocfs2_move_extent()\n' +
      '   which clears OCFS2_EXT_REFCOUNTED flag on disk (flags=0x0)\n' +
      '5. The extent map cache is not invalidated after the move\n' +
      '6. Later write() operations read stale cached flags (0x2) but disk has\n' +
      '   updated flags (0x0), causing a mismatch\n' +
      '7. BUG_ON(!(rec->e_flags  OCFS2_EXT_REFCOUNTED)) triggers\n' +
      '\n' +
      'Fix by clearing the extent map cache after each extent move/defrag\n' +
      'operation in __ocfs2_move_extents_range().  This ensures subsequent\n' +
      'operations read fresh extent data from disk. | Severity UNKNOWN  ',
    contentSnippet: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'ocfs2 clear extent cache after moving/defragmenting extents\n' +
      '\n' +
      'The extent map cache can become stale when extents are moved or\n' +
      'defragmented, causing subsequent operations to see outdated extent flags. \n' +
      'This triggers a BUG_ON in ocfs2_refcount_cal_cow_clusters().\n' +
      '\n' +
      'The problem occurs when\n' +
      '1. copy_file_range() creates a reflinked extent with OCFS2_EXT_REFCOUNTED\n' +
      '2. ioctl(FITRIM) triggers ocfs2_move_extents()\n' +
      '3. __ocfs2_move_extents_range() reads and caches the extent (flags=0x2)\n' +
      '4. ocfs2_move_extent()/ocfs2_defrag_extent() calls __ocfs2_move_extent()\n' +
      '   which clears OCFS2_EXT_REFCOUNTED flag on disk (flags=0x0)\n' +
      '5. The extent map cache is not invalidated after the move\n' +
      '6. Later write() operations read stale cached flags (0x2) but disk has\n' +
      '   updated flags (0x0), causing a mismatch\n' +
      '7. BUG_ON(!(rec->e_flags  OCFS2_EXT_REFCOUNTED)) triggers\n' +
      '\n' +
      'Fix by clearing the extent map cache after each extent move/defrag\n' +
      'operation in __ocfs2_move_extents_range().  This ensures subsequent\n' +
      'operations read fresh extent data from disk. | Severity UNKNOWN',
    guid: 'CVE-2025-40233',
    isoDate: '2025-12-04T16:16:00.000Z'
  },
  {
    title: 'CVE-2025-40234 In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'platform/x86 alienware-wmi-wma...',
    link: 'https//nvd.nist.gov/vuln/detail/CVE-2025-40234',
    pubDate: 'Thu, 04 Dec 2025 16:16:00 GMT',
    content: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'platform/x86 alienware-wmi-wmax Fix NULL pointer dereference in sleep handlers\n' +
      '\n' +
      "Devices without the AWCC interface don't initialize `awcc`. Add a check\n" +
      'before dereferencing it in sleep handlers. | Severity UNKNOWN  ',
    contentSnippet: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'platform/x86 alienware-wmi-wmax Fix NULL pointer dereference in sleep handlers\n' +
      '\n' +
      "Devices without the AWCC interface don't initialize `awcc`. Add a check\n" +
      'before dereferencing it in sleep handlers. | Severity UNKNOWN',
    guid: 'CVE-2025-40234',
    isoDate: '2025-12-04T16:16:00.000Z'
  },
  {
    title: 'CVE-2025-40235 In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'btrfs directly free partially ...',
    link: 'https//nvd.nist.gov/vuln/detail/CVE-2025-40235',
    pubDate: 'Thu, 04 Dec 2025 16:16:00 GMT',
    content: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'btrfs directly free partially initialized fs_info in btrfs_check_leaked_roots()\n' +
      '\n' +
      'If fs_info->super_copy or fs_info->super_for_commit allocated failed in\n' +
      'btrfs_get_tree_subvol(), then no need to call btrfs_free_fs_info().\n' +
      'Otherwise btrfs_check_leaked_roots() would access NULL pointer because\n' +
      'fs_info->allocated_roots had not been initialised.\n' +
      '\n' +
      'syzkaller reported the following information\n' +
      '  ------------[ cut here ]------------\n' +
      '  BUG unable to handle page fault for address fffffffffffffbb0\n' +
      '  #PF supervisor read access in kernel mode\n' +
      '  #PF error_code(0x0000) - not-present page\n' +
      '  PGD 64c9067 P4D 64c9067 PUD 64cb067 PMD 0\n' +
      '  Oops Oops 0000 [#1] SMP KASAN PTI\n' +
      '  CPU 0 UID 0 PID 1402 Comm syz.1.35 Not tainted 6.15.8 #4 PREEMPT(lazy)\n' +
      '  Hardware name QEMU Standard PC (i440FX + PIIX, 1996), (...)\n' +
      '  RIP 0010arch_atomic_read arch/x86/include/asm/atomic.h23 [inline]\n' +
      '  RIP 0010raw_atomic_read include/linux/atomic/atomic-arch-fallback.h457 [inline]\n' +
      '  RIP 0010atomic_read include/linux/atomic/atomic-instrumented.h33 [inline]\n' +
      '  RIP 0010refcount_read include/linux/refcount.h170 [inline]\n' +
      '  RIP 0010btrfs_check_leaked_roots+0x18f/0x2c0 fs/btrfs/disk-io.c1230\n' +
      '  [...]\n' +
      '  Call Trace\n' +
      '   TASK>\n' +
      '   btrfs_free_fs_info+0x310/0x410 fs/btrfs/disk-io.c1280\n' +
      '   btrfs_get_tree_subvol+0x592/0x6b0 fs/btrfs/super.c2029\n' +
      '   btrfs_get_tree+0x63/0x80 fs/btrfs/super.c2097\n' +
      '   vfs_get_tree+0x98/0x320 fs/super.c1759\n' +
      '   do_new_mount+0x357/0x660 fs/namespace.c3899\n' +
      '   path_mount+0x716/0x19c0 fs/namespace.c4226\n' +
      '   do_mount fs/namespace.c4239 [inline]\n' +
      '   __do_sys_mount fs/namespace.c4450 [inline]\n' +
      '   __se_sys_mount fs/namespace.c4427 [inline]\n' +
      '   __x64_sys_mount+0x28c/0x310 fs/namespace.c4427\n' +
      '   do_syscall_x64 arch/x86/entry/syscall_64.c63 [inline]\n' +
      '   do_syscall_64+0x92/0x180 arch/x86/entry/syscall_64.c94\n' +
      '   entry_SYSCALL_64_after_hwframe+0x76/0x7e\n' +
      '  RIP 00330x7f032eaffa8d\n' +
      '  [...] | Severity UNKNOWN  ',
    contentSnippet: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'btrfs directly free partially initialized fs_info in btrfs_check_leaked_roots()\n' +
      '\n' +
      'If fs_info->super_copy or fs_info->super_for_commit allocated failed in\n' +
      'btrfs_get_tree_subvol(), then no need to call btrfs_free_fs_info().\n' +
      'Otherwise btrfs_check_leaked_roots() would access NULL pointer because\n' +
      'fs_info->allocated_roots had not been initialised.\n' +
      '\n' +
      'syzkaller reported the following information\n' +
      '  ------------[ cut here ]------------\n' +
      '  BUG unable to handle page fault for address fffffffffffffbb0\n' +
      '  #PF supervisor read access in kernel mode\n' +
      '  #PF error_code(0x0000) - not-present page\n' +
      '  PGD 64c9067 P4D 64c9067 PUD 64cb067 PMD 0\n' +
      '  Oops Oops 0000 [#1] SMP KASAN PTI\n' +
      '  CPU 0 UID 0 PID 1402 Comm syz.1.35 Not tainted 6.15.8 #4 PREEMPT(lazy)\n' +
      '  Hardware name QEMU Standard PC (i440FX + PIIX, 1996), (...)\n' +
      '  RIP 0010arch_atomic_read arch/x86/include/asm/atomic.h23 [inline]\n' +
      '  RIP 0010raw_atomic_read include/linux/atomic/atomic-arch-fallback.h457 [inline]\n' +
      '  RIP 0010atomic_read include/linux/atomic/atomic-instrumented.h33 [inline]\n' +
      '  RIP 0010refcount_read include/linux/refcount.h170 [inline]\n' +
      '  RIP 0010btrfs_check_leaked_roots+0x18f/0x2c0 fs/btrfs/disk-io.c1230\n' +
      '  [...]\n' +
      '  Call Trace\n' +
      '   TASK>\n' +
      '   btrfs_free_fs_info+0x310/0x410 fs/btrfs/disk-io.c1280\n' +
      '   btrfs_get_tree_subvol+0x592/0x6b0 fs/btrfs/super.c2029\n' +
      '   btrfs_get_tree+0x63/0x80 fs/btrfs/super.c2097\n' +
      '   vfs_get_tree+0x98/0x320 fs/super.c1759\n' +
      '   do_new_mount+0x357/0x660 fs/namespace.c3899\n' +
      '   path_mount+0x716/0x19c0 fs/namespace.c4226\n' +
      '   do_mount fs/namespace.c4239 [inline]\n' +
      '   __do_sys_mount fs/namespace.c4450 [inline]\n' +
      '   __se_sys_mount fs/namespace.c4427 [inline]\n' +
      '   __x64_sys_mount+0x28c/0x310 fs/namespace.c4427\n' +
      '   do_syscall_x64 arch/x86/entry/syscall_64.c63 [inline]\n' +
      '   do_syscall_64+0x92/0x180 arch/x86/entry/syscall_64.c94\n' +
      '   entry_SYSCALL_64_after_hwframe+0x76/0x7e\n' +
      '  RIP 00330x7f032eaffa8d\n' +
      '  [...] | Severity UNKNOWN',
    guid: 'CVE-2025-40235',
    isoDate: '2025-12-04T16:16:00.000Z'
  },
  {
    title: 'CVE-2025-40236 In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'virtio-net zero unused hash fi...',
    link: 'https//nvd.nist.gov/vuln/detail/CVE-2025-40236',
    pubDate: 'Thu, 04 Dec 2025 16:16:00 GMT',
    content: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'virtio-net zero unused hash fields\n' +
      '\n' +
      'When GSO tunnel is negotiated virtio_net_hdr_tnl_from_skb() tries to\n' +
      'initialize the tunnel metadata but forget to zero unused rxhash\n' +
      'fields. This may leak information to another side. Fixing this by\n' +
      'zeroing the unused hash fields. | Severity UNKNOWN  ',
    contentSnippet: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'virtio-net zero unused hash fields\n' +
      '\n' +
      'When GSO tunnel is negotiated virtio_net_hdr_tnl_from_skb() tries to\n' +
      'initialize the tunnel metadata but forget to zero unused rxhash\n' +
      'fields. This may leak information to another side. Fixing this by\n' +
      'zeroing the unused hash fields. | Severity UNKNOWN',
    guid: 'CVE-2025-40236',
    isoDate: '2025-12-04T16:16:00.000Z'
  },
  {
    title: 'CVE-2025-40237 In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'fs/notify call exportfs_encode...',
    link: 'https//nvd.nist.gov/vuln/detail/CVE-2025-40237',
    pubDate: 'Thu, 04 Dec 2025 16:16:00 GMT',
    content: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'fs/notify call exportfs_encode_fid with s_umount\n' +
      '\n' +
      'Calling intotify_show_fdinfo() on fd watching an overlayfs inode, while\n' +
      'the overlayfs is being unmounted, can lead to dereferencing NULL ptr.\n' +
      '\n' +
      'This issue was found by syzkaller.\n' +
      '\n' +
      'Race Condition Diagram\n' +
      '\n' +
      'Thread 1                           Thread 2\n' +
      '--------                           --------\n' +
      '\n' +
      'generic_shutdown_super()\n' +
      ' shrink_dcache_for_umount\n' +
      '  sb->s_root = NULL\n' +
      '\n' +
      '                    |\n' +
      '                    |             vfs_read()\n' +
      '                    |              inotify_fdinfo()\n' +
      '                    |               * inode get from mark *\n' +
      '                    |               show_mark_fhandle(m, inode)\n' +
      '                    |                exportfs_encode_fid(inode, ..)\n' +
      '                    |                 ovl_encode_fh(inode, ..)\n' +
      '                    |                  ovl_check_encode_origin(inode)\n' +
      '                    |                   * deref i_sb->s_root *\n' +
      '                    |\n' +
      '                    |\n' +
      '                    v\n' +
      ' fsnotify_sb_delete(sb)\n' +
      '\n' +
      'Which then leads to\n' +
      '\n' +
      '[   32.133461] Oops general protection fault, probably for non-canonical address 0xdffffc0000000006 0000 [#1] SMP DEBUG_PAGEALLOC KASAN NOPTI\n' +
      '[   32.134438] KASAN null-ptr-deref in range [0x0000000000000030-0x0000000000000037]\n' +
      '[   32.135032] CPU 1 UID 0 PID 4468 Comm systemd-coredum Not tainted 6.17.0-rc6 #22 PREEMPT(none)\n' +
      '\n' +
      'snip registers, unreliable trace>\n' +
      '\n' +
      '[   32.143353] Call Trace\n' +
      '[   32.143732]  ovl_encode_fh+0xd5/0x170\n' +
      '[   32.144031]  exportfs_encode_inode_fh+0x12f/0x300\n' +
      '[   32.144425]  show_mark_fhandle+0xbe/0x1f0\n' +
      '[   32.145805]  inotify_fdinfo+0x226/0x2d0\n' +
      '[   32.146442]  inotify_show_fdinfo+0x1c5/0x350\n' +
      '[   32.147168]  seq_show+0x530/0x6f0\n' +
      '[   32.147449]  seq_read_iter+0x503/0x12a0\n' +
      '[   32.148419]  seq_read+0x31f/0x410\n' +
      '[   32.150714]  vfs_read+0x1f0/0x9e0\n' +
      '[   32.152297]  ksys_read+0x125/0x240\n' +
      '\n' +
      'IOW ovl_check_encode_origin derefs inode->i_sb->s_root, after it was set\n' +
      'to NULL in the unmount path.\n' +
      '\n' +
      'Fix it by protecting calling exportfs_encode_fid() from\n' +
      'show_mark_fhandle() with s_umount lock.\n' +
      '\n' +
      'This form of fix was suggested by Amir in [1].\n' +
      '\n' +
      '[1] https//lore.kernel.org/all/CAOQ4uxhbDwhb+2Brs1UdkoF0a3NSdBAOQPNfEHjahrgoKJpLEw@mail.gmail.com/ | Severity UNKNOWN  ',
    contentSnippet: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'fs/notify call exportfs_encode_fid with s_umount\n' +
      '\n' +
      'Calling intotify_show_fdinfo() on fd watching an overlayfs inode, while\n' +
      'the overlayfs is being unmounted, can lead to dereferencing NULL ptr.\n' +
      '\n' +
      'This issue was found by syzkaller.\n' +
      '\n' +
      'Race Condition Diagram\n' +
      '\n' +
      'Thread 1                           Thread 2\n' +
      '--------                           --------\n' +
      '\n' +
      'generic_shutdown_super()\n' +
      ' shrink_dcache_for_umount\n' +
      '  sb->s_root = NULL\n' +
      '\n' +
      '                    |\n' +
      '                    |             vfs_read()\n' +
      '                    |              inotify_fdinfo()\n' +
      '                    |               * inode get from mark *\n' +
      '                    |               show_mark_fhandle(m, inode)\n' +
      '                    |                exportfs_encode_fid(inode, ..)\n' +
      '                    |                 ovl_encode_fh(inode, ..)\n' +
      '                    |                  ovl_check_encode_origin(inode)\n' +
      '                    |                   * deref i_sb->s_root *\n' +
      '                    |\n' +
      '                    |\n' +
      '                    v\n' +
      ' fsnotify_sb_delete(sb)\n' +
      '\n' +
      'Which then leads to\n' +
      '\n' +
      '[   32.133461] Oops general protection fault, probably for non-canonical address 0xdffffc0000000006 0000 [#1] SMP DEBUG_PAGEALLOC KASAN NOPTI\n' +
      '[   32.134438] KASAN null-ptr-deref in range [0x0000000000000030-0x0000000000000037]\n' +
      '[   32.135032] CPU 1 UID 0 PID 4468 Comm systemd-coredum Not tainted 6.17.0-rc6 #22 PREEMPT(none)\n' +
      '\n' +
      'snip registers, unreliable trace>\n' +
      '\n' +
      '[   32.143353] Call Trace\n' +
      '[   32.143732]  ovl_encode_fh+0xd5/0x170\n' +
      '[   32.144031]  exportfs_encode_inode_fh+0x12f/0x300\n' +
      '[   32.144425]  show_mark_fhandle+0xbe/0x1f0\n' +
      '[   32.145805]  inotify_fdinfo+0x226/0x2d0\n' +
      '[   32.146442]  inotify_show_fdinfo+0x1c5/0x350\n' +
      '[   32.147168]  seq_show+0x530/0x6f0\n' +
      '[   32.147449]  seq_read_iter+0x503/0x12a0\n' +
      '[   32.148419]  seq_read+0x31f/0x410\n' +
      '[   32.150714]  vfs_read+0x1f0/0x9e0\n' +
      '[   32.152297]  ksys_read+0x125/0x240\n' +
      '\n' +
      'IOW ovl_check_encode_origin derefs inode->i_sb->s_root, after it was set\n' +
      'to NULL in the unmount path.\n' +
      '\n' +
      'Fix it by protecting calling exportfs_encode_fid() from\n' +
      'show_mark_fhandle() with s_umount lock.\n' +
      '\n' +
      'This form of fix was suggested by Amir in [1].\n' +
      '\n' +
      '[1] https//lore.kernel.org/all/CAOQ4uxhbDwhb+2Brs1UdkoF0a3NSdBAOQPNfEHjahrgoKJpLEw@mail.gmail.com/ | Severity UNKNOWN',
    guid: 'CVE-2025-40237',
    isoDate: '2025-12-04T16:16:00.000Z'
  },
  {
    title: 'CVE-2025-40238 In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'net/mlx5 Fix IPsec cleanup ove...',
    link: 'https//nvd.nist.gov/vuln/detail/CVE-2025-40238',
    pubDate: 'Thu, 04 Dec 2025 16:16:00 GMT',
    content: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'net/mlx5 Fix IPsec cleanup over MPV device\n' +
      '\n' +
      'When we do mlx5e_detach_netdev() we eventually disable blocking events\n' +
      'notifier, among those events are IPsec MPV events from IB to core.\n' +
      '\n' +
      'So before disabling those blocking events, make sure to also unregister\n' +
      'the devcom device and mark all this device operations as complete,\n' +
      'in order to prevent the other device from using invalid netdev\n' +
      'during future devcom events which could cause the trace below.\n' +
      '\n' +
      'BUG kernel NULL pointer dereference, address 0000000000000010\n' +
      'PGD 146427067 P4D 146427067 PUD 146488067 PMD 0\n' +
      'Oops Oops 0000 [#1] SMP\n' +
      'CPU 1 UID 0 PID 7735 Comm devlink Tainted GW 6.12.0-rc6_for_upstream_min_debug_2024_11_08_00_46 #1\n' +
      'Tainted [W]=WARN\n' +
      'Hardware name QEMU Standard PC (Q35 + ICH9, 2009), BIOS rel-1.13.0-0-gf21b5a4aeb02-prebuilt.qemu.org 04/01/2014\n' +
      'RIP 0010mlx5_devcom_comp_set_ready+0x5/0x40 [mlx5_core]\n' +
      'Code 00 01 48 83 05 23 32 1e 00 01 41 b8 ed ff ff ff e9 60 ff ff ff 48 83 05 00 32 1e 00 01 eb e3 66 0f 1f 44 00 00 0f 1f 44 00 00 48> 8b 47 10 48 83 05 5f 32 1e 00 01 48 8b 50 40 48 85 d2 74 05 40\n' +
      'RSP 0018ffff88811a5c35f8 EFLAGS 00010206\n' +
      'RAX ffff888106e8ab80 RBX ffff888107d7e200 RCX ffff88810d6f0a00\n' +
      'RDX ffff88810d6f0a00 RSI 0000000000000001 RDI 0000000000000000\n' +
      'RBP ffff88811a17e620 R08 0000000000000040 R09 0000000000000000\n' +
      'R10 ffff88811a5c3618 R11 0000000de85d51bd R12 ffff88811a17e600\n' +
      'R13 ffff88810d6f0a00 R14 0000000000000000 R15 ffff8881034bda80\n' +
      'FS  00007f27bdf89180(0000) GSffff88852c880000(0000) knlGS0000000000000000\n' +
      'CS  0010 DS 0000 ES 0000 CR0 0000000080050033\n' +
      'CR2 0000000000000010 CR3 000000010f159005 CR4 0000000000372eb0\n' +
      'DR0 0000000000000000 DR1 0000000000000000 DR2 0000000000000000\n' +
      'DR3 0000000000000000 DR6 00000000fffe0ff0 DR7 0000000000000400\n' +
      'Call Trace\n' +
      ' TASK>\n' +
      ' ? __die+0x20/0x60\n' +
      ' ? page_fault_oops+0x150/0x3e0\n' +
      ' ? exc_page_fault+0x74/0x130\n' +
      ' ? asm_exc_page_fault+0x22/0x30\n' +
      ' ? mlx5_devcom_comp_set_ready+0x5/0x40 [mlx5_core]\n' +
      ' mlx5e_devcom_event_mpv+0x42/0x60 [mlx5_core]\n' +
      ' mlx5_devcom_send_event+0x8c/0x170 [mlx5_core]\n' +
      ' blocking_event+0x17b/0x230 [mlx5_core]\n' +
      ' notifier_call_chain+0x35/0xa0\n' +
      ' blocking_notifier_call_chain+0x3d/0x60\n' +
      ' mlx5_blocking_notifier_call_chain+0x22/0x30 [mlx5_core]\n' +
      ' mlx5_core_mp_event_replay+0x12/0x20 [mlx5_core]\n' +
      ' mlx5_ib_bind_slave_port+0x228/0x2c0 [mlx5_ib]\n' +
      ' mlx5_ib_stage_init_init+0x664/0x9d0 [mlx5_ib]\n' +
      ' ? idr_alloc_cyclic+0x50/0xb0\n' +
      ' ? __kmalloc_cache_noprof+0x167/0x340\n' +
      ' ? __kmalloc_noprof+0x1a7/0x430\n' +
      ' __mlx5_ib_add+0x34/0xd0 [mlx5_ib]\n' +
      ' mlx5r_probe+0xe9/0x310 [mlx5_ib]\n' +
      ' ? kernfs_add_one+0x107/0x150\n' +
      ' ? __mlx5_ib_add+0xd0/0xd0 [mlx5_ib]\n' +
      ' auxiliary_bus_probe+0x3e/0x90\n' +
      ' really_probe+0xc5/0x3a0\n' +
      ' ? driver_probe_device+0x90/0x90\n' +
      ' __driver_probe_device+0x80/0x160\n' +
      ' driver_probe_device+0x1e/0x90\n' +
      ' __device_attach_driver+0x7d/0x100\n' +
      ' bus_for_each_drv+0x80/0xd0\n' +
      ' __device_attach+0xbc/0x1f0\n' +
      ' bus_probe_device+0x86/0xa0\n' +
      ' device_add+0x62d/0x830\n' +
      ' __auxiliary_device_add+0x3b/0xa0\n' +
      ' ? auxiliary_device_init+0x41/0x90\n' +
      ' add_adev+0xd1/0x150 [mlx5_core]\n' +
      ' mlx5_rescan_drivers_locked+0x21c/0x300 [mlx5_core]\n' +
      ' esw_mode_change+0x6c/0xc0 [mlx5_core]\n' +
      ' mlx5_devlink_eswitch_mode_set+0x21e/0x640 [mlx5_core]\n' +
      ' devlink_nl_eswitch_set_doit+0x60/0xe0\n' +
      ' genl_family_rcv_msg_doit+0xd0/0x120\n' +
      ' genl_rcv_msg+0x180/0x2b0\n' +
      ' ? devlink_get_from_attrs_lock+0x170/0x170\n' +
      ' ? devlink_nl_eswitch_get_doit+0x290/0x290\n' +
      ' ? devlink_nl_pre_doit_port_optional+0x50/0x50\n' +
      ' ? genl_family_rcv_msg_dumpit+0xf0/0xf0\n' +
      ' netlink_rcv_skb+0x54/0x100\n' +
      ' genl_rcv+0x24/0x40\n' +
      ' netlink_unicast+0x1fc/0x2d0\n' +
      ' netlink_sendmsg+0x1e4/0x410\n' +
      ' __sock_sendmsg+0x38/0x60\n' +
      ' ? sockfd_lookup_light+0x12/0x60\n' +
      ' __sys_sendto+0x105/0x160\n' +
      ' ? __sys_recvmsg+0x4e/0x90\n' +
      ' __x64_sys_sendto+0x20/0x30\n' +
      ' do_syscall_64+0x4c/0x100\n' +
      ' entry_SYSCALL_64_after_hwframe+0x4b/0x53\n' +
      'RIP 00330x7f27bc91b13a\n' +
      'Code bb 66 2e 0f 1f 84 00 00 00 00 00 0f 1f 44 00 00 8b 05 fa 96 2c 00 45 89 c9 4c 63 d1 48 63 ff 85 c0 75 15 b8 2c 00 00 00 0f 05 48> 3d 00 f0 ff ff \n' +
      '---truncated--- | Severity UNKNOWN  ',
    contentSnippet: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'net/mlx5 Fix IPsec cleanup over MPV device\n' +
      '\n' +
      'When we do mlx5e_detach_netdev() we eventually disable blocking events\n' +
      'notifier, among those events are IPsec MPV events from IB to core.\n' +
      '\n' +
      'So before disabling those blocking events, make sure to also unregister\n' +
      'the devcom device and mark all this device operations as complete,\n' +
      'in order to prevent the other device from using invalid netdev\n' +
      'during future devcom events which could cause the trace below.\n' +
      '\n' +
      'BUG kernel NULL pointer dereference, address 0000000000000010\n' +
      'PGD 146427067 P4D 146427067 PUD 146488067 PMD 0\n' +
      'Oops Oops 0000 [#1] SMP\n' +
      'CPU 1 UID 0 PID 7735 Comm devlink Tainted GW 6.12.0-rc6_for_upstream_min_debug_2024_11_08_00_46 #1\n' +
      'Tainted [W]=WARN\n' +
      'Hardware name QEMU Standard PC (Q35 + ICH9, 2009), BIOS rel-1.13.0-0-gf21b5a4aeb02-prebuilt.qemu.org 04/01/2014\n' +
      'RIP 0010mlx5_devcom_comp_set_ready+0x5/0x40 [mlx5_core]\n' +
      'Code 00 01 48 83 05 23 32 1e 00 01 41 b8 ed ff ff ff e9 60 ff ff ff 48 83 05 00 32 1e 00 01 eb e3 66 0f 1f 44 00 00 0f 1f 44 00 00 48> 8b 47 10 48 83 05 5f 32 1e 00 01 48 8b 50 40 48 85 d2 74 05 40\n' +
      'RSP 0018ffff88811a5c35f8 EFLAGS 00010206\n' +
      'RAX ffff888106e8ab80 RBX ffff888107d7e200 RCX ffff88810d6f0a00\n' +
      'RDX ffff88810d6f0a00 RSI 0000000000000001 RDI 0000000000000000\n' +
      'RBP ffff88811a17e620 R08 0000000000000040 R09 0000000000000000\n' +
      'R10 ffff88811a5c3618 R11 0000000de85d51bd R12 ffff88811a17e600\n' +
      'R13 ffff88810d6f0a00 R14 0000000000000000 R15 ffff8881034bda80\n' +
      'FS  00007f27bdf89180(0000) GSffff88852c880000(0000) knlGS0000000000000000\n' +
      'CS  0010 DS 0000 ES 0000 CR0 0000000080050033\n' +
      'CR2 0000000000000010 CR3 000000010f159005 CR4 0000000000372eb0\n' +
      'DR0 0000000000000000 DR1 0000000000000000 DR2 0000000000000000\n' +
      'DR3 0000000000000000 DR6 00000000fffe0ff0 DR7 0000000000000400\n' +
      'Call Trace\n' +
      ' TASK>\n' +
      ' ? __die+0x20/0x60\n' +
      ' ? page_fault_oops+0x150/0x3e0\n' +
      ' ? exc_page_fault+0x74/0x130\n' +
      ' ? asm_exc_page_fault+0x22/0x30\n' +
      ' ? mlx5_devcom_comp_set_ready+0x5/0x40 [mlx5_core]\n' +
      ' mlx5e_devcom_event_mpv+0x42/0x60 [mlx5_core]\n' +
      ' mlx5_devcom_send_event+0x8c/0x170 [mlx5_core]\n' +
      ' blocking_event+0x17b/0x230 [mlx5_core]\n' +
      ' notifier_call_chain+0x35/0xa0\n' +
      ' blocking_notifier_call_chain+0x3d/0x60\n' +
      ' mlx5_blocking_notifier_call_chain+0x22/0x30 [mlx5_core]\n' +
      ' mlx5_core_mp_event_replay+0x12/0x20 [mlx5_core]\n' +
      ' mlx5_ib_bind_slave_port+0x228/0x2c0 [mlx5_ib]\n' +
      ' mlx5_ib_stage_init_init+0x664/0x9d0 [mlx5_ib]\n' +
      ' ? idr_alloc_cyclic+0x50/0xb0\n' +
      ' ? __kmalloc_cache_noprof+0x167/0x340\n' +
      ' ? __kmalloc_noprof+0x1a7/0x430\n' +
      ' __mlx5_ib_add+0x34/0xd0 [mlx5_ib]\n' +
      ' mlx5r_probe+0xe9/0x310 [mlx5_ib]\n' +
      ' ? kernfs_add_one+0x107/0x150\n' +
      ' ? __mlx5_ib_add+0xd0/0xd0 [mlx5_ib]\n' +
      ' auxiliary_bus_probe+0x3e/0x90\n' +
      ' really_probe+0xc5/0x3a0\n' +
      ' ? driver_probe_device+0x90/0x90\n' +
      ' __driver_probe_device+0x80/0x160\n' +
      ' driver_probe_device+0x1e/0x90\n' +
      ' __device_attach_driver+0x7d/0x100\n' +
      ' bus_for_each_drv+0x80/0xd0\n' +
      ' __device_attach+0xbc/0x1f0\n' +
      ' bus_probe_device+0x86/0xa0\n' +
      ' device_add+0x62d/0x830\n' +
      ' __auxiliary_device_add+0x3b/0xa0\n' +
      ' ? auxiliary_device_init+0x41/0x90\n' +
      ' add_adev+0xd1/0x150 [mlx5_core]\n' +
      ' mlx5_rescan_drivers_locked+0x21c/0x300 [mlx5_core]\n' +
      ' esw_mode_change+0x6c/0xc0 [mlx5_core]\n' +
      ' mlx5_devlink_eswitch_mode_set+0x21e/0x640 [mlx5_core]\n' +
      ' devlink_nl_eswitch_set_doit+0x60/0xe0\n' +
      ' genl_family_rcv_msg_doit+0xd0/0x120\n' +
      ' genl_rcv_msg+0x180/0x2b0\n' +
      ' ? devlink_get_from_attrs_lock+0x170/0x170\n' +
      ' ? devlink_nl_eswitch_get_doit+0x290/0x290\n' +
      ' ? devlink_nl_pre_doit_port_optional+0x50/0x50\n' +
      ' ? genl_family_rcv_msg_dumpit+0xf0/0xf0\n' +
      ' netlink_rcv_skb+0x54/0x100\n' +
      ' genl_rcv+0x24/0x40\n' +
      ' netlink_unicast+0x1fc/0x2d0\n' +
      ' netlink_sendmsg+0x1e4/0x410\n' +
      ' __sock_sendmsg+0x38/0x60\n' +
      ' ? sockfd_lookup_light+0x12/0x60\n' +
      ' __sys_sendto+0x105/0x160\n' +
      ' ? __sys_recvmsg+0x4e/0x90\n' +
      ' __x64_sys_sendto+0x20/0x30\n' +
      ' do_syscall_64+0x4c/0x100\n' +
      ' entry_SYSCALL_64_after_hwframe+0x4b/0x53\n' +
      'RIP 00330x7f27bc91b13a\n' +
      'Code bb 66 2e 0f 1f 84 00 00 00 00 00 0f 1f 44 00 00 8b 05 fa 96 2c 00 45 89 c9 4c 63 d1 48 63 ff 85 c0 75 15 b8 2c 00 00 00 0f 05 48> 3d 00 f0 ff ff \n' +
      '---truncated--- | Severity UNKNOWN',
    guid: 'CVE-2025-40238',
    isoDate: '2025-12-04T16:16:00.000Z'
  },
  {
    title: 'CVE-2025-40239 In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'net phy micrel always set sh...',
    link: 'https//nvd.nist.gov/vuln/detail/CVE-2025-40239',
    pubDate: 'Thu, 04 Dec 2025 16:16:00 GMT',
    content: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'net phy micrel always set shared->phydev for LAN8814\n' +
      '\n' +
      'Currently, during the LAN8814 PTP probe shared->phydev is only set if PTP\n' +
      'clock gets actually set, otherwise the function will return before setting\n' +
      'it.\n' +
      '\n' +
      'This is an issue as shared->phydev is unconditionally being used when IRQ\n' +
      'is being handled, especially in lan8814_gpio_process_cap and since it was\n' +
      'not set it will cause a NULL pointer exception and crash the kernel.\n' +
      '\n' +
      'So, simply always set shared->phydev to avoid the NULL pointer exception. | Severity UNKNOWN  ',
    contentSnippet: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'net phy micrel always set shared->phydev for LAN8814\n' +
      '\n' +
      'Currently, during the LAN8814 PTP probe shared->phydev is only set if PTP\n' +
      'clock gets actually set, otherwise the function will return before setting\n' +
      'it.\n' +
      '\n' +
      'This is an issue as shared->phydev is unconditionally being used when IRQ\n' +
      'is being handled, especially in lan8814_gpio_process_cap and since it was\n' +
      'not set it will cause a NULL pointer exception and crash the kernel.\n' +
      '\n' +
      'So, simply always set shared->phydev to avoid the NULL pointer exception. | Severity UNKNOWN',
    guid: 'CVE-2025-40239',
    isoDate: '2025-12-04T16:16:00.000Z'
  },
  {
    title: 'CVE-2025-40240 In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'sctp avoid NULL dereference wh...',
    link: 'https//nvd.nist.gov/vuln/detail/CVE-2025-40240',
    pubDate: 'Thu, 04 Dec 2025 16:16:00 GMT',
    content: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'sctp avoid NULL dereference when chunk data buffer is missing\n' +
      '\n' +
      "chunk->skb pointer is dereferenced in the if-block where it's supposed\n" +
      'to be NULL only.\n' +
      '\n' +
      'chunk->skb can only be NULL if chunk->head_skb is not. Check for frag_list\n' +
      "instead and do it just before replacing chunk->skb. We're sure that\n" +
      'otherwise chunk->skb is non-NULL because of outer if() condition. | Severity UNKNOWN  ',
    contentSnippet: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'sctp avoid NULL dereference when chunk data buffer is missing\n' +
      '\n' +
      "chunk->skb pointer is dereferenced in the if-block where it's supposed\n" +
      'to be NULL only.\n' +
      '\n' +
      'chunk->skb can only be NULL if chunk->head_skb is not. Check for frag_list\n' +
      "instead and do it just before replacing chunk->skb. We're sure that\n" +
      'otherwise chunk->skb is non-NULL because of outer if() condition. | Severity UNKNOWN',
    guid: 'CVE-2025-40240',
    isoDate: '2025-12-04T16:16:00.000Z'
  },
  {
    title: 'CVE-2025-40241 In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'erofs fix crafted invalid case...',
    link: 'https//nvd.nist.gov/vuln/detail/CVE-2025-40241',
    pubDate: 'Thu, 04 Dec 2025 16:16:00 GMT',
    content: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'erofs fix crafted invalid cases for encoded extents\n' +
      '\n' +
      'Robert recently reported two corrupted images that can cause system\n' +
      'crashes, which are related to the new encoded extents introduced\n' +
      'in Linux 6.15\n' +
      '\n' +
      '  - The first one [1] has plen != 0 (e.g. plen == 0x2000000) but\n' +
      '    (plen  Z_EROFS_EXTENT_PLEN_MASK) == 0. It is used to represent\n' +
      '    special extents such as sparse extents (!EROFS_MAP_MAPPED), but\n' +
      '    previously only plen == 0 was handled\n' +
      '\n' +
      '  - The second one [2] has pa 0xffffffffffdcffed and plen 0xb4000,\n' +
      '    then "cur [0xfffffffffffff000] += bvec.bv_len [0x1000]" in\n' +
      '    "} while ((cur += bvec.bv_len)  end)" wraps around, causing an\n' +
      '    out-of-bound access of pcl->compressed_bvecs[] in\n' +
      '    z_erofs_submit_queue().  EROFS only supports 48-bit physical block\n' +
      '    addresses (up to 1EiB for 4k blocks), so add a sanity check to\n' +
      '    enforce this. | Severity UNKNOWN  ',
    contentSnippet: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'erofs fix crafted invalid cases for encoded extents\n' +
      '\n' +
      'Robert recently reported two corrupted images that can cause system\n' +
      'crashes, which are related to the new encoded extents introduced\n' +
      'in Linux 6.15\n' +
      '\n' +
      '  - The first one [1] has plen != 0 (e.g. plen == 0x2000000) but\n' +
      '    (plen  Z_EROFS_EXTENT_PLEN_MASK) == 0. It is used to represent\n' +
      '    special extents such as sparse extents (!EROFS_MAP_MAPPED), but\n' +
      '    previously only plen == 0 was handled\n' +
      '\n' +
      '  - The second one [2] has pa 0xffffffffffdcffed and plen 0xb4000,\n' +
      '    then "cur [0xfffffffffffff000] += bvec.bv_len [0x1000]" in\n' +
      '    "} while ((cur += bvec.bv_len)  end)" wraps around, causing an\n' +
      '    out-of-bound access of pcl->compressed_bvecs[] in\n' +
      '    z_erofs_submit_queue().  EROFS only supports 48-bit physical block\n' +
      '    addresses (up to 1EiB for 4k blocks), so add a sanity check to\n' +
      '    enforce this. | Severity UNKNOWN',
    guid: 'CVE-2025-40241',
    isoDate: '2025-12-04T16:16:00.000Z'
  },
  {
    title: 'CVE-2025-40242 In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'gfs2 Fix unlikely race in gdlm...',
    link: 'https//nvd.nist.gov/vuln/detail/CVE-2025-40242',
    pubDate: 'Thu, 04 Dec 2025 16:16:00 GMT',
    content: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'gfs2 Fix unlikely race in gdlm_put_lock\n' +
      '\n' +
      'In gdlm_put_lock(), there is a small window of time in which the\n' +
      "DFL_UNMOUNT flag has been set but the lockspace hasn't been released,\n" +
      'yet.  In that window, dlm may still call gdlm_ast() and gdlm_bast().\n' +
      'To prevent it from dereferencing freed glock objects, only free the\n' +
      'glock if the lockspace has actually been released. | Severity UNKNOWN  ',
    contentSnippet: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'gfs2 Fix unlikely race in gdlm_put_lock\n' +
      '\n' +
      'In gdlm_put_lock(), there is a small window of time in which the\n' +
      "DFL_UNMOUNT flag has been set but the lockspace hasn't been released,\n" +
      'yet.  In that window, dlm may still call gdlm_ast() and gdlm_bast().\n' +
      'To prevent it from dereferencing freed glock objects, only free the\n' +
      'glock if the lockspace has actually been released. | Severity UNKNOWN',
    guid: 'CVE-2025-40242',
    isoDate: '2025-12-04T16:16:00.000Z'
  },
  {
    title: 'CVE-2025-40243 In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'hfs fix KMSAN uninit-value iss...',
    link: 'https//nvd.nist.gov/vuln/detail/CVE-2025-40243',
    pubDate: 'Thu, 04 Dec 2025 16:16:00 GMT',
    content: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'hfs fix KMSAN uninit-value issue in hfs_find_set_zero_bits()\n' +
      '\n' +
      'The syzbot reported issue in hfs_find_set_zero_bits()\n' +
      '\n' +
      '=====================================================\n' +
      'BUG KMSAN uninit-value in hfs_find_set_zero_bits+0x74d/0xb60 fs/hfs/bitmap.c45\n' +
      ' hfs_find_set_zero_bits+0x74d/0xb60 fs/hfs/bitmap.c45\n' +
      ' hfs_vbm_search_free+0x13c/0x5b0 fs/hfs/bitmap.c151\n' +
      ' hfs_extend_file+0x6a5/0x1b00 fs/hfs/extent.c408\n' +
      ' hfs_get_block+0x435/0x1150 fs/hfs/extent.c353\n' +
      ' __block_write_begin_int+0xa76/0x3030 fs/buffer.c2151\n' +
      ' block_write_begin fs/buffer.c2262 [inline]\n' +
      ' cont_write_begin+0x10e1/0x1bc0 fs/buffer.c2601\n' +
      ' hfs_write_begin+0x85/0x130 fs/hfs/inode.c52\n' +
      ' cont_expand_zero fs/buffer.c2528 [inline]\n' +
      ' cont_write_begin+0x35a/0x1bc0 fs/buffer.c2591\n' +
      ' hfs_write_begin+0x85/0x130 fs/hfs/inode.c52\n' +
      ' hfs_file_truncate+0x1d6/0xe60 fs/hfs/extent.c494\n' +
      ' hfs_inode_setattr+0x964/0xaa0 fs/hfs/inode.c654\n' +
      ' notify_change+0x1993/0x1aa0 fs/attr.c552\n' +
      ' do_truncate+0x28f/0x310 fs/open.c68\n' +
      ' do_ftruncate+0x698/0x730 fs/open.c195\n' +
      ' do_sys_ftruncate fs/open.c210 [inline]\n' +
      ' __do_sys_ftruncate fs/open.c215 [inline]\n' +
      ' __se_sys_ftruncate fs/open.c213 [inline]\n' +
      ' __x64_sys_ftruncate+0x11b/0x250 fs/open.c213\n' +
      ' x64_sys_call+0xfe3/0x3db0 arch/x86/include/generated/asm/syscalls_64.h78\n' +
      ' do_syscall_x64 arch/x86/entry/syscall_64.c63 [inline]\n' +
      ' do_syscall_64+0xd9/0x210 arch/x86/entry/syscall_64.c94\n' +
      ' entry_SYSCALL_64_after_hwframe+0x77/0x7f\n' +
      '\n' +
      'Uninit was created at\n' +
      ' slab_post_alloc_hook mm/slub.c4154 [inline]\n' +
      ' slab_alloc_node mm/slub.c4197 [inline]\n' +
      ' __kmalloc_cache_noprof+0x7f7/0xed0 mm/slub.c4354\n' +
      ' kmalloc_noprof include/linux/slab.h905 [inline]\n' +
      ' hfs_mdb_get+0x1cc8/0x2a90 fs/hfs/mdb.c175\n' +
      ' hfs_fill_super+0x3d0/0xb80 fs/hfs/super.c337\n' +
      ' get_tree_bdev_flags+0x6e3/0x920 fs/super.c1681\n' +
      ' get_tree_bdev+0x38/0x50 fs/super.c1704\n' +
      ' hfs_get_tree+0x35/0x40 fs/hfs/super.c388\n' +
      ' vfs_get_tree+0xb0/0x5c0 fs/super.c1804\n' +
      ' do_new_mount+0x738/0x1610 fs/namespace.c3902\n' +
      ' path_mount+0x6db/0x1e90 fs/namespace.c4226\n' +
      ' do_mount fs/namespace.c4239 [inline]\n' +
      ' __do_sys_mount fs/namespace.c4450 [inline]\n' +
      ' __se_sys_mount+0x6eb/0x7d0 fs/namespace.c4427\n' +
      ' __x64_sys_mount+0xe4/0x150 fs/namespace.c4427\n' +
      ' x64_sys_call+0xfa7/0x3db0 arch/x86/include/generated/asm/syscalls_64.h166\n' +
      ' do_syscall_x64 arch/x86/entry/syscall_64.c63 [inline]\n' +
      ' do_syscall_64+0xd9/0x210 arch/x86/entry/syscall_64.c94\n' +
      ' entry_SYSCALL_64_after_hwframe+0x77/0x7f\n' +
      '\n' +
      'CPU 1 UID 0 PID 12609 Comm syz.1.2692 Not tainted 6.16.0-syzkaller #0 PREEMPT(none)\n' +
      'Hardware name Google Google Compute Engine/Google Compute Engine, BIOS Google 07/12/2025\n' +
      '=====================================================\n' +
      '\n' +
      'The HFS_SB(sb)->bitmap buffer is allocated in hfs_mdb_get()\n' +
      '\n' +
      'HFS_SB(sb)->bitmap = kmalloc(8192, GFP_KERNEL)\n' +
      '\n' +
      'Finally, it can trigger the reported issue because kmalloc()\n' +
      "doesn't clear the allocated memory. If allocated memory contains\n" +
      'only zeros, then everything will work pretty fine.\n' +
      'But if the allocated memory contains the "garbage", then\n' +
      'it can affect the bitmap operations and it triggers\n' +
      'the reported issue.\n' +
      '\n' +
      'This patch simply exchanges the kmalloc() on kzalloc()\n' +
      'with the goal to guarantee the correctness of bitmap operations.\n' +
      'Because, newly created allocation bitmap should have all\n' +
      "available blocks free. Potentially, initialization bitmap's read\n" +
      'operation could not fill the whole allocated memory and\n' +
      '"garbage" in the not initialized memory will be the reason of\n' +
      'volume coruptions and file system driver bugs. | Severity UNKNOWN  ',
    contentSnippet: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'hfs fix KMSAN uninit-value issue in hfs_find_set_zero_bits()\n' +
      '\n' +
      'The syzbot reported issue in hfs_find_set_zero_bits()\n' +
      '\n' +
      '=====================================================\n' +
      'BUG KMSAN uninit-value in hfs_find_set_zero_bits+0x74d/0xb60 fs/hfs/bitmap.c45\n' +
      ' hfs_find_set_zero_bits+0x74d/0xb60 fs/hfs/bitmap.c45\n' +
      ' hfs_vbm_search_free+0x13c/0x5b0 fs/hfs/bitmap.c151\n' +
      ' hfs_extend_file+0x6a5/0x1b00 fs/hfs/extent.c408\n' +
      ' hfs_get_block+0x435/0x1150 fs/hfs/extent.c353\n' +
      ' __block_write_begin_int+0xa76/0x3030 fs/buffer.c2151\n' +
      ' block_write_begin fs/buffer.c2262 [inline]\n' +
      ' cont_write_begin+0x10e1/0x1bc0 fs/buffer.c2601\n' +
      ' hfs_write_begin+0x85/0x130 fs/hfs/inode.c52\n' +
      ' cont_expand_zero fs/buffer.c2528 [inline]\n' +
      ' cont_write_begin+0x35a/0x1bc0 fs/buffer.c2591\n' +
      ' hfs_write_begin+0x85/0x130 fs/hfs/inode.c52\n' +
      ' hfs_file_truncate+0x1d6/0xe60 fs/hfs/extent.c494\n' +
      ' hfs_inode_setattr+0x964/0xaa0 fs/hfs/inode.c654\n' +
      ' notify_change+0x1993/0x1aa0 fs/attr.c552\n' +
      ' do_truncate+0x28f/0x310 fs/open.c68\n' +
      ' do_ftruncate+0x698/0x730 fs/open.c195\n' +
      ' do_sys_ftruncate fs/open.c210 [inline]\n' +
      ' __do_sys_ftruncate fs/open.c215 [inline]\n' +
      ' __se_sys_ftruncate fs/open.c213 [inline]\n' +
      ' __x64_sys_ftruncate+0x11b/0x250 fs/open.c213\n' +
      ' x64_sys_call+0xfe3/0x3db0 arch/x86/include/generated/asm/syscalls_64.h78\n' +
      ' do_syscall_x64 arch/x86/entry/syscall_64.c63 [inline]\n' +
      ' do_syscall_64+0xd9/0x210 arch/x86/entry/syscall_64.c94\n' +
      ' entry_SYSCALL_64_after_hwframe+0x77/0x7f\n' +
      '\n' +
      'Uninit was created at\n' +
      ' slab_post_alloc_hook mm/slub.c4154 [inline]\n' +
      ' slab_alloc_node mm/slub.c4197 [inline]\n' +
      ' __kmalloc_cache_noprof+0x7f7/0xed0 mm/slub.c4354\n' +
      ' kmalloc_noprof include/linux/slab.h905 [inline]\n' +
      ' hfs_mdb_get+0x1cc8/0x2a90 fs/hfs/mdb.c175\n' +
      ' hfs_fill_super+0x3d0/0xb80 fs/hfs/super.c337\n' +
      ' get_tree_bdev_flags+0x6e3/0x920 fs/super.c1681\n' +
      ' get_tree_bdev+0x38/0x50 fs/super.c1704\n' +
      ' hfs_get_tree+0x35/0x40 fs/hfs/super.c388\n' +
      ' vfs_get_tree+0xb0/0x5c0 fs/super.c1804\n' +
      ' do_new_mount+0x738/0x1610 fs/namespace.c3902\n' +
      ' path_mount+0x6db/0x1e90 fs/namespace.c4226\n' +
      ' do_mount fs/namespace.c4239 [inline]\n' +
      ' __do_sys_mount fs/namespace.c4450 [inline]\n' +
      ' __se_sys_mount+0x6eb/0x7d0 fs/namespace.c4427\n' +
      ' __x64_sys_mount+0xe4/0x150 fs/namespace.c4427\n' +
      ' x64_sys_call+0xfa7/0x3db0 arch/x86/include/generated/asm/syscalls_64.h166\n' +
      ' do_syscall_x64 arch/x86/entry/syscall_64.c63 [inline]\n' +
      ' do_syscall_64+0xd9/0x210 arch/x86/entry/syscall_64.c94\n' +
      ' entry_SYSCALL_64_after_hwframe+0x77/0x7f\n' +
      '\n' +
      'CPU 1 UID 0 PID 12609 Comm syz.1.2692 Not tainted 6.16.0-syzkaller #0 PREEMPT(none)\n' +
      'Hardware name Google Google Compute Engine/Google Compute Engine, BIOS Google 07/12/2025\n' +
      '=====================================================\n' +
      '\n' +
      'The HFS_SB(sb)->bitmap buffer is allocated in hfs_mdb_get()\n' +
      '\n' +
      'HFS_SB(sb)->bitmap = kmalloc(8192, GFP_KERNEL)\n' +
      '\n' +
      'Finally, it can trigger the reported issue because kmalloc()\n' +
      "doesn't clear the allocated memory. If allocated memory contains\n" +
      'only zeros, then everything will work pretty fine.\n' +
      'But if the allocated memory contains the "garbage", then\n' +
      'it can affect the bitmap operations and it triggers\n' +
      'the reported issue.\n' +
      '\n' +
      'This patch simply exchanges the kmalloc() on kzalloc()\n' +
      'with the goal to guarantee the correctness of bitmap operations.\n' +
      'Because, newly created allocation bitmap should have all\n' +
      "available blocks free. Potentially, initialization bitmap's read\n" +
      'operation could not fill the whole allocated memory and\n' +
      '"garbage" in the not initialized memory will be the reason of\n' +
      'volume coruptions and file system driver bugs. | Severity UNKNOWN',
    guid: 'CVE-2025-40243',
    isoDate: '2025-12-04T16:16:00.000Z'
  },
  {
    title: 'CVE-2025-40244 In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'hfsplus fix KMSAN uninit-value...',
    link: 'https//nvd.nist.gov/vuln/detail/CVE-2025-40244',
    pubDate: 'Thu, 04 Dec 2025 16:16:00 GMT',
    content: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'hfsplus fix KMSAN uninit-value issue in __hfsplus_ext_cache_extent()\n' +
      '\n' +
      'The syzbot reported issue in __hfsplus_ext_cache_extent()\n' +
      '\n' +
      '[   70.194323][ T9350] BUG KMSAN uninit-value in __hfsplus_ext_cache_extent+0x7d0/0x990\n' +
      '[   70.195022][ T9350]  __hfsplus_ext_cache_extent+0x7d0/0x990\n' +
      '[   70.195530][ T9350]  hfsplus_file_extend+0x74f/0x1cf0\n' +
      '[   70.195998][ T9350]  hfsplus_get_block+0xe16/0x17b0\n' +
      '[   70.196458][ T9350]  __block_write_begin_int+0x962/0x2ce0\n' +
      '[   70.196959][ T9350]  cont_write_begin+0x1000/0x1950\n' +
      '[   70.197416][ T9350]  hfsplus_write_begin+0x85/0x130\n' +
      '[   70.197873][ T9350]  generic_perform_write+0x3e8/0x1060\n' +
      '[   70.198374][ T9350]  __generic_file_write_iter+0x215/0x460\n' +
      '[   70.198892][ T9350]  generic_file_write_iter+0x109/0x5e0\n' +
      '[   70.199393][ T9350]  vfs_write+0xb0f/0x14e0\n' +
      '[   70.199771][ T9350]  ksys_write+0x23e/0x490\n' +
      '[   70.200149][ T9350]  __x64_sys_write+0x97/0xf0\n' +
      '[   70.200570][ T9350]  x64_sys_call+0x3015/0x3cf0\n' +
      '[   70.201065][ T9350]  do_syscall_64+0xd9/0x1d0\n' +
      '[   70.201506][ T9350]  entry_SYSCALL_64_after_hwframe+0x77/0x7f\n' +
      '[   70.202054][ T9350]\n' +
      '[   70.202279][ T9350] Uninit was created at\n' +
      '[   70.202693][ T9350]  __kmalloc_noprof+0x621/0xf80\n' +
      '[   70.203149][ T9350]  hfsplus_find_init+0x8d/0x1d0\n' +
      '[   70.203602][ T9350]  hfsplus_file_extend+0x6ca/0x1cf0\n' +
      '[   70.204087][ T9350]  hfsplus_get_block+0xe16/0x17b0\n' +
      '[   70.204561][ T9350]  __block_write_begin_int+0x962/0x2ce0\n' +
      '[   70.205074][ T9350]  cont_write_begin+0x1000/0x1950\n' +
      '[   70.205547][ T9350]  hfsplus_write_begin+0x85/0x130\n' +
      '[   70.206017][ T9350]  generic_perform_write+0x3e8/0x1060\n' +
      '[   70.206519][ T9350]  __generic_file_write_iter+0x215/0x460\n' +
      '[   70.207042][ T9350]  generic_file_write_iter+0x109/0x5e0\n' +
      '[   70.207552][ T9350]  vfs_write+0xb0f/0x14e0\n' +
      '[   70.207961][ T9350]  ksys_write+0x23e/0x490\n' +
      '[   70.208375][ T9350]  __x64_sys_write+0x97/0xf0\n' +
      '[   70.208810][ T9350]  x64_sys_call+0x3015/0x3cf0\n' +
      '[   70.209255][ T9350]  do_syscall_64+0xd9/0x1d0\n' +
      '[   70.209680][ T9350]  entry_SYSCALL_64_after_hwframe+0x77/0x7f\n' +
      '[   70.210230][ T9350]\n' +
      '[   70.210454][ T9350] CPU 2 UID 0 PID 9350 Comm repro Not tainted 6.12.0-rc5 #5\n' +
      '[   70.211174][ T9350] Hardware name QEMU Ubuntu 24.04 PC (i440FX + PIIX, 1996), BIOS 1.16.3-debian-1.16.3-2 04/01/2014\n' +
      '[   70.212115][ T9350] =====================================================\n' +
      '[   70.212734][ T9350] Disabling lock debugging due to kernel taint\n' +
      '[   70.213284][ T9350] Kernel panic - not syncing kmsan.panic set ...\n' +
      '[   70.213858][ T9350] CPU 2 UID 0 PID 9350 Comm repro Tainted G    B              6.12.0-rc5 #5\n' +
      '[   70.214679][ T9350] Tainted [B]=BAD_PAGE\n' +
      '[   70.215057][ T9350] Hardware name QEMU Ubuntu 24.04 PC (i440FX + PIIX, 1996), BIOS 1.16.3-debian-1.16.3-2 04/01/2014\n' +
      '[   70.215999][ T9350] Call Trace\n' +
      '[   70.216309][ T9350]  TASK>\n' +
      '[   70.216585][ T9350]  dump_stack_lvl+0x1fd/0x2b0\n' +
      '[   70.217025][ T9350]  dump_stack+0x1e/0x30\n' +
      '[   70.217421][ T9350]  panic+0x502/0xca0\n' +
      '[   70.217803][ T9350]  ? kmsan_get_metadata+0x13e/0x1c0\n' +
      '\n' +
      '[   70.218294][ Message fromT sy9350]  kmsan_report+0x296/slogd@syzkaller 0x2aat Aug 18 2211058 ...\n' +
      ' kernel\n' +
      '[   70.213284][ T9350] Kernel panic - not syncing kmsan.panic [   70.220179][ T9350]  ? kmsan_get_metadata+0x13e/0x1c0\n' +
      'set ...\n' +
      '[   70.221254][ T9350]  ? __msan_warning+0x96/0x120\n' +
      '[   70.222066][ T9350]  ? __hfsplus_ext_cache_extent+0x7d0/0x990\n' +
      '[   70.223023][ T9350]  ? hfsplus_file_extend+0x74f/0x1cf0\n' +
      '[   70.224120][ T9350]  ? hfsplus_get_block+0xe16/0x17b0\n' +
      '[   70.224946][ T9350]  ? __block_write_begin_int+0x962/0x2ce0\n' +
      '[   70.225756][ T9350]  ? cont_write_begin+0x1000/0x1950\n' +
      '[   70.226337][ T9350]  ? hfsplus_write_begin+0x85/0x130\n' +
      '[   70.226852][ T9350]  ? generic_perform_write+0x3e8/0x1060\n' +
      '[   70.227405][ T9350]  ? __generic_file_write_iter+0x215/0x460\n' +
      '[   70.227979][ T9350]  ? generic_file_write_iter+0x109/0x5e0\n' +
      '[   70.228540][ T9350]  ? vfs_write+0xb0f/0x14e0\n' +
      '[   70.228997][ T9350]  ? ksys_write+0x23e/0x490\n' +
      '---truncated--- | Severity UNKNOWN  ',
    contentSnippet: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'hfsplus fix KMSAN uninit-value issue in __hfsplus_ext_cache_extent()\n' +
      '\n' +
      'The syzbot reported issue in __hfsplus_ext_cache_extent()\n' +
      '\n' +
      '[   70.194323][ T9350] BUG KMSAN uninit-value in __hfsplus_ext_cache_extent+0x7d0/0x990\n' +
      '[   70.195022][ T9350]  __hfsplus_ext_cache_extent+0x7d0/0x990\n' +
      '[   70.195530][ T9350]  hfsplus_file_extend+0x74f/0x1cf0\n' +
      '[   70.195998][ T9350]  hfsplus_get_block+0xe16/0x17b0\n' +
      '[   70.196458][ T9350]  __block_write_begin_int+0x962/0x2ce0\n' +
      '[   70.196959][ T9350]  cont_write_begin+0x1000/0x1950\n' +
      '[   70.197416][ T9350]  hfsplus_write_begin+0x85/0x130\n' +
      '[   70.197873][ T9350]  generic_perform_write+0x3e8/0x1060\n' +
      '[   70.198374][ T9350]  __generic_file_write_iter+0x215/0x460\n' +
      '[   70.198892][ T9350]  generic_file_write_iter+0x109/0x5e0\n' +
      '[   70.199393][ T9350]  vfs_write+0xb0f/0x14e0\n' +
      '[   70.199771][ T9350]  ksys_write+0x23e/0x490\n' +
      '[   70.200149][ T9350]  __x64_sys_write+0x97/0xf0\n' +
      '[   70.200570][ T9350]  x64_sys_call+0x3015/0x3cf0\n' +
      '[   70.201065][ T9350]  do_syscall_64+0xd9/0x1d0\n' +
      '[   70.201506][ T9350]  entry_SYSCALL_64_after_hwframe+0x77/0x7f\n' +
      '[   70.202054][ T9350]\n' +
      '[   70.202279][ T9350] Uninit was created at\n' +
      '[   70.202693][ T9350]  __kmalloc_noprof+0x621/0xf80\n' +
      '[   70.203149][ T9350]  hfsplus_find_init+0x8d/0x1d0\n' +
      '[   70.203602][ T9350]  hfsplus_file_extend+0x6ca/0x1cf0\n' +
      '[   70.204087][ T9350]  hfsplus_get_block+0xe16/0x17b0\n' +
      '[   70.204561][ T9350]  __block_write_begin_int+0x962/0x2ce0\n' +
      '[   70.205074][ T9350]  cont_write_begin+0x1000/0x1950\n' +
      '[   70.205547][ T9350]  hfsplus_write_begin+0x85/0x130\n' +
      '[   70.206017][ T9350]  generic_perform_write+0x3e8/0x1060\n' +
      '[   70.206519][ T9350]  __generic_file_write_iter+0x215/0x460\n' +
      '[   70.207042][ T9350]  generic_file_write_iter+0x109/0x5e0\n' +
      '[   70.207552][ T9350]  vfs_write+0xb0f/0x14e0\n' +
      '[   70.207961][ T9350]  ksys_write+0x23e/0x490\n' +
      '[   70.208375][ T9350]  __x64_sys_write+0x97/0xf0\n' +
      '[   70.208810][ T9350]  x64_sys_call+0x3015/0x3cf0\n' +
      '[   70.209255][ T9350]  do_syscall_64+0xd9/0x1d0\n' +
      '[   70.209680][ T9350]  entry_SYSCALL_64_after_hwframe+0x77/0x7f\n' +
      '[   70.210230][ T9350]\n' +
      '[   70.210454][ T9350] CPU 2 UID 0 PID 9350 Comm repro Not tainted 6.12.0-rc5 #5\n' +
      '[   70.211174][ T9350] Hardware name QEMU Ubuntu 24.04 PC (i440FX + PIIX, 1996), BIOS 1.16.3-debian-1.16.3-2 04/01/2014\n' +
      '[   70.212115][ T9350] =====================================================\n' +
      '[   70.212734][ T9350] Disabling lock debugging due to kernel taint\n' +
      '[   70.213284][ T9350] Kernel panic - not syncing kmsan.panic set ...\n' +
      '[   70.213858][ T9350] CPU 2 UID 0 PID 9350 Comm repro Tainted G    B              6.12.0-rc5 #5\n' +
      '[   70.214679][ T9350] Tainted [B]=BAD_PAGE\n' +
      '[   70.215057][ T9350] Hardware name QEMU Ubuntu 24.04 PC (i440FX + PIIX, 1996), BIOS 1.16.3-debian-1.16.3-2 04/01/2014\n' +
      '[   70.215999][ T9350] Call Trace\n' +
      '[   70.216309][ T9350]  TASK>\n' +
      '[   70.216585][ T9350]  dump_stack_lvl+0x1fd/0x2b0\n' +
      '[   70.217025][ T9350]  dump_stack+0x1e/0x30\n' +
      '[   70.217421][ T9350]  panic+0x502/0xca0\n' +
      '[   70.217803][ T9350]  ? kmsan_get_metadata+0x13e/0x1c0\n' +
      '\n' +
      '[   70.218294][ Message fromT sy9350]  kmsan_report+0x296/slogd@syzkaller 0x2aat Aug 18 2211058 ...\n' +
      ' kernel\n' +
      '[   70.213284][ T9350] Kernel panic - not syncing kmsan.panic [   70.220179][ T9350]  ? kmsan_get_metadata+0x13e/0x1c0\n' +
      'set ...\n' +
      '[   70.221254][ T9350]  ? __msan_warning+0x96/0x120\n' +
      '[   70.222066][ T9350]  ? __hfsplus_ext_cache_extent+0x7d0/0x990\n' +
      '[   70.223023][ T9350]  ? hfsplus_file_extend+0x74f/0x1cf0\n' +
      '[   70.224120][ T9350]  ? hfsplus_get_block+0xe16/0x17b0\n' +
      '[   70.224946][ T9350]  ? __block_write_begin_int+0x962/0x2ce0\n' +
      '[   70.225756][ T9350]  ? cont_write_begin+0x1000/0x1950\n' +
      '[   70.226337][ T9350]  ? hfsplus_write_begin+0x85/0x130\n' +
      '[   70.226852][ T9350]  ? generic_perform_write+0x3e8/0x1060\n' +
      '[   70.227405][ T9350]  ? __generic_file_write_iter+0x215/0x460\n' +
      '[   70.227979][ T9350]  ? generic_file_write_iter+0x109/0x5e0\n' +
      '[   70.228540][ T9350]  ? vfs_write+0xb0f/0x14e0\n' +
      '[   70.228997][ T9350]  ? ksys_write+0x23e/0x490\n' +
      '---truncated--- | Severity UNKNOWN',
    guid: 'CVE-2025-40244',
    isoDate: '2025-12-04T16:16:00.000Z'
  },
  {
    title: 'CVE-2025-40245 In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'nios2 ensure that memblock.cur...',
    link: 'https//nvd.nist.gov/vuln/detail/CVE-2025-40245',
    pubDate: 'Thu, 04 Dec 2025 16:16:00 GMT',
    content: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'nios2 ensure that memblock.current_limit is set when setting pfn limits\n' +
      '\n' +
      'On nios2, with CONFIG_FLATMEM set, the kernel relies on\n' +
      'memblock_get_current_limit() to determine the limits of mem_map, in\n' +
      'particular for max_low_pfn.\n' +
      'Unfortunately, memblock.current_limit is only default initialized to\n' +
      'MEMBLOCK_ALLOC_ANYWHERE at this point of the bootup, potentially leading\n' +
      'to situations where max_low_pfn can erroneously exceed the value of\n' +
      'max_pfn and, thus, the valid range of available DRAM.\n' +
      '\n' +
      'This can in turn cause kernel-level paging failures, e.g.\n' +
      '\n' +
      '[   76.900000] Unable to handle kernel paging request at virtual address 20303000\n' +
      '[   76.900000] ea = c0080890, ra = c000462c, cause = 14\n' +
      '[   76.900000] Kernel panic - not syncing Oops\n' +
      '[   76.900000] ---[ end Kernel panic - not syncing Oops ]---\n' +
      '\n' +
      'This patch fixes this by pre-calculating memblock.current_limit\n' +
      'based on the upper limits of the available memory ranges via\n' +
      'adjust_lowmem_bounds, a simplified version of the equivalent\n' +
      'implementation within the arm architecture. | Severity UNKNOWN  ',
    contentSnippet: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'nios2 ensure that memblock.current_limit is set when setting pfn limits\n' +
      '\n' +
      'On nios2, with CONFIG_FLATMEM set, the kernel relies on\n' +
      'memblock_get_current_limit() to determine the limits of mem_map, in\n' +
      'particular for max_low_pfn.\n' +
      'Unfortunately, memblock.current_limit is only default initialized to\n' +
      'MEMBLOCK_ALLOC_ANYWHERE at this point of the bootup, potentially leading\n' +
      'to situations where max_low_pfn can erroneously exceed the value of\n' +
      'max_pfn and, thus, the valid range of available DRAM.\n' +
      '\n' +
      'This can in turn cause kernel-level paging failures, e.g.\n' +
      '\n' +
      '[   76.900000] Unable to handle kernel paging request at virtual address 20303000\n' +
      '[   76.900000] ea = c0080890, ra = c000462c, cause = 14\n' +
      '[   76.900000] Kernel panic - not syncing Oops\n' +
      '[   76.900000] ---[ end Kernel panic - not syncing Oops ]---\n' +
      '\n' +
      'This patch fixes this by pre-calculating memblock.current_limit\n' +
      'based on the upper limits of the available memory ranges via\n' +
      'adjust_lowmem_bounds, a simplified version of the equivalent\n' +
      'implementation within the arm architecture. | Severity UNKNOWN',
    guid: 'CVE-2025-40245',
    isoDate: '2025-12-04T16:16:00.000Z'
  },
  {
    title: 'CVE-2025-40246 In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'xfs fix out of bounds memory r...',
    link: 'https//nvd.nist.gov/vuln/detail/CVE-2025-40246',
    pubDate: 'Thu, 04 Dec 2025 16:16:00 GMT',
    content: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'xfs fix out of bounds memory read error in symlink repair\n' +
      '\n' +
      'xfs/286 produced this report on my test fleet\n' +
      '\n' +
      ' ==================================================================\n' +
      ' BUG KFENCE out-of-bounds read in memcpy_orig+0x54/0x110\n' +
      '\n' +
      ' Out-of-bounds read at 0xffff88843fe9e038 (184B right of kfence-#184)\n' +
      '  memcpy_orig+0x54/0x110\n' +
      '  xrep_symlink_salvage_inline+0xb3/0xf0 [xfs]\n' +
      '  xrep_symlink_salvage+0x100/0x110 [xfs]\n' +
      '  xrep_symlink+0x2e/0x80 [xfs]\n' +
      '  xrep_attempt+0x61/0x1f0 [xfs]\n' +
      '  xfs_scrub_metadata+0x34f/0x5c0 [xfs]\n' +
      '  xfs_ioc_scrubv_metadata+0x387/0x560 [xfs]\n' +
      '  xfs_file_ioctl+0xe23/0x10e0 [xfs]\n' +
      '  __x64_sys_ioctl+0x76/0xc0\n' +
      '  do_syscall_64+0x4e/0x1e0\n' +
      '  entry_SYSCALL_64_after_hwframe+0x4b/0x53\n' +
      '\n' +
      ' kfence-#184 0xffff88843fe9df80-0xffff88843fe9dfea, size=107, cache=kmalloc-128\n' +
      '\n' +
      ' allocated by task 3470 on cpu 1 at 263329.131592s (192823.508886s ago)\n' +
      '  xfs_init_local_fork+0x79/0xe0 [xfs]\n' +
      '  xfs_iformat_local+0xa4/0x170 [xfs]\n' +
      '  xfs_iformat_data_fork+0x148/0x180 [xfs]\n' +
      '  xfs_inode_from_disk+0x2cd/0x480 [xfs]\n' +
      '  xfs_iget+0x450/0xd60 [xfs]\n' +
      '  xfs_bulkstat_one_int+0x6b/0x510 [xfs]\n' +
      '  xfs_bulkstat_iwalk+0x1e/0x30 [xfs]\n' +
      '  xfs_iwalk_ag_recs+0xdf/0x150 [xfs]\n' +
      '  xfs_iwalk_run_callbacks+0xb9/0x190 [xfs]\n' +
      '  xfs_iwalk_ag+0x1dc/0x2f0 [xfs]\n' +
      '  xfs_iwalk_args.constprop.0+0x6a/0x120 [xfs]\n' +
      '  xfs_iwalk+0xa4/0xd0 [xfs]\n' +
      '  xfs_bulkstat+0xfa/0x170 [xfs]\n' +
      '  xfs_ioc_fsbulkstat.isra.0+0x13a/0x230 [xfs]\n' +
      '  xfs_file_ioctl+0xbf2/0x10e0 [xfs]\n' +
      '  __x64_sys_ioctl+0x76/0xc0\n' +
      '  do_syscall_64+0x4e/0x1e0\n' +
      '  entry_SYSCALL_64_after_hwframe+0x4b/0x53\n' +
      '\n' +
      ' CPU 1 UID 0 PID 1300113 Comm xfs_scrub Not tainted 6.18.0-rc4-djwx #rc4 PREEMPT(lazy)  3d744dd94e92690f00a04398d2bd8631dcef1954\n' +
      ' Hardware name QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.16.0-4.module+el8.8.0+21164+ed375313 04/01/2014\n' +
      ' ==================================================================\n' +
      '\n' +
      'On further analysis, I realized that the second parameter to min() is\n' +
      'not correct.  xfs_iforkif_bytes is the size of the xfs_iforkif_data\n' +
      'buffer.  if_bytes can be smaller than the data fork size because\n' +
      '\n' +
      '(a) the forkoff code tries to keep the data area as large as possible\n' +
      '(b) for symbolic links, if_bytes is the ondisk file size + 1\n' +
      '(c) forkoff is always a multiple of 8.\n' +
      '\n' +
      'Case in point for a single-byte symlink target, forkoff will be\n' +
      '8 but the buffer will only be 2 bytes long.\n' +
      '\n' +
      'In other words, the logic here is wrong and we walk off the end of the\n' +
      'incore buffer.  Fix that. | Severity UNKNOWN  ',
    contentSnippet: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'xfs fix out of bounds memory read error in symlink repair\n' +
      '\n' +
      'xfs/286 produced this report on my test fleet\n' +
      '\n' +
      ' ==================================================================\n' +
      ' BUG KFENCE out-of-bounds read in memcpy_orig+0x54/0x110\n' +
      '\n' +
      ' Out-of-bounds read at 0xffff88843fe9e038 (184B right of kfence-#184)\n' +
      '  memcpy_orig+0x54/0x110\n' +
      '  xrep_symlink_salvage_inline+0xb3/0xf0 [xfs]\n' +
      '  xrep_symlink_salvage+0x100/0x110 [xfs]\n' +
      '  xrep_symlink+0x2e/0x80 [xfs]\n' +
      '  xrep_attempt+0x61/0x1f0 [xfs]\n' +
      '  xfs_scrub_metadata+0x34f/0x5c0 [xfs]\n' +
      '  xfs_ioc_scrubv_metadata+0x387/0x560 [xfs]\n' +
      '  xfs_file_ioctl+0xe23/0x10e0 [xfs]\n' +
      '  __x64_sys_ioctl+0x76/0xc0\n' +
      '  do_syscall_64+0x4e/0x1e0\n' +
      '  entry_SYSCALL_64_after_hwframe+0x4b/0x53\n' +
      '\n' +
      ' kfence-#184 0xffff88843fe9df80-0xffff88843fe9dfea, size=107, cache=kmalloc-128\n' +
      '\n' +
      ' allocated by task 3470 on cpu 1 at 263329.131592s (192823.508886s ago)\n' +
      '  xfs_init_local_fork+0x79/0xe0 [xfs]\n' +
      '  xfs_iformat_local+0xa4/0x170 [xfs]\n' +
      '  xfs_iformat_data_fork+0x148/0x180 [xfs]\n' +
      '  xfs_inode_from_disk+0x2cd/0x480 [xfs]\n' +
      '  xfs_iget+0x450/0xd60 [xfs]\n' +
      '  xfs_bulkstat_one_int+0x6b/0x510 [xfs]\n' +
      '  xfs_bulkstat_iwalk+0x1e/0x30 [xfs]\n' +
      '  xfs_iwalk_ag_recs+0xdf/0x150 [xfs]\n' +
      '  xfs_iwalk_run_callbacks+0xb9/0x190 [xfs]\n' +
      '  xfs_iwalk_ag+0x1dc/0x2f0 [xfs]\n' +
      '  xfs_iwalk_args.constprop.0+0x6a/0x120 [xfs]\n' +
      '  xfs_iwalk+0xa4/0xd0 [xfs]\n' +
      '  xfs_bulkstat+0xfa/0x170 [xfs]\n' +
      '  xfs_ioc_fsbulkstat.isra.0+0x13a/0x230 [xfs]\n' +
      '  xfs_file_ioctl+0xbf2/0x10e0 [xfs]\n' +
      '  __x64_sys_ioctl+0x76/0xc0\n' +
      '  do_syscall_64+0x4e/0x1e0\n' +
      '  entry_SYSCALL_64_after_hwframe+0x4b/0x53\n' +
      '\n' +
      ' CPU 1 UID 0 PID 1300113 Comm xfs_scrub Not tainted 6.18.0-rc4-djwx #rc4 PREEMPT(lazy)  3d744dd94e92690f00a04398d2bd8631dcef1954\n' +
      ' Hardware name QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.16.0-4.module+el8.8.0+21164+ed375313 04/01/2014\n' +
      ' ==================================================================\n' +
      '\n' +
      'On further analysis, I realized that the second parameter to min() is\n' +
      'not correct.  xfs_iforkif_bytes is the size of the xfs_iforkif_data\n' +
      'buffer.  if_bytes can be smaller than the data fork size because\n' +
      '\n' +
      '(a) the forkoff code tries to keep the data area as large as possible\n' +
      '(b) for symbolic links, if_bytes is the ondisk file size + 1\n' +
      '(c) forkoff is always a multiple of 8.\n' +
      '\n' +
      'Case in point for a single-byte symlink target, forkoff will be\n' +
      '8 but the buffer will only be 2 bytes long.\n' +
      '\n' +
      'In other words, the logic here is wrong and we walk off the end of the\n' +
      'incore buffer.  Fix that. | Severity UNKNOWN',
    guid: 'CVE-2025-40246',
    isoDate: '2025-12-04T16:16:00.000Z'
  },
  {
    title: 'CVE-2025-40247 In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'drm/msm Fix pgtable prealloc e...',
    link: 'https//nvd.nist.gov/vuln/detail/CVE-2025-40247',
    pubDate: 'Thu, 04 Dec 2025 16:16:00 GMT',
    content: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'drm/msm Fix pgtable prealloc error path\n' +
      '\n' +
      'The following splat was reported\n' +
      '\n' +
      '    Unable to handle kernel NULL pointer dereference at virtual address 0000000000000010\n' +
      '    Mem abort info\n' +
      '      ESR = 0x0000000096000004\n' +
      '      EC = 0x25 DABT (current EL), IL = 32 bits\n' +
      '      SET = 0, FnV = 0\n' +
      '      EA = 0, S1PTW = 0\n' +
      '      FSC = 0x04 level 0 translation fault\n' +
      '    Data abort info\n' +
      '      ISV = 0, ISS = 0x00000004, ISS2 = 0x00000000\n' +
      '      CM = 0, WnR = 0, TnD = 0, TagAccess = 0\n' +
      '      GCS = 0, Overlay = 0, DirtyBit = 0, Xs = 0\n' +
      '    user pgtable 4k pages, 48-bit VAs, pgdp=00000008d0fd8000\n' +
      '    [0000000000000010] pgd=0000000000000000, p4d=0000000000000000\n' +
      '    Internal error Oops 0000000096000004 [#1]  SMP\n' +
      '    CPU 5 UID 1000 PID 149076 Comm Xwayland Tainted G S                  6.16.0-rc2-00809-g0b6974bb4134-dirty #367 PREEMPT\n' +
      '    Tainted [S]=CPU_OUT_OF_SPEC\n' +
      '    Hardware name Qualcomm Technologies, Inc. SM8650 HDK (DT)\n' +
      '    pstate 83400005 (Nzcv daif +PAN -UAO +TCO +DIT -SSBS BTYPE=--)\n' +
      '    pc  build_detached_freelist+0x28/0x224\n' +
      '    lr  kmem_cache_free_bulk.part.0+0x38/0x244\n' +
      '    sp  ffff000a508c7a20\n' +
      '    x29 ffff000a508c7a20 x28 ffff000a508c7d50 x27 ffffc4e49d16f350\n' +
      '    x26 0000000000000058 x25 00000000fffffffc x24 0000000000000000\n' +
      '    x23 ffff00098c4e1450 x22 00000000fffffffc x21 0000000000000000\n' +
      '    x20 ffff000a508c7af8 x19 0000000000000002 x18 00000000000003e8\n' +
      '    x17 ffff000809523850 x16 ffff000809523820 x15 0000000000401640\n' +
      '    x14 ffff000809371140 x13 0000000000000130 x12 ffff0008b5711e30\n' +
      '    x11 00000000001058fa x10 0000000000000a80 x9  ffff000a508c7940\n' +
      '    x8  ffff000809371ba0 x7  781fffe033087fff x6  0000000000000000\n' +
      '    x5  ffff0008003cd000 x4  781fffe033083fff x3  ffff000a508c7af8\n' +
      '    x2  fffffdffc0000000 x1  0001000000000000 x0  ffff0008001a6a00\n' +
      '    Call trace\n' +
      '     build_detached_freelist+0x28/0x224 (P)\n' +
      '     kmem_cache_free_bulk.part.0+0x38/0x244\n' +
      '     kmem_cache_free_bulk+0x10/0x1c\n' +
      '     msm_iommu_pagetable_prealloc_cleanup+0x3c/0xd0\n' +
      '     msm_vma_job_free+0x30/0x240\n' +
      '     msm_ioctl_vm_bind+0x1d0/0x9a0\n' +
      '     drm_ioctl_kernel+0x84/0x104\n' +
      '     drm_ioctl+0x358/0x4d4\n' +
      '     __arm64_sys_ioctl+0x8c/0xe0\n' +
      '     invoke_syscall+0x44/0x100\n' +
      '     el0_svc_common.constprop.0+0x3c/0xe0\n' +
      '     do_el0_svc+0x18/0x20\n' +
      '     el0_svc+0x30/0x100\n' +
      '     el0t_64_sync_handler+0x104/0x130\n' +
      '     el0t_64_sync+0x170/0x174\n' +
      '    Code aa0203f5 b26287e2 f2dfbfe2 aa0303f4 (f8737ab6)\n' +
      '    ---[ end trace 0000000000000000 ]---\n' +
      '\n' +
      'Since msm_vma_job_free() is called directly from the ioctl, this looks\n' +
      'like an error path cleanup issue.  Which I think results from\n' +
      'prealloc_cleanup() called without a preceding successful\n' +
      'prealloc_allocate() call.  So handle that case better.\n' +
      '\n' +
      'Patchwork https//patchwork.freedesktop.org/patch/678677/ | Severity UNKNOWN  ',
    contentSnippet: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'drm/msm Fix pgtable prealloc error path\n' +
      '\n' +
      'The following splat was reported\n' +
      '\n' +
      '    Unable to handle kernel NULL pointer dereference at virtual address 0000000000000010\n' +
      '    Mem abort info\n' +
      '      ESR = 0x0000000096000004\n' +
      '      EC = 0x25 DABT (current EL), IL = 32 bits\n' +
      '      SET = 0, FnV = 0\n' +
      '      EA = 0, S1PTW = 0\n' +
      '      FSC = 0x04 level 0 translation fault\n' +
      '    Data abort info\n' +
      '      ISV = 0, ISS = 0x00000004, ISS2 = 0x00000000\n' +
      '      CM = 0, WnR = 0, TnD = 0, TagAccess = 0\n' +
      '      GCS = 0, Overlay = 0, DirtyBit = 0, Xs = 0\n' +
      '    user pgtable 4k pages, 48-bit VAs, pgdp=00000008d0fd8000\n' +
      '    [0000000000000010] pgd=0000000000000000, p4d=0000000000000000\n' +
      '    Internal error Oops 0000000096000004 [#1]  SMP\n' +
      '    CPU 5 UID 1000 PID 149076 Comm Xwayland Tainted G S                  6.16.0-rc2-00809-g0b6974bb4134-dirty #367 PREEMPT\n' +
      '    Tainted [S]=CPU_OUT_OF_SPEC\n' +
      '    Hardware name Qualcomm Technologies, Inc. SM8650 HDK (DT)\n' +
      '    pstate 83400005 (Nzcv daif +PAN -UAO +TCO +DIT -SSBS BTYPE=--)\n' +
      '    pc  build_detached_freelist+0x28/0x224\n' +
      '    lr  kmem_cache_free_bulk.part.0+0x38/0x244\n' +
      '    sp  ffff000a508c7a20\n' +
      '    x29 ffff000a508c7a20 x28 ffff000a508c7d50 x27 ffffc4e49d16f350\n' +
      '    x26 0000000000000058 x25 00000000fffffffc x24 0000000000000000\n' +
      '    x23 ffff00098c4e1450 x22 00000000fffffffc x21 0000000000000000\n' +
      '    x20 ffff000a508c7af8 x19 0000000000000002 x18 00000000000003e8\n' +
      '    x17 ffff000809523850 x16 ffff000809523820 x15 0000000000401640\n' +
      '    x14 ffff000809371140 x13 0000000000000130 x12 ffff0008b5711e30\n' +
      '    x11 00000000001058fa x10 0000000000000a80 x9  ffff000a508c7940\n' +
      '    x8  ffff000809371ba0 x7  781fffe033087fff x6  0000000000000000\n' +
      '    x5  ffff0008003cd000 x4  781fffe033083fff x3  ffff000a508c7af8\n' +
      '    x2  fffffdffc0000000 x1  0001000000000000 x0  ffff0008001a6a00\n' +
      '    Call trace\n' +
      '     build_detached_freelist+0x28/0x224 (P)\n' +
      '     kmem_cache_free_bulk.part.0+0x38/0x244\n' +
      '     kmem_cache_free_bulk+0x10/0x1c\n' +
      '     msm_iommu_pagetable_prealloc_cleanup+0x3c/0xd0\n' +
      '     msm_vma_job_free+0x30/0x240\n' +
      '     msm_ioctl_vm_bind+0x1d0/0x9a0\n' +
      '     drm_ioctl_kernel+0x84/0x104\n' +
      '     drm_ioctl+0x358/0x4d4\n' +
      '     __arm64_sys_ioctl+0x8c/0xe0\n' +
      '     invoke_syscall+0x44/0x100\n' +
      '     el0_svc_common.constprop.0+0x3c/0xe0\n' +
      '     do_el0_svc+0x18/0x20\n' +
      '     el0_svc+0x30/0x100\n' +
      '     el0t_64_sync_handler+0x104/0x130\n' +
      '     el0t_64_sync+0x170/0x174\n' +
      '    Code aa0203f5 b26287e2 f2dfbfe2 aa0303f4 (f8737ab6)\n' +
      '    ---[ end trace 0000000000000000 ]---\n' +
      '\n' +
      'Since msm_vma_job_free() is called directly from the ioctl, this looks\n' +
      'like an error path cleanup issue.  Which I think results from\n' +
      'prealloc_cleanup() called without a preceding successful\n' +
      'prealloc_allocate() call.  So handle that case better.\n' +
      '\n' +
      'Patchwork https//patchwork.freedesktop.org/patch/678677/ | Severity UNKNOWN',
    guid: 'CVE-2025-40247',
    isoDate: '2025-12-04T16:16:00.000Z'
  },
  {
    title: 'CVE-2025-40248 In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'vsock Ignore signal/timeout on...',
    link: 'https//nvd.nist.gov/vuln/detail/CVE-2025-40248',
    pubDate: 'Thu, 04 Dec 2025 16:16:00 GMT',
    content: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'vsock Ignore signal/timeout on connect() if already established\n' +
      '\n' +
      'During connect(), acting on a signal/timeout by disconnecting an already\n' +
      'established socket leads to several issues\n' +
      '\n' +
      '1. connect() invoking vsock_transport_cancel_pkt() ->\n' +
      '   virtio_transport_purge_skbs() may race with sendmsg() invoking\n' +
      '   virtio_transport_get_credit(). This results in a permanently elevated\n' +
      '   `vvs->bytes_unsent`. Which, in turn, confuses the SOCK_LINGER handling.\n' +
      '\n' +
      "2. connect() resetting a connected socket's state may race with socket\n" +
      '   being placed in a sockmap. A disconnected socket remaining in a sockmap\n' +
      "   breaks sockmap's assumptions. And gives rise to WARNs.\n" +
      '\n' +
      '3. connect() transitioning SS_CONNECTED -> SS_UNCONNECTED allows for a\n' +
      '   transport change/drop after TCP_ESTABLISHED. Which poses a problem for\n' +
      '   any simultaneous sendmsg() or connect() and may result in a\n' +
      '   use-after-free/null-ptr-deref.\n' +
      '\n' +
      'Do not disconnect socket on signal/timeout. Keep the logic for unconnected\n' +
      "sockets they don't linger, can't be placed in a sockmap, are rejected by\n" +
      'sendmsg().\n' +
      '\n' +
      '[1] https//lore.kernel.org/netdev/e07fd95c-9a38-4eea-9638-133e38c2ec9b@rbox.co/\n' +
      '[2] https//lore.kernel.org/netdev/20250317-vsock-trans-signal-race-v4-0-fc8837f3f1d4@rbox.co/\n' +
      '[3] https//lore.kernel.org/netdev/60f1b7db-3099-4f6a-875e-af9f6ef194f6@rbox.co/ | Severity UNKNOWN  ',
    contentSnippet: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'vsock Ignore signal/timeout on connect() if already established\n' +
      '\n' +
      'During connect(), acting on a signal/timeout by disconnecting an already\n' +
      'established socket leads to several issues\n' +
      '\n' +
      '1. connect() invoking vsock_transport_cancel_pkt() ->\n' +
      '   virtio_transport_purge_skbs() may race with sendmsg() invoking\n' +
      '   virtio_transport_get_credit(). This results in a permanently elevated\n' +
      '   `vvs->bytes_unsent`. Which, in turn, confuses the SOCK_LINGER handling.\n' +
      '\n' +
      "2. connect() resetting a connected socket's state may race with socket\n" +
      '   being placed in a sockmap. A disconnected socket remaining in a sockmap\n' +
      "   breaks sockmap's assumptions. And gives rise to WARNs.\n" +
      '\n' +
      '3. connect() transitioning SS_CONNECTED -> SS_UNCONNECTED allows for a\n' +
      '   transport change/drop after TCP_ESTABLISHED. Which poses a problem for\n' +
      '   any simultaneous sendmsg() or connect() and may result in a\n' +
      '   use-after-free/null-ptr-deref.\n' +
      '\n' +
      'Do not disconnect socket on signal/timeout. Keep the logic for unconnected\n' +
      "sockets they don't linger, can't be placed in a sockmap, are rejected by\n" +
      'sendmsg().\n' +
      '\n' +
      '[1] https//lore.kernel.org/netdev/e07fd95c-9a38-4eea-9638-133e38c2ec9b@rbox.co/\n' +
      '[2] https//lore.kernel.org/netdev/20250317-vsock-trans-signal-race-v4-0-fc8837f3f1d4@rbox.co/\n' +
      '[3] https//lore.kernel.org/netdev/60f1b7db-3099-4f6a-875e-af9f6ef194f6@rbox.co/ | Severity UNKNOWN',
    guid: 'CVE-2025-40248',
    isoDate: '2025-12-04T16:16:00.000Z'
  },
  {
    title: 'CVE-2025-40249 In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'gpio cdev make sure the cdev ...',
    link: 'https//nvd.nist.gov/vuln/detail/CVE-2025-40249',
    pubDate: 'Thu, 04 Dec 2025 16:16:00 GMT',
    content: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'gpio cdev make sure the cdev fd is still active before emitting events\n' +
      '\n' +
      'With the final call to fput() on a file descriptor, the release action\n' +
      'may be deferred and scheduled on a work queue. The reference count of\n' +
      "that descriptor is still zero and it must not be used. It's possible\n" +
      'that a GPIO change, we want to notify the user-space about, happens\n' +
      'AFTER the reference count on the file descriptor associated with the\n' +
      'character device went down to zero but BEFORE the .release() callback\n' +
      'was called from the workqueue and so BEFORE we unregistered from the\n' +
      'notifier.\n' +
      '\n' +
      'Using the regular get_file() routine in this situation triggers the\n' +
      'following warning\n' +
      '\n' +
      '  struct filef_count incremented from zero use-after-free condition present!\n' +
      '\n' +
      'So use the get_file_active() variant that will return NULL on file\n' +
      'descriptors that have been or are being released. | Severity UNKNOWN  ',
    contentSnippet: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'gpio cdev make sure the cdev fd is still active before emitting events\n' +
      '\n' +
      'With the final call to fput() on a file descriptor, the release action\n' +
      'may be deferred and scheduled on a work queue. The reference count of\n' +
      "that descriptor is still zero and it must not be used. It's possible\n" +
      'that a GPIO change, we want to notify the user-space about, happens\n' +
      'AFTER the reference count on the file descriptor associated with the\n' +
      'character device went down to zero but BEFORE the .release() callback\n' +
      'was called from the workqueue and so BEFORE we unregistered from the\n' +
      'notifier.\n' +
      '\n' +
      'Using the regular get_file() routine in this situation triggers the\n' +
      'following warning\n' +
      '\n' +
      '  struct filef_count incremented from zero use-after-free condition present!\n' +
      '\n' +
      'So use the get_file_active() variant that will return NULL on file\n' +
      'descriptors that have been or are being released. | Severity UNKNOWN',
    guid: 'CVE-2025-40249',
    isoDate: '2025-12-04T16:16:00.000Z'
  },
  {
    title: 'CVE-2025-40250 In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'net/mlx5 Clean up only new IRQ...',
    link: 'https//nvd.nist.gov/vuln/detail/CVE-2025-40250',
    pubDate: 'Thu, 04 Dec 2025 16:16:00 GMT',
    content: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'net/mlx5 Clean up only new IRQ glue on request_irq() failure\n' +
      '\n' +
      'The mlx5_irq_alloc() function can inadvertently free the entire rmap\n' +
      'and end up in a crash[1] when the other threads tries to access this,\n' +
      'when request_irq() fails due to exhausted IRQ vectors. This commit\n' +
      'modifies the cleanup to remove only the specific IRQ mapping that was\n' +
      'just added.\n' +
      '\n' +
      'This prevents removal of other valid mappings and ensures precise\n' +
      "cleanup of the failed IRQ allocation's associated glue object.\n" +
      '\n' +
      'Note This error is observed when both fwctl and rds configs are enabled.\n' +
      '\n' +
      '[1]\n' +
      'mlx5_core 00000500.0 Successfully registered panic handler for port 1\n' +
      'mlx5_core 00000500.0 mlx5_irq_alloc293(pid 66740) Failed to\n' +
      'request irq. err = -28\n' +
      'infiniband mlx5_0 mlx5_ib_test_wc290(pid 66740) Error -28 while\n' +
      'trying to test write-combining support\n' +
      'mlx5_core 00000500.0 Successfully unregistered panic handler for port 1\n' +
      'mlx5_core 00000600.0 Successfully registered panic handler for port 1\n' +
      'mlx5_core 00000600.0 mlx5_irq_alloc293(pid 66740) Failed to\n' +
      'request irq. err = -28\n' +
      'infiniband mlx5_0 mlx5_ib_test_wc290(pid 66740) Error -28 while\n' +
      'trying to test write-combining support\n' +
      'mlx5_core 00000600.0 Successfully unregistered panic handler for port 1\n' +
      'mlx5_core 00000300.0 mlx5_irq_alloc293(pid 28895) Failed to\n' +
      'request irq. err = -28\n' +
      'mlx5_core 00000500.0 mlx5_irq_alloc293(pid 28895) Failed to\n' +
      'request irq. err = -28\n' +
      'general protection fault, probably for non-canonical address\n' +
      '0xe277a58fde16f291 0000 [#1] SMP NOPTI\n' +
      '\n' +
      'RIP 0010free_irq_cpu_rmap+0x23/0x7d\n' +
      'Call Trace\n' +
      '   TASK>\n' +
      '   ? show_trace_log_lvl+0x1d6/0x2f9\n' +
      '   ? show_trace_log_lvl+0x1d6/0x2f9\n' +
      '   ? mlx5_irq_alloc.cold+0x5d/0xf3 [mlx5_core]\n' +
      '   ? __die_body.cold+0x8/0xa\n' +
      '   ? die_addr+0x39/0x53\n' +
      '   ? exc_general_protection+0x1c4/0x3e9\n' +
      '   ? dev_vprintk_emit+0x5f/0x90\n' +
      '   ? asm_exc_general_protection+0x22/0x27\n' +
      '   ? free_irq_cpu_rmap+0x23/0x7d\n' +
      '   mlx5_irq_alloc.cold+0x5d/0xf3 [mlx5_core]\n' +
      '   irq_pool_request_vector+0x7d/0x90 [mlx5_core]\n' +
      '   mlx5_irq_request+0x2e/0xe0 [mlx5_core]\n' +
      '   mlx5_irq_request_vector+0xad/0xf7 [mlx5_core]\n' +
      '   comp_irq_request_pci+0x64/0xf0 [mlx5_core]\n' +
      '   create_comp_eq+0x71/0x385 [mlx5_core]\n' +
      '   ? mlx5e_open_xdpsq+0x11c/0x230 [mlx5_core]\n' +
      '   mlx5_comp_eqn_get+0x72/0x90 [mlx5_core]\n' +
      '   ? xas_load+0x8/0x91\n' +
      '   mlx5_comp_irqn_get+0x40/0x90 [mlx5_core]\n' +
      '   mlx5e_open_channel+0x7d/0x3c7 [mlx5_core]\n' +
      '   mlx5e_open_channels+0xad/0x250 [mlx5_core]\n' +
      '   mlx5e_open_locked+0x3e/0x110 [mlx5_core]\n' +
      '   mlx5e_open+0x23/0x70 [mlx5_core]\n' +
      '   __dev_open+0xf1/0x1a5\n' +
      '   __dev_change_flags+0x1e1/0x249\n' +
      '   dev_change_flags+0x21/0x5c\n' +
      '   do_setlink+0x28b/0xcc4\n' +
      '   ? __nla_parse+0x22/0x3d\n' +
      '   ? inet6_validate_link_af+0x6b/0x108\n' +
      '   ? cpumask_next+0x1f/0x35\n' +
      '   ? __snmp6_fill_stats64.constprop.0+0x66/0x107\n' +
      '   ? __nla_validate_parse+0x48/0x1e6\n' +
      '   __rtnl_newlink+0x5ff/0xa57\n' +
      '   ? kmem_cache_alloc_trace+0x164/0x2ce\n' +
      '   rtnl_newlink+0x44/0x6e\n' +
      '   rtnetlink_rcv_msg+0x2bb/0x362\n' +
      '   ? __netlink_sendskb+0x4c/0x6c\n' +
      '   ? netlink_unicast+0x28f/0x2ce\n' +
      '   ? rtnl_calcit.isra.0+0x150/0x146\n' +
      '   netlink_rcv_skb+0x5f/0x112\n' +
      '   netlink_unicast+0x213/0x2ce\n' +
      '   netlink_sendmsg+0x24f/0x4d9\n' +
      '   __sock_sendmsg+0x65/0x6a\n' +
      '   ____sys_sendmsg+0x28f/0x2c9\n' +
      '   ? import_iovec+0x17/0x2b\n' +
      '   ___sys_sendmsg+0x97/0xe0\n' +
      '   __sys_sendmsg+0x81/0xd8\n' +
      '   do_syscall_64+0x35/0x87\n' +
      '   entry_SYSCALL_64_after_hwframe+0x6e/0x0\n' +
      'RIP 00330x7fc328603727\n' +
      'Code c3 66 90 41 54 41 89 d4 55 48 89 f5 53 89 fb 48 83 ec 10 e8 0b ed\n' +
      'ff ff 44 89 e2 48 89 ee 89 df 41 89 c0 b8 2e 00 00 00 0f 05 48> 3d 00\n' +
      'f0 ff ff 77 35 44 89 c7 48 89 44 24 08 e8 44 ed ff ff 48\n' +
      'RSP 002b00007ffe8eb3f1a0 EFLAGS 00000293 ORIG_RAX 000000000000002e\n' +
      'RAX ffffffffffffffda RBX 000000000000000d RCX 00007fc328603727\n' +
      'RDX 0000000000000000 RSI 00007ffe8eb3f1f0 RDI 000000000000000d\n' +
      'RBP 00007ffe8eb3f1f0 R08 0000000000000000 R09 0000000000000000\n' +
      'R10 0000000000000000 R11 0000000000000293 R12 0000000000000000\n' +
      'R13 00000000000\n' +
      '---truncated--- | Severity UNKNOWN  ',
    contentSnippet: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'net/mlx5 Clean up only new IRQ glue on request_irq() failure\n' +
      '\n' +
      'The mlx5_irq_alloc() function can inadvertently free the entire rmap\n' +
      'and end up in a crash[1] when the other threads tries to access this,\n' +
      'when request_irq() fails due to exhausted IRQ vectors. This commit\n' +
      'modifies the cleanup to remove only the specific IRQ mapping that was\n' +
      'just added.\n' +
      '\n' +
      'This prevents removal of other valid mappings and ensures precise\n' +
      "cleanup of the failed IRQ allocation's associated glue object.\n" +
      '\n' +
      'Note This error is observed when both fwctl and rds configs are enabled.\n' +
      '\n' +
      '[1]\n' +
      'mlx5_core 00000500.0 Successfully registered panic handler for port 1\n' +
      'mlx5_core 00000500.0 mlx5_irq_alloc293(pid 66740) Failed to\n' +
      'request irq. err = -28\n' +
      'infiniband mlx5_0 mlx5_ib_test_wc290(pid 66740) Error -28 while\n' +
      'trying to test write-combining support\n' +
      'mlx5_core 00000500.0 Successfully unregistered panic handler for port 1\n' +
      'mlx5_core 00000600.0 Successfully registered panic handler for port 1\n' +
      'mlx5_core 00000600.0 mlx5_irq_alloc293(pid 66740) Failed to\n' +
      'request irq. err = -28\n' +
      'infiniband mlx5_0 mlx5_ib_test_wc290(pid 66740) Error -28 while\n' +
      'trying to test write-combining support\n' +
      'mlx5_core 00000600.0 Successfully unregistered panic handler for port 1\n' +
      'mlx5_core 00000300.0 mlx5_irq_alloc293(pid 28895) Failed to\n' +
      'request irq. err = -28\n' +
      'mlx5_core 00000500.0 mlx5_irq_alloc293(pid 28895) Failed to\n' +
      'request irq. err = -28\n' +
      'general protection fault, probably for non-canonical address\n' +
      '0xe277a58fde16f291 0000 [#1] SMP NOPTI\n' +
      '\n' +
      'RIP 0010free_irq_cpu_rmap+0x23/0x7d\n' +
      'Call Trace\n' +
      '   TASK>\n' +
      '   ? show_trace_log_lvl+0x1d6/0x2f9\n' +
      '   ? show_trace_log_lvl+0x1d6/0x2f9\n' +
      '   ? mlx5_irq_alloc.cold+0x5d/0xf3 [mlx5_core]\n' +
      '   ? __die_body.cold+0x8/0xa\n' +
      '   ? die_addr+0x39/0x53\n' +
      '   ? exc_general_protection+0x1c4/0x3e9\n' +
      '   ? dev_vprintk_emit+0x5f/0x90\n' +
      '   ? asm_exc_general_protection+0x22/0x27\n' +
      '   ? free_irq_cpu_rmap+0x23/0x7d\n' +
      '   mlx5_irq_alloc.cold+0x5d/0xf3 [mlx5_core]\n' +
      '   irq_pool_request_vector+0x7d/0x90 [mlx5_core]\n' +
      '   mlx5_irq_request+0x2e/0xe0 [mlx5_core]\n' +
      '   mlx5_irq_request_vector+0xad/0xf7 [mlx5_core]\n' +
      '   comp_irq_request_pci+0x64/0xf0 [mlx5_core]\n' +
      '   create_comp_eq+0x71/0x385 [mlx5_core]\n' +
      '   ? mlx5e_open_xdpsq+0x11c/0x230 [mlx5_core]\n' +
      '   mlx5_comp_eqn_get+0x72/0x90 [mlx5_core]\n' +
      '   ? xas_load+0x8/0x91\n' +
      '   mlx5_comp_irqn_get+0x40/0x90 [mlx5_core]\n' +
      '   mlx5e_open_channel+0x7d/0x3c7 [mlx5_core]\n' +
      '   mlx5e_open_channels+0xad/0x250 [mlx5_core]\n' +
      '   mlx5e_open_locked+0x3e/0x110 [mlx5_core]\n' +
      '   mlx5e_open+0x23/0x70 [mlx5_core]\n' +
      '   __dev_open+0xf1/0x1a5\n' +
      '   __dev_change_flags+0x1e1/0x249\n' +
      '   dev_change_flags+0x21/0x5c\n' +
      '   do_setlink+0x28b/0xcc4\n' +
      '   ? __nla_parse+0x22/0x3d\n' +
      '   ? inet6_validate_link_af+0x6b/0x108\n' +
      '   ? cpumask_next+0x1f/0x35\n' +
      '   ? __snmp6_fill_stats64.constprop.0+0x66/0x107\n' +
      '   ? __nla_validate_parse+0x48/0x1e6\n' +
      '   __rtnl_newlink+0x5ff/0xa57\n' +
      '   ? kmem_cache_alloc_trace+0x164/0x2ce\n' +
      '   rtnl_newlink+0x44/0x6e\n' +
      '   rtnetlink_rcv_msg+0x2bb/0x362\n' +
      '   ? __netlink_sendskb+0x4c/0x6c\n' +
      '   ? netlink_unicast+0x28f/0x2ce\n' +
      '   ? rtnl_calcit.isra.0+0x150/0x146\n' +
      '   netlink_rcv_skb+0x5f/0x112\n' +
      '   netlink_unicast+0x213/0x2ce\n' +
      '   netlink_sendmsg+0x24f/0x4d9\n' +
      '   __sock_sendmsg+0x65/0x6a\n' +
      '   ____sys_sendmsg+0x28f/0x2c9\n' +
      '   ? import_iovec+0x17/0x2b\n' +
      '   ___sys_sendmsg+0x97/0xe0\n' +
      '   __sys_sendmsg+0x81/0xd8\n' +
      '   do_syscall_64+0x35/0x87\n' +
      '   entry_SYSCALL_64_after_hwframe+0x6e/0x0\n' +
      'RIP 00330x7fc328603727\n' +
      'Code c3 66 90 41 54 41 89 d4 55 48 89 f5 53 89 fb 48 83 ec 10 e8 0b ed\n' +
      'ff ff 44 89 e2 48 89 ee 89 df 41 89 c0 b8 2e 00 00 00 0f 05 48> 3d 00\n' +
      'f0 ff ff 77 35 44 89 c7 48 89 44 24 08 e8 44 ed ff ff 48\n' +
      'RSP 002b00007ffe8eb3f1a0 EFLAGS 00000293 ORIG_RAX 000000000000002e\n' +
      'RAX ffffffffffffffda RBX 000000000000000d RCX 00007fc328603727\n' +
      'RDX 0000000000000000 RSI 00007ffe8eb3f1f0 RDI 000000000000000d\n' +
      'RBP 00007ffe8eb3f1f0 R08 0000000000000000 R09 0000000000000000\n' +
      'R10 0000000000000000 R11 0000000000000293 R12 0000000000000000\n' +
      'R13 00000000000\n' +
      '---truncated--- | Severity UNKNOWN',
    guid: 'CVE-2025-40250',
    isoDate: '2025-12-04T16:16:00.000Z'
  },
  {
    title: 'CVE-2025-40251 In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'devlink rate Unset parent poi...',
    link: 'https//nvd.nist.gov/vuln/detail/CVE-2025-40251',
    pubDate: 'Thu, 04 Dec 2025 16:16:00 GMT',
    content: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'devlink rate Unset parent pointer in devl_rate_nodes_destroy\n' +
      '\n' +
      'The function devl_rate_nodes_destroy is documented to "Unset parent for\n' +
      'all rate objects". However, it was only calling the driver-specific\n' +
      '`rate_leaf_parent_set` or `rate_node_parent_set` ops and decrementing\n' +
      "the parent's refcount, without actually setting the\n" +
      '`devlink_rate->parent` pointer to NULL.\n' +
      '\n' +
      'This leaves a dangling pointer in the `devlink_rate` struct, which cause\n' +
      'refcount error in netdevsim[1] and mlx5[2]. In addition, this is\n' +
      'inconsistent with the behavior of `devlink_nl_rate_parent_node_set`,\n' +
      'where the parent pointer is correctly cleared.\n' +
      '\n' +
      'This patch fixes the issue by explicitly setting `devlink_rate->parent`\n' +
      "to NULL after notifying the driver, thus fulfilling the function's\n" +
      'documented behavior for all rate objects.\n' +
      '\n' +
      '[1]\n' +
      'repro steps\n' +
      'echo 1 > /sys/bus/netdevsim/new_device\n' +
      'devlink dev eswitch set netdevsim/netdevsim1 mode switchdev\n' +
      'echo 1 > /sys/bus/netdevsim/devices/netdevsim1/sriov_numvfs\n' +
      'devlink port function rate add netdevsim/netdevsim1/test_node\n' +
      'devlink port function rate set netdevsim/netdevsim1/128 parent test_node\n' +
      'echo 1 > /sys/bus/netdevsim/del_device\n' +
      '\n' +
      'dmesg\n' +
      'refcount_t decrement hit 0 leaking memory.\n' +
      'WARNING CPU 8 PID 1530 at lib/refcount.c31 refcount_warn_saturate+0x42/0xe0\n' +
      'CPU 8 UID 0 PID 1530 Comm bash Not tainted 6.18.0-rc4+ #1 NONE\n' +
      'Hardware name QEMU Standard PC (Q35 + ICH9, 2009), BIOS rel-1.16.0-0-gd239552ce722-prebuilt.qemu.org 04/01/2014\n' +
      'RIP 0010refcount_warn_saturate+0x42/0xe0\n' +
      'Call Trace\n' +
      ' TASK>\n' +
      ' devl_rate_leaf_destroy+0x8d/0x90\n' +
      ' __nsim_dev_port_del+0x6c/0x70 [netdevsim]\n' +
      ' nsim_dev_reload_destroy+0x11c/0x140 [netdevsim]\n' +
      ' nsim_drv_remove+0x2b/0xb0 [netdevsim]\n' +
      ' device_release_driver_internal+0x194/0x1f0\n' +
      ' bus_remove_device+0xc6/0x130\n' +
      ' device_del+0x159/0x3c0\n' +
      ' device_unregister+0x1a/0x60\n' +
      ' del_device_store+0x111/0x170 [netdevsim]\n' +
      ' kernfs_fop_write_iter+0x12e/0x1e0\n' +
      ' vfs_write+0x215/0x3d0\n' +
      ' ksys_write+0x5f/0xd0\n' +
      ' do_syscall_64+0x55/0x10f0\n' +
      ' entry_SYSCALL_64_after_hwframe+0x4b/0x53\n' +
      '\n' +
      '[2]\n' +
      'devlink dev eswitch set pci/00000800.0 mode switchdev\n' +
      'devlink port add pci/00000800.0 flavour pcisf pfnum 0 sfnum 1000\n' +
      'devlink port function rate add pci/00000800.0/group1\n' +
      'devlink port function rate set pci/00000800.0/32768 parent group1\n' +
      'modprobe -r mlx5_ib mlx5_fwctl mlx5_core\n' +
      '\n' +
      'dmesg\n' +
      'refcount_t decrement hit 0 leaking memory.\n' +
      'WARNING CPU 7 PID 16151 at lib/refcount.c31 refcount_warn_saturate+0x42/0xe0\n' +
      'CPU 7 UID 0 PID 16151 Comm bash Not tainted 6.17.0-rc7_for_upstream_min_debug_2025_10_02_12_44 #1 NONE\n' +
      'Hardware name QEMU Standard PC (Q35 + ICH9, 2009), BIOS rel-1.16.3-0-ga6ed6b701f0a-prebuilt.qemu.org 04/01/2014\n' +
      'RIP 0010refcount_warn_saturate+0x42/0xe0\n' +
      'Call Trace\n' +
      ' TASK>\n' +
      ' devl_rate_leaf_destroy+0x8d/0x90\n' +
      ' mlx5_esw_offloads_devlink_port_unregister+0x33/0x60 [mlx5_core]\n' +
      ' mlx5_esw_offloads_unload_rep+0x3f/0x50 [mlx5_core]\n' +
      ' mlx5_eswitch_unload_sf_vport+0x40/0x90 [mlx5_core]\n' +
      ' mlx5_sf_esw_event+0xc4/0x120 [mlx5_core]\n' +
      ' notifier_call_chain+0x33/0xa0\n' +
      ' blocking_notifier_call_chain+0x3b/0x50\n' +
      ' mlx5_eswitch_disable_locked+0x50/0x110 [mlx5_core]\n' +
      ' mlx5_eswitch_disable+0x63/0x90 [mlx5_core]\n' +
      ' mlx5_unload+0x1d/0x170 [mlx5_core]\n' +
      ' mlx5_uninit_one+0xa2/0x130 [mlx5_core]\n' +
      ' remove_one+0x78/0xd0 [mlx5_core]\n' +
      ' pci_device_remove+0x39/0xa0\n' +
      ' device_release_driver_internal+0x194/0x1f0\n' +
      ' unbind_store+0x99/0xa0\n' +
      ' kernfs_fop_write_iter+0x12e/0x1e0\n' +
      ' vfs_write+0x215/0x3d0\n' +
      ' ksys_write+0x5f/0xd0\n' +
      ' do_syscall_64+0x53/0x1f0\n' +
      ' entry_SYSCALL_64_after_hwframe+0x4b/0x53 | Severity UNKNOWN  ',
    contentSnippet: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'devlink rate Unset parent pointer in devl_rate_nodes_destroy\n' +
      '\n' +
      'The function devl_rate_nodes_destroy is documented to "Unset parent for\n' +
      'all rate objects". However, it was only calling the driver-specific\n' +
      '`rate_leaf_parent_set` or `rate_node_parent_set` ops and decrementing\n' +
      "the parent's refcount, without actually setting the\n" +
      '`devlink_rate->parent` pointer to NULL.\n' +
      '\n' +
      'This leaves a dangling pointer in the `devlink_rate` struct, which cause\n' +
      'refcount error in netdevsim[1] and mlx5[2]. In addition, this is\n' +
      'inconsistent with the behavior of `devlink_nl_rate_parent_node_set`,\n' +
      'where the parent pointer is correctly cleared.\n' +
      '\n' +
      'This patch fixes the issue by explicitly setting `devlink_rate->parent`\n' +
      "to NULL after notifying the driver, thus fulfilling the function's\n" +
      'documented behavior for all rate objects.\n' +
      '\n' +
      '[1]\n' +
      'repro steps\n' +
      'echo 1 > /sys/bus/netdevsim/new_device\n' +
      'devlink dev eswitch set netdevsim/netdevsim1 mode switchdev\n' +
      'echo 1 > /sys/bus/netdevsim/devices/netdevsim1/sriov_numvfs\n' +
      'devlink port function rate add netdevsim/netdevsim1/test_node\n' +
      'devlink port function rate set netdevsim/netdevsim1/128 parent test_node\n' +
      'echo 1 > /sys/bus/netdevsim/del_device\n' +
      '\n' +
      'dmesg\n' +
      'refcount_t decrement hit 0 leaking memory.\n' +
      'WARNING CPU 8 PID 1530 at lib/refcount.c31 refcount_warn_saturate+0x42/0xe0\n' +
      'CPU 8 UID 0 PID 1530 Comm bash Not tainted 6.18.0-rc4+ #1 NONE\n' +
      'Hardware name QEMU Standard PC (Q35 + ICH9, 2009), BIOS rel-1.16.0-0-gd239552ce722-prebuilt.qemu.org 04/01/2014\n' +
      'RIP 0010refcount_warn_saturate+0x42/0xe0\n' +
      'Call Trace\n' +
      ' TASK>\n' +
      ' devl_rate_leaf_destroy+0x8d/0x90\n' +
      ' __nsim_dev_port_del+0x6c/0x70 [netdevsim]\n' +
      ' nsim_dev_reload_destroy+0x11c/0x140 [netdevsim]\n' +
      ' nsim_drv_remove+0x2b/0xb0 [netdevsim]\n' +
      ' device_release_driver_internal+0x194/0x1f0\n' +
      ' bus_remove_device+0xc6/0x130\n' +
      ' device_del+0x159/0x3c0\n' +
      ' device_unregister+0x1a/0x60\n' +
      ' del_device_store+0x111/0x170 [netdevsim]\n' +
      ' kernfs_fop_write_iter+0x12e/0x1e0\n' +
      ' vfs_write+0x215/0x3d0\n' +
      ' ksys_write+0x5f/0xd0\n' +
      ' do_syscall_64+0x55/0x10f0\n' +
      ' entry_SYSCALL_64_after_hwframe+0x4b/0x53\n' +
      '\n' +
      '[2]\n' +
      'devlink dev eswitch set pci/00000800.0 mode switchdev\n' +
      'devlink port add pci/00000800.0 flavour pcisf pfnum 0 sfnum 1000\n' +
      'devlink port function rate add pci/00000800.0/group1\n' +
      'devlink port function rate set pci/00000800.0/32768 parent group1\n' +
      'modprobe -r mlx5_ib mlx5_fwctl mlx5_core\n' +
      '\n' +
      'dmesg\n' +
      'refcount_t decrement hit 0 leaking memory.\n' +
      'WARNING CPU 7 PID 16151 at lib/refcount.c31 refcount_warn_saturate+0x42/0xe0\n' +
      'CPU 7 UID 0 PID 16151 Comm bash Not tainted 6.17.0-rc7_for_upstream_min_debug_2025_10_02_12_44 #1 NONE\n' +
      'Hardware name QEMU Standard PC (Q35 + ICH9, 2009), BIOS rel-1.16.3-0-ga6ed6b701f0a-prebuilt.qemu.org 04/01/2014\n' +
      'RIP 0010refcount_warn_saturate+0x42/0xe0\n' +
      'Call Trace\n' +
      ' TASK>\n' +
      ' devl_rate_leaf_destroy+0x8d/0x90\n' +
      ' mlx5_esw_offloads_devlink_port_unregister+0x33/0x60 [mlx5_core]\n' +
      ' mlx5_esw_offloads_unload_rep+0x3f/0x50 [mlx5_core]\n' +
      ' mlx5_eswitch_unload_sf_vport+0x40/0x90 [mlx5_core]\n' +
      ' mlx5_sf_esw_event+0xc4/0x120 [mlx5_core]\n' +
      ' notifier_call_chain+0x33/0xa0\n' +
      ' blocking_notifier_call_chain+0x3b/0x50\n' +
      ' mlx5_eswitch_disable_locked+0x50/0x110 [mlx5_core]\n' +
      ' mlx5_eswitch_disable+0x63/0x90 [mlx5_core]\n' +
      ' mlx5_unload+0x1d/0x170 [mlx5_core]\n' +
      ' mlx5_uninit_one+0xa2/0x130 [mlx5_core]\n' +
      ' remove_one+0x78/0xd0 [mlx5_core]\n' +
      ' pci_device_remove+0x39/0xa0\n' +
      ' device_release_driver_internal+0x194/0x1f0\n' +
      ' unbind_store+0x99/0xa0\n' +
      ' kernfs_fop_write_iter+0x12e/0x1e0\n' +
      ' vfs_write+0x215/0x3d0\n' +
      ' ksys_write+0x5f/0xd0\n' +
      ' do_syscall_64+0x53/0x1f0\n' +
      ' entry_SYSCALL_64_after_hwframe+0x4b/0x53 | Severity UNKNOWN',
    guid: 'CVE-2025-40251',
    isoDate: '2025-12-04T16:16:00.000Z'
  },
  {
    title: 'CVE-2025-40252 In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'net qlogic/qede fix potential...',
    link: 'https//nvd.nist.gov/vuln/detail/CVE-2025-40252',
    pubDate: 'Thu, 04 Dec 2025 16:16:00 GMT',
    content: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'net qlogic/qede fix potential out-of-bounds read in qede_tpa_cont() and qede_tpa_end()\n' +
      '\n' +
      "The loops in 'qede_tpa_cont()' and 'qede_tpa_end()', iterate\n" +
      "over 'cqe->len_list[]' using only a zero-length terminator as\n" +
      'the stopping condition. If the terminator was missing or\n' +
      'malformed, the loop could run past the end of the fixed-size array.\n' +
      '\n' +
      'Add an explicit bound check using ARRAY_SIZE() in both loops to prevent\n' +
      'a potential out-of-bounds access.\n' +
      '\n' +
      'Found by Linux Verification Center (linuxtesting.org) with SVACE. | Severity UNKNOWN  ',
    contentSnippet: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'net qlogic/qede fix potential out-of-bounds read in qede_tpa_cont() and qede_tpa_end()\n' +
      '\n' +
      "The loops in 'qede_tpa_cont()' and 'qede_tpa_end()', iterate\n" +
      "over 'cqe->len_list[]' using only a zero-length terminator as\n" +
      'the stopping condition. If the terminator was missing or\n' +
      'malformed, the loop could run past the end of the fixed-size array.\n' +
      '\n' +
      'Add an explicit bound check using ARRAY_SIZE() in both loops to prevent\n' +
      'a potential out-of-bounds access.\n' +
      '\n' +
      'Found by Linux Verification Center (linuxtesting.org) with SVACE. | Severity UNKNOWN',
    guid: 'CVE-2025-40252',
    isoDate: '2025-12-04T16:16:00.000Z'
  },
  {
    title: 'CVE-2025-40253 In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      's390/ctcm Fix double-kfree\n' +
      '\n' +
      'Th...',
    link: 'https//nvd.nist.gov/vuln/detail/CVE-2025-40253',
    pubDate: 'Thu, 04 Dec 2025 16:16:00 GMT',
    content: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      's390/ctcm Fix double-kfree\n' +
      '\n' +
      "The function 'mpc_rcvd_sweep_req(mpcginfo)' is called conditionally\n" +
      "from function 'ctcmpc_unpack_skb'. It frees passed mpcginfo.\n" +
      "After that a call to function 'kfree' in function 'ctcmpc_unpack_skb'\n" +
      'frees it again.\n' +
      '\n' +
      "Remove 'kfree' call in function 'mpc_rcvd_sweep_req(mpcginfo)'.\n" +
      '\n' +
      'Bug detected by the clang static analyzer. | Severity UNKNOWN  ',
    contentSnippet: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      's390/ctcm Fix double-kfree\n' +
      '\n' +
      "The function 'mpc_rcvd_sweep_req(mpcginfo)' is called conditionally\n" +
      "from function 'ctcmpc_unpack_skb'. It frees passed mpcginfo.\n" +
      "After that a call to function 'kfree' in function 'ctcmpc_unpack_skb'\n" +
      'frees it again.\n' +
      '\n' +
      "Remove 'kfree' call in function 'mpc_rcvd_sweep_req(mpcginfo)'.\n" +
      '\n' +
      'Bug detected by the clang static analyzer. | Severity UNKNOWN',
    guid: 'CVE-2025-40253',
    isoDate: '2025-12-04T16:16:00.000Z'
  },
  {
    title: 'CVE-2025-40254 In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'net openvswitch remove never-...',
    link: 'https//nvd.nist.gov/vuln/detail/CVE-2025-40254',
    pubDate: 'Thu, 04 Dec 2025 16:16:00 GMT',
    content: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'net openvswitch remove never-working support for setting nsh fields\n' +
      '\n' +
      'The validation of the set(nsh(...)) action is completely wrong.\n' +
      'It runs through the nsh_key_put_from_nlattr() function that is the\n' +
      'same function that validates NSH keys for the flow match and the\n' +
      'push_nsh() action.  However, the set(nsh(...)) has a very different\n' +
      'memory layout.  Nested attributes in there are doubled in size in\n' +
      'case of the masked set().  That makes proper validation impossible.\n' +
      '\n' +
      "There is also confusion in the code between the 'masked' flag, that\n" +
      'says that the nested attributes are doubled in size containing both\n' +
      "the value and the mask, and the 'is_mask' that says that the value\n" +
      "we're parsing is the mask.  This is causing kernel crash on trying to\n" +
      'write into mask part of the match with SW_FLOW_KEY_PUT() during\n' +
      "validation, while validate_nsh() doesn't allocate any memory for it\n" +
      '\n' +
      '  BUG kernel NULL pointer dereference, address 0000000000000018\n' +
      '  #PF supervisor read access in kernel mode\n' +
      '  #PF error_code(0x0000) - not-present page\n' +
      '  PGD 1c2383067 P4D 1c2383067 PUD 20b703067 PMD 0\n' +
      '  Oops Oops 0000 [#1] SMP NOPTI\n' +
      '  CPU 8 UID 0 Kdump loaded Not tainted 6.17.0-rc4+ #107 PREEMPT(voluntary)\n' +
      '  RIP 0010nsh_key_put_from_nlattr+0x19d/0x610 [openvswitch]\n' +
      '  Call Trace\n' +
      '   TASK>\n' +
      '   validate_nsh+0x60/0x90 [openvswitch]\n' +
      '   validate_set.constprop.0+0x270/0x3c0 [openvswitch]\n' +
      '   __ovs_nla_copy_actions+0x477/0x860 [openvswitch]\n' +
      '   ovs_nla_copy_actions+0x8d/0x100 [openvswitch]\n' +
      '   ovs_packet_cmd_execute+0x1cc/0x310 [openvswitch]\n' +
      '   genl_family_rcv_msg_doit+0xdb/0x130\n' +
      '   genl_family_rcv_msg+0x14b/0x220\n' +
      '   genl_rcv_msg+0x47/0xa0\n' +
      '   netlink_rcv_skb+0x53/0x100\n' +
      '   genl_rcv+0x24/0x40\n' +
      '   netlink_unicast+0x280/0x3b0\n' +
      '   netlink_sendmsg+0x1f7/0x430\n' +
      '   ____sys_sendmsg+0x36b/0x3a0\n' +
      '   ___sys_sendmsg+0x87/0xd0\n' +
      '   __sys_sendmsg+0x6d/0xd0\n' +
      '   do_syscall_64+0x7b/0x2c0\n' +
      '   entry_SYSCALL_64_after_hwframe+0x76/0x7e\n' +
      '\n' +
      'The third issue with this process is that while trying to convert\n' +
      'the non-masked set into masked one, validate_set() copies and doubles\n' +
      "the size of the OVS_KEY_ATTR_NSH as if it didn't have any nested\n" +
      'attributes.  It should be copying each nested attribute and doubling\n' +
      'them in size independently.  And the process must be properly reversed\n' +
      'during the conversion back from masked to a non-masked variant during\n' +
      'the flow dump.\n' +
      '\n' +
      'In the end, the only two outcomes of trying to use this action are\n' +
      'either validation failure or a kernel crash.  And if somehow someone\n' +
      'manages to install a flow with such an action, it will most definitely\n' +
      'not do what it is supposed to, since all the keys and the masks are\n' +
      'mixed up.\n' +
      '\n' +
      'Fixing all the issues is a complex task as it requires re-writing\n' +
      'most of the validation code.\n' +
      '\n' +
      'Given that and the fact that this functionality never worked since\n' +
      "introduction, let's just remove it altogether.  It's better to\n" +
      're-introduce it later with a proper implementation instead of trying\n' +
      'to fix it in stable releases. | Severity UNKNOWN  ',
    contentSnippet: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'net openvswitch remove never-working support for setting nsh fields\n' +
      '\n' +
      'The validation of the set(nsh(...)) action is completely wrong.\n' +
      'It runs through the nsh_key_put_from_nlattr() function that is the\n' +
      'same function that validates NSH keys for the flow match and the\n' +
      'push_nsh() action.  However, the set(nsh(...)) has a very different\n' +
      'memory layout.  Nested attributes in there are doubled in size in\n' +
      'case of the masked set().  That makes proper validation impossible.\n' +
      '\n' +
      "There is also confusion in the code between the 'masked' flag, that\n" +
      'says that the nested attributes are doubled in size containing both\n' +
      "the value and the mask, and the 'is_mask' that says that the value\n" +
      "we're parsing is the mask.  This is causing kernel crash on trying to\n" +
      'write into mask part of the match with SW_FLOW_KEY_PUT() during\n' +
      "validation, while validate_nsh() doesn't allocate any memory for it\n" +
      '\n' +
      '  BUG kernel NULL pointer dereference, address 0000000000000018\n' +
      '  #PF supervisor read access in kernel mode\n' +
      '  #PF error_code(0x0000) - not-present page\n' +
      '  PGD 1c2383067 P4D 1c2383067 PUD 20b703067 PMD 0\n' +
      '  Oops Oops 0000 [#1] SMP NOPTI\n' +
      '  CPU 8 UID 0 Kdump loaded Not tainted 6.17.0-rc4+ #107 PREEMPT(voluntary)\n' +
      '  RIP 0010nsh_key_put_from_nlattr+0x19d/0x610 [openvswitch]\n' +
      '  Call Trace\n' +
      '   TASK>\n' +
      '   validate_nsh+0x60/0x90 [openvswitch]\n' +
      '   validate_set.constprop.0+0x270/0x3c0 [openvswitch]\n' +
      '   __ovs_nla_copy_actions+0x477/0x860 [openvswitch]\n' +
      '   ovs_nla_copy_actions+0x8d/0x100 [openvswitch]\n' +
      '   ovs_packet_cmd_execute+0x1cc/0x310 [openvswitch]\n' +
      '   genl_family_rcv_msg_doit+0xdb/0x130\n' +
      '   genl_family_rcv_msg+0x14b/0x220\n' +
      '   genl_rcv_msg+0x47/0xa0\n' +
      '   netlink_rcv_skb+0x53/0x100\n' +
      '   genl_rcv+0x24/0x40\n' +
      '   netlink_unicast+0x280/0x3b0\n' +
      '   netlink_sendmsg+0x1f7/0x430\n' +
      '   ____sys_sendmsg+0x36b/0x3a0\n' +
      '   ___sys_sendmsg+0x87/0xd0\n' +
      '   __sys_sendmsg+0x6d/0xd0\n' +
      '   do_syscall_64+0x7b/0x2c0\n' +
      '   entry_SYSCALL_64_after_hwframe+0x76/0x7e\n' +
      '\n' +
      'The third issue with this process is that while trying to convert\n' +
      'the non-masked set into masked one, validate_set() copies and doubles\n' +
      "the size of the OVS_KEY_ATTR_NSH as if it didn't have any nested\n" +
      'attributes.  It should be copying each nested attribute and doubling\n' +
      'them in size independently.  And the process must be properly reversed\n' +
      'during the conversion back from masked to a non-masked variant during\n' +
      'the flow dump.\n' +
      '\n' +
      'In the end, the only two outcomes of trying to use this action are\n' +
      'either validation failure or a kernel crash.  And if somehow someone\n' +
      'manages to install a flow with such an action, it will most definitely\n' +
      'not do what it is supposed to, since all the keys and the masks are\n' +
      'mixed up.\n' +
      '\n' +
      'Fixing all the issues is a complex task as it requires re-writing\n' +
      'most of the validation code.\n' +
      '\n' +
      'Given that and the fact that this functionality never worked since\n' +
      "introduction, let's just remove it altogether.  It's better to\n" +
      're-introduce it later with a proper implementation instead of trying\n' +
      'to fix it in stable releases. | Severity UNKNOWN',
    guid: 'CVE-2025-40254',
    isoDate: '2025-12-04T16:16:00.000Z'
  },
  {
    title: 'CVE-2025-40255 In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'net core prevent NULL deref i...',
    link: 'https//nvd.nist.gov/vuln/detail/CVE-2025-40255',
    pubDate: 'Thu, 04 Dec 2025 16:16:00 GMT',
    content: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'net core prevent NULL deref in generic_hwtstamp_ioctl_lower()\n' +
      '\n' +
      'The ethtool tsconfig Netlink path can trigger a null pointer\n' +
      'dereference. A call chain such as\n' +
      '\n' +
      '  tsconfig_prepare_data() ->\n' +
      '  dev_get_hwtstamp_phylib() ->\n' +
      '  vlan_hwtstamp_get() ->\n' +
      '  generic_hwtstamp_get_lower() ->\n' +
      '  generic_hwtstamp_ioctl_lower()\n' +
      '\n' +
      'results in generic_hwtstamp_ioctl_lower() being called with\n' +
      'kernel_cfg->ifr as NULL.\n' +
      '\n' +
      'The generic_hwtstamp_ioctl_lower() function does not expect\n' +
      'a NULL ifr and dereferences it, leading to a system crash.\n' +
      '\n' +
      'Fix this by adding a NULL check for kernel_cfg->ifr in\n' +
      'generic_hwtstamp_ioctl_lower(). If ifr is NULL, return -EINVAL. | Severity UNKNOWN  ',
    contentSnippet: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'net core prevent NULL deref in generic_hwtstamp_ioctl_lower()\n' +
      '\n' +
      'The ethtool tsconfig Netlink path can trigger a null pointer\n' +
      'dereference. A call chain such as\n' +
      '\n' +
      '  tsconfig_prepare_data() ->\n' +
      '  dev_get_hwtstamp_phylib() ->\n' +
      '  vlan_hwtstamp_get() ->\n' +
      '  generic_hwtstamp_get_lower() ->\n' +
      '  generic_hwtstamp_ioctl_lower()\n' +
      '\n' +
      'results in generic_hwtstamp_ioctl_lower() being called with\n' +
      'kernel_cfg->ifr as NULL.\n' +
      '\n' +
      'The generic_hwtstamp_ioctl_lower() function does not expect\n' +
      'a NULL ifr and dereferences it, leading to a system crash.\n' +
      '\n' +
      'Fix this by adding a NULL check for kernel_cfg->ifr in\n' +
      'generic_hwtstamp_ioctl_lower(). If ifr is NULL, return -EINVAL. | Severity UNKNOWN',
    guid: 'CVE-2025-40255',
    isoDate: '2025-12-04T16:16:00.000Z'
  },
  {
    title: 'CVE-2025-40256 In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'xfrm also call xfrm_state_dele...',
    link: 'https//nvd.nist.gov/vuln/detail/CVE-2025-40256',
    pubDate: 'Thu, 04 Dec 2025 16:16:00 GMT',
    content: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'xfrm also call xfrm_state_delete_tunnel at destroy time for states that were never added\n' +
      '\n' +
      'In commit b441cf3f8c4b ("xfrm delete x->tunnel as we delete x"), I\n' +
      'missed the case where state creation fails between full\n' +
      'initialization (->init_state has been called) and being inserted on\n' +
      'the lists.\n' +
      '\n' +
      'In this situation, ->init_state has been called, so for IPcomp\n' +
      'tunnels, the fallback tunnel has been created and added onto the\n' +
      'lists, but the user state never gets added, because we fail before\n' +
      "that. The user state doesn't go through __xfrm_state_delete, so we\n" +
      "don't call xfrm_state_delete_tunnel for those states, and we end up\n" +
      'leaking the FB tunnel.\n' +
      '\n' +
      'There are several codepaths affected by this the add/update paths, in\n' +
      'both net/key and xfrm, and the migrate code (xfrm_migrate,\n' +
      'xfrm_state_migrate). A "proper" rollback of the init_state work would\n' +
      'probably be doable in the add/update code, but for migrate it gets\n' +
      'more complicated as multiple states may be involved.\n' +
      '\n' +
      'At some point, the new (not-inserted) state will be destroyed, so call\n' +
      'xfrm_state_delete_tunnel during xfrm_state_gc_destroy. Most states\n' +
      'will have their fallback tunnel cleaned up during __xfrm_state_delete,\n' +
      'which solves the issue that b441cf3f8c4b (and other patches before it)\n' +
      'aimed at. All states (including FB tunnels) will be removed from the\n' +
      'lists once xfrm_state_fini has called flush_work(xfrm_state_gc_work). | Severity UNKNOWN  ',
    contentSnippet: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'xfrm also call xfrm_state_delete_tunnel at destroy time for states that were never added\n' +
      '\n' +
      'In commit b441cf3f8c4b ("xfrm delete x->tunnel as we delete x"), I\n' +
      'missed the case where state creation fails between full\n' +
      'initialization (->init_state has been called) and being inserted on\n' +
      'the lists.\n' +
      '\n' +
      'In this situation, ->init_state has been called, so for IPcomp\n' +
      'tunnels, the fallback tunnel has been created and added onto the\n' +
      'lists, but the user state never gets added, because we fail before\n' +
      "that. The user state doesn't go through __xfrm_state_delete, so we\n" +
      "don't call xfrm_state_delete_tunnel for those states, and we end up\n" +
      'leaking the FB tunnel.\n' +
      '\n' +
      'There are several codepaths affected by this the add/update paths, in\n' +
      'both net/key and xfrm, and the migrate code (xfrm_migrate,\n' +
      'xfrm_state_migrate). A "proper" rollback of the init_state work would\n' +
      'probably be doable in the add/update code, but for migrate it gets\n' +
      'more complicated as multiple states may be involved.\n' +
      '\n' +
      'At some point, the new (not-inserted) state will be destroyed, so call\n' +
      'xfrm_state_delete_tunnel during xfrm_state_gc_destroy. Most states\n' +
      'will have their fallback tunnel cleaned up during __xfrm_state_delete,\n' +
      'which solves the issue that b441cf3f8c4b (and other patches before it)\n' +
      'aimed at. All states (including FB tunnels) will be removed from the\n' +
      'lists once xfrm_state_fini has called flush_work(xfrm_state_gc_work). | Severity UNKNOWN',
    guid: 'CVE-2025-40256',
    isoDate: '2025-12-04T16:16:00.000Z'
  },
  {
    title: 'CVE-2025-40257 In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'mptcp fix a race in mptcp_pm_d...',
    link: 'https//nvd.nist.gov/vuln/detail/CVE-2025-40257',
    pubDate: 'Thu, 04 Dec 2025 16:16:00 GMT',
    content: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'mptcp fix a race in mptcp_pm_del_add_timer()\n' +
      '\n' +
      'mptcp_pm_del_add_timer() can call sk_stop_timer_sync(sk, entry->add_timer)\n' +
      'while another might have free entry already, as reported by syzbot.\n' +
      '\n' +
      'Add RCU protection to fix this issue.\n' +
      '\n' +
      'Also change confusing add_timer variable with stop_timer boolean.\n' +
      '\n' +
      'syzbot report\n' +
      '\n' +
      'BUG KASAN slab-use-after-free in __timer_delete_sync+0x372/0x3f0 kernel/time/timer.c1616\n' +
      'Read of size 4 at addr ffff8880311e4150 by task kworker/11/44\n' +
      '\n' +
      'CPU 1 UID 0 PID 44 Comm kworker/11 Not tainted syzkaller #0 PREEMPT_{RT,(full)}\n' +
      'Hardware name Google Google Compute Engine/Google Compute Engine, BIOS Google 10/02/2025\n' +
      'Workqueue events mptcp_worker\n' +
      'Call Trace\n' +
      ' TASK>\n' +
      '  dump_stack_lvl+0x189/0x250 lib/dump_stack.c120\n' +
      '  print_address_description mm/kasan/report.c378 [inline]\n' +
      '  print_report+0xca/0x240 mm/kasan/report.c482\n' +
      '  kasan_report+0x118/0x150 mm/kasan/report.c595\n' +
      '  __timer_delete_sync+0x372/0x3f0 kernel/time/timer.c1616\n' +
      '  sk_stop_timer_sync+0x1b/0x90 net/core/sock.c3631\n' +
      '  mptcp_pm_del_add_timer+0x283/0x310 net/mptcp/pm.c362\n' +
      '  mptcp_incoming_options+0x1357/0x1f60 net/mptcp/options.c1174\n' +
      '  tcp_data_queue+0xca/0x6450 net/ipv4/tcp_input.c5361\n' +
      '  tcp_rcv_established+0x1335/0x2670 net/ipv4/tcp_input.c6441\n' +
      '  tcp_v4_do_rcv+0x98b/0xbf0 net/ipv4/tcp_ipv4.c1931\n' +
      '  tcp_v4_rcv+0x252a/0x2dc0 net/ipv4/tcp_ipv4.c2374\n' +
      '  ip_protocol_deliver_rcu+0x221/0x440 net/ipv4/ip_input.c205\n' +
      '  ip_local_deliver_finish+0x3bb/0x6f0 net/ipv4/ip_input.c239\n' +
      '  NF_HOOK+0x30c/0x3a0 include/linux/netfilter.h318\n' +
      '  NF_HOOK+0x30c/0x3a0 include/linux/netfilter.h318\n' +
      '  __netif_receive_skb_one_core net/core/dev.c6079 [inline]\n' +
      '  __netif_receive_skb+0x143/0x380 net/core/dev.c6192\n' +
      '  process_backlog+0x31e/0x900 net/core/dev.c6544\n' +
      '  __napi_poll+0xb6/0x540 net/core/dev.c7594\n' +
      '  napi_poll net/core/dev.c7657 [inline]\n' +
      '  net_rx_action+0x5f7/0xda0 net/core/dev.c7784\n' +
      '  handle_softirqs+0x22f/0x710 kernel/softirq.c622\n' +
      '  __do_softirq kernel/softirq.c656 [inline]\n' +
      '  __local_bh_enable_ip+0x1a0/0x2e0 kernel/softirq.c302\n' +
      '  mptcp_pm_send_ack net/mptcp/pm.c210 [inline]\n' +
      ' mptcp_pm_addr_send_ack+0x41f/0x500 net/mptcp/pm.c-1\n' +
      '  mptcp_pm_worker+0x174/0x320 net/mptcp/pm.c1002\n' +
      '  mptcp_worker+0xd5/0x1170 net/mptcp/protocol.c2762\n' +
      '  process_one_work kernel/workqueue.c3263 [inline]\n' +
      '  process_scheduled_works+0xae1/0x17b0 kernel/workqueue.c3346\n' +
      '  worker_thread+0x8a0/0xda0 kernel/workqueue.c3427\n' +
      '  kthread+0x711/0x8a0 kernel/kthread.c463\n' +
      '  ret_from_fork+0x4bc/0x870 arch/x86/kernel/process.c158\n' +
      '  ret_from_fork_asm+0x1a/0x30 arch/x86/entry/entry_64.S245\n' +
      ' /TASK>\n' +
      '\n' +
      'Allocated by task 44\n' +
      '  kasan_save_stack mm/kasan/common.c56 [inline]\n' +
      '  kasan_save_track+0x3e/0x80 mm/kasan/common.c77\n' +
      '  poison_kmalloc_redzone mm/kasan/common.c400 [inline]\n' +
      '  __kasan_kmalloc+0x93/0xb0 mm/kasan/common.c417\n' +
      '  kasan_kmalloc include/linux/kasan.h262 [inline]\n' +
      '  __kmalloc_cache_noprof+0x1ef/0x6c0 mm/slub.c5748\n' +
      '  kmalloc_noprof include/linux/slab.h957 [inline]\n' +
      '  mptcp_pm_alloc_anno_list+0x104/0x460 net/mptcp/pm.c385\n' +
      '  mptcp_pm_create_subflow_or_signal_addr+0xf9d/0x1360 net/mptcp/pm_kernel.c355\n' +
      '  mptcp_pm_nl_fully_established net/mptcp/pm_kernel.c409 [inline]\n' +
      '  __mptcp_pm_kernel_worker+0x417/0x1ef0 net/mptcp/pm_kernel.c1529\n' +
      '  mptcp_pm_worker+0x1ee/0x320 net/mptcp/pm.c1008\n' +
      '  mptcp_worker+0xd5/0x1170 net/mptcp/protocol.c2762\n' +
      '  process_one_work kernel/workqueue.c3263 [inline]\n' +
      '  process_scheduled_works+0xae1/0x17b0 kernel/workqueue.c3346\n' +
      '  worker_thread+0x8a0/0xda0 kernel/workqueue.c3427\n' +
      '  kthread+0x711/0x8a0 kernel/kthread.c463\n' +
      '  ret_from_fork+0x4bc/0x870 arch/x86/kernel/process.c158\n' +
      '  ret_from_fork_asm+0x1a/0x30 arch/x86/entry/entry_64.S245\n' +
      '\n' +
      'Freed by task 6630\n' +
      '  kasan_save_stack mm/kasan/common.c56 [inline]\n' +
      '  kasan_save_track+0x3e/0x80 mm/kasan/common.c77\n' +
      '  __kasan_save_free_info+0x46/0x50 mm/kasan/generic.c587\n' +
      '  kasan_save_free_info mm/kasan/kasan.h406 [inline]\n' +
      '  poison_slab_object m\n' +
      '---truncated--- | Severity UNKNOWN  ',
    contentSnippet: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'mptcp fix a race in mptcp_pm_del_add_timer()\n' +
      '\n' +
      'mptcp_pm_del_add_timer() can call sk_stop_timer_sync(sk, entry->add_timer)\n' +
      'while another might have free entry already, as reported by syzbot.\n' +
      '\n' +
      'Add RCU protection to fix this issue.\n' +
      '\n' +
      'Also change confusing add_timer variable with stop_timer boolean.\n' +
      '\n' +
      'syzbot report\n' +
      '\n' +
      'BUG KASAN slab-use-after-free in __timer_delete_sync+0x372/0x3f0 kernel/time/timer.c1616\n' +
      'Read of size 4 at addr ffff8880311e4150 by task kworker/11/44\n' +
      '\n' +
      'CPU 1 UID 0 PID 44 Comm kworker/11 Not tainted syzkaller #0 PREEMPT_{RT,(full)}\n' +
      'Hardware name Google Google Compute Engine/Google Compute Engine, BIOS Google 10/02/2025\n' +
      'Workqueue events mptcp_worker\n' +
      'Call Trace\n' +
      ' TASK>\n' +
      '  dump_stack_lvl+0x189/0x250 lib/dump_stack.c120\n' +
      '  print_address_description mm/kasan/report.c378 [inline]\n' +
      '  print_report+0xca/0x240 mm/kasan/report.c482\n' +
      '  kasan_report+0x118/0x150 mm/kasan/report.c595\n' +
      '  __timer_delete_sync+0x372/0x3f0 kernel/time/timer.c1616\n' +
      '  sk_stop_timer_sync+0x1b/0x90 net/core/sock.c3631\n' +
      '  mptcp_pm_del_add_timer+0x283/0x310 net/mptcp/pm.c362\n' +
      '  mptcp_incoming_options+0x1357/0x1f60 net/mptcp/options.c1174\n' +
      '  tcp_data_queue+0xca/0x6450 net/ipv4/tcp_input.c5361\n' +
      '  tcp_rcv_established+0x1335/0x2670 net/ipv4/tcp_input.c6441\n' +
      '  tcp_v4_do_rcv+0x98b/0xbf0 net/ipv4/tcp_ipv4.c1931\n' +
      '  tcp_v4_rcv+0x252a/0x2dc0 net/ipv4/tcp_ipv4.c2374\n' +
      '  ip_protocol_deliver_rcu+0x221/0x440 net/ipv4/ip_input.c205\n' +
      '  ip_local_deliver_finish+0x3bb/0x6f0 net/ipv4/ip_input.c239\n' +
      '  NF_HOOK+0x30c/0x3a0 include/linux/netfilter.h318\n' +
      '  NF_HOOK+0x30c/0x3a0 include/linux/netfilter.h318\n' +
      '  __netif_receive_skb_one_core net/core/dev.c6079 [inline]\n' +
      '  __netif_receive_skb+0x143/0x380 net/core/dev.c6192\n' +
      '  process_backlog+0x31e/0x900 net/core/dev.c6544\n' +
      '  __napi_poll+0xb6/0x540 net/core/dev.c7594\n' +
      '  napi_poll net/core/dev.c7657 [inline]\n' +
      '  net_rx_action+0x5f7/0xda0 net/core/dev.c7784\n' +
      '  handle_softirqs+0x22f/0x710 kernel/softirq.c622\n' +
      '  __do_softirq kernel/softirq.c656 [inline]\n' +
      '  __local_bh_enable_ip+0x1a0/0x2e0 kernel/softirq.c302\n' +
      '  mptcp_pm_send_ack net/mptcp/pm.c210 [inline]\n' +
      ' mptcp_pm_addr_send_ack+0x41f/0x500 net/mptcp/pm.c-1\n' +
      '  mptcp_pm_worker+0x174/0x320 net/mptcp/pm.c1002\n' +
      '  mptcp_worker+0xd5/0x1170 net/mptcp/protocol.c2762\n' +
      '  process_one_work kernel/workqueue.c3263 [inline]\n' +
      '  process_scheduled_works+0xae1/0x17b0 kernel/workqueue.c3346\n' +
      '  worker_thread+0x8a0/0xda0 kernel/workqueue.c3427\n' +
      '  kthread+0x711/0x8a0 kernel/kthread.c463\n' +
      '  ret_from_fork+0x4bc/0x870 arch/x86/kernel/process.c158\n' +
      '  ret_from_fork_asm+0x1a/0x30 arch/x86/entry/entry_64.S245\n' +
      ' /TASK>\n' +
      '\n' +
      'Allocated by task 44\n' +
      '  kasan_save_stack mm/kasan/common.c56 [inline]\n' +
      '  kasan_save_track+0x3e/0x80 mm/kasan/common.c77\n' +
      '  poison_kmalloc_redzone mm/kasan/common.c400 [inline]\n' +
      '  __kasan_kmalloc+0x93/0xb0 mm/kasan/common.c417\n' +
      '  kasan_kmalloc include/linux/kasan.h262 [inline]\n' +
      '  __kmalloc_cache_noprof+0x1ef/0x6c0 mm/slub.c5748\n' +
      '  kmalloc_noprof include/linux/slab.h957 [inline]\n' +
      '  mptcp_pm_alloc_anno_list+0x104/0x460 net/mptcp/pm.c385\n' +
      '  mptcp_pm_create_subflow_or_signal_addr+0xf9d/0x1360 net/mptcp/pm_kernel.c355\n' +
      '  mptcp_pm_nl_fully_established net/mptcp/pm_kernel.c409 [inline]\n' +
      '  __mptcp_pm_kernel_worker+0x417/0x1ef0 net/mptcp/pm_kernel.c1529\n' +
      '  mptcp_pm_worker+0x1ee/0x320 net/mptcp/pm.c1008\n' +
      '  mptcp_worker+0xd5/0x1170 net/mptcp/protocol.c2762\n' +
      '  process_one_work kernel/workqueue.c3263 [inline]\n' +
      '  process_scheduled_works+0xae1/0x17b0 kernel/workqueue.c3346\n' +
      '  worker_thread+0x8a0/0xda0 kernel/workqueue.c3427\n' +
      '  kthread+0x711/0x8a0 kernel/kthread.c463\n' +
      '  ret_from_fork+0x4bc/0x870 arch/x86/kernel/process.c158\n' +
      '  ret_from_fork_asm+0x1a/0x30 arch/x86/entry/entry_64.S245\n' +
      '\n' +
      'Freed by task 6630\n' +
      '  kasan_save_stack mm/kasan/common.c56 [inline]\n' +
      '  kasan_save_track+0x3e/0x80 mm/kasan/common.c77\n' +
      '  __kasan_save_free_info+0x46/0x50 mm/kasan/generic.c587\n' +
      '  kasan_save_free_info mm/kasan/kasan.h406 [inline]\n' +
      '  poison_slab_object m\n' +
      '---truncated--- | Severity UNKNOWN',
    guid: 'CVE-2025-40257',
    isoDate: '2025-12-04T16:16:00.000Z'
  },
  {
    title: 'CVE-2025-40258 In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'mptcp fix race condition in mp...',
    link: 'https//nvd.nist.gov/vuln/detail/CVE-2025-40258',
    pubDate: 'Thu, 04 Dec 2025 16:16:00 GMT',
    content: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'mptcp fix race condition in mptcp_schedule_work()\n' +
      '\n' +
      'syzbot reported use-after-free in mptcp_schedule_work() [1]\n' +
      '\n' +
      'Issue here is that mptcp_schedule_work() schedules a work,\n' +
      'then gets a refcount on sk->sk_refcnt if the work was scheduled.\n' +
      'This refcount will be released by mptcp_worker().\n' +
      '\n' +
      '[A] if (schedule_work(...)) {\n' +
      '[B]     sock_hold(sk)\n' +
      '        return true\n' +
      '    }\n' +
      '\n' +
      'Problem is that mptcp_worker() can run immediately and complete before [B]\n' +
      '\n' +
      'We need instead \n' +
      '\n' +
      '    sock_hold(sk)\n' +
      '    if (schedule_work(...))\n' +
      '        return true\n' +
      '    sock_put(sk)\n' +
      '\n' +
      '[1]\n' +
      'refcount_t addition on 0 use-after-free.\n' +
      ' WARNING CPU 1 PID 29 at lib/refcount.c25 refcount_warn_saturate+0xfa/0x1d0 lib/refcount.c25\n' +
      'Call Trace\n' +
      ' TASK>\n' +
      ' __refcount_add include/linux/refcount.h-1 [inline]\n' +
      '  __refcount_inc include/linux/refcount.h366 [inline]\n' +
      '  refcount_inc include/linux/refcount.h383 [inline]\n' +
      '  sock_hold include/net/sock.h816 [inline]\n' +
      '  mptcp_schedule_work+0x164/0x1a0 net/mptcp/protocol.c943\n' +
      '  mptcp_tout_timer+0x21/0xa0 net/mptcp/protocol.c2316\n' +
      '  call_timer_fn+0x17e/0x5f0 kernel/time/timer.c1747\n' +
      '  expire_timers kernel/time/timer.c1798 [inline]\n' +
      '  __run_timers kernel/time/timer.c2372 [inline]\n' +
      '  __run_timer_base+0x648/0x970 kernel/time/timer.c2384\n' +
      '  run_timer_base kernel/time/timer.c2393 [inline]\n' +
      '  run_timer_softirq+0xb7/0x180 kernel/time/timer.c2403\n' +
      '  handle_softirqs+0x22f/0x710 kernel/softirq.c622\n' +
      '  __do_softirq kernel/softirq.c656 [inline]\n' +
      '  run_ktimerd+0xcf/0x190 kernel/softirq.c1138\n' +
      '  smpboot_thread_fn+0x542/0xa60 kernel/smpboot.c160\n' +
      '  kthread+0x711/0x8a0 kernel/kthread.c463\n' +
      '  ret_from_fork+0x4bc/0x870 arch/x86/kernel/process.c158\n' +
      '  ret_from_fork_asm+0x1a/0x30 arch/x86/entry/entry_64.S245 | Severity UNKNOWN  ',
    contentSnippet: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'mptcp fix race condition in mptcp_schedule_work()\n' +
      '\n' +
      'syzbot reported use-after-free in mptcp_schedule_work() [1]\n' +
      '\n' +
      'Issue here is that mptcp_schedule_work() schedules a work,\n' +
      'then gets a refcount on sk->sk_refcnt if the work was scheduled.\n' +
      'This refcount will be released by mptcp_worker().\n' +
      '\n' +
      '[A] if (schedule_work(...)) {\n' +
      '[B]     sock_hold(sk)\n' +
      '        return true\n' +
      '    }\n' +
      '\n' +
      'Problem is that mptcp_worker() can run immediately and complete before [B]\n' +
      '\n' +
      'We need instead \n' +
      '\n' +
      '    sock_hold(sk)\n' +
      '    if (schedule_work(...))\n' +
      '        return true\n' +
      '    sock_put(sk)\n' +
      '\n' +
      '[1]\n' +
      'refcount_t addition on 0 use-after-free.\n' +
      ' WARNING CPU 1 PID 29 at lib/refcount.c25 refcount_warn_saturate+0xfa/0x1d0 lib/refcount.c25\n' +
      'Call Trace\n' +
      ' TASK>\n' +
      ' __refcount_add include/linux/refcount.h-1 [inline]\n' +
      '  __refcount_inc include/linux/refcount.h366 [inline]\n' +
      '  refcount_inc include/linux/refcount.h383 [inline]\n' +
      '  sock_hold include/net/sock.h816 [inline]\n' +
      '  mptcp_schedule_work+0x164/0x1a0 net/mptcp/protocol.c943\n' +
      '  mptcp_tout_timer+0x21/0xa0 net/mptcp/protocol.c2316\n' +
      '  call_timer_fn+0x17e/0x5f0 kernel/time/timer.c1747\n' +
      '  expire_timers kernel/time/timer.c1798 [inline]\n' +
      '  __run_timers kernel/time/timer.c2372 [inline]\n' +
      '  __run_timer_base+0x648/0x970 kernel/time/timer.c2384\n' +
      '  run_timer_base kernel/time/timer.c2393 [inline]\n' +
      '  run_timer_softirq+0xb7/0x180 kernel/time/timer.c2403\n' +
      '  handle_softirqs+0x22f/0x710 kernel/softirq.c622\n' +
      '  __do_softirq kernel/softirq.c656 [inline]\n' +
      '  run_ktimerd+0xcf/0x190 kernel/softirq.c1138\n' +
      '  smpboot_thread_fn+0x542/0xa60 kernel/smpboot.c160\n' +
      '  kthread+0x711/0x8a0 kernel/kthread.c463\n' +
      '  ret_from_fork+0x4bc/0x870 arch/x86/kernel/process.c158\n' +
      '  ret_from_fork_asm+0x1a/0x30 arch/x86/entry/entry_64.S245 | Severity UNKNOWN',
    guid: 'CVE-2025-40258',
    isoDate: '2025-12-04T16:16:00.000Z'
  },
  {
    title: 'CVE-2025-40259 In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'scsi sg Do not sleep in atomi...',
    link: 'https//nvd.nist.gov/vuln/detail/CVE-2025-40259',
    pubDate: 'Thu, 04 Dec 2025 16:16:00 GMT',
    content: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'scsi sg Do not sleep in atomic context\n' +
      '\n' +
      'sg_finish_rem_req() calls blk_rq_unmap_user(). The latter function may\n' +
      'sleep. Hence, call sg_finish_rem_req() with interrupts enabled instead\n' +
      'of disabled. | Severity UNKNOWN  ',
    contentSnippet: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'scsi sg Do not sleep in atomic context\n' +
      '\n' +
      'sg_finish_rem_req() calls blk_rq_unmap_user(). The latter function may\n' +
      'sleep. Hence, call sg_finish_rem_req() with interrupts enabled instead\n' +
      'of disabled. | Severity UNKNOWN',
    guid: 'CVE-2025-40259',
    isoDate: '2025-12-04T16:16:00.000Z'
  },
  {
    title: 'CVE-2025-40260 In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'sched_ext Fix scx_enable() cra...',
    link: 'https//nvd.nist.gov/vuln/detail/CVE-2025-40260',
    pubDate: 'Thu, 04 Dec 2025 16:16:00 GMT',
    content: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'sched_ext Fix scx_enable() crash on helper kthread creation failure\n' +
      '\n' +
      'A crash was observed when the sched_ext selftests runner was\n' +
      'terminated with Ctrl+\\ while test 15 was running\n' +
      '\n' +
      'NIP [c00000000028fa58] scx_enable.constprop.0+0x358/0x12b0\n' +
      'LR [c00000000028fa2c] scx_enable.constprop.0+0x32c/0x12b0\n' +
      'Call Trace\n' +
      'scx_enable.constprop.0+0x32c/0x12b0 (unreliable)\n' +
      'bpf_struct_ops_link_create+0x18c/0x22c\n' +
      '__sys_bpf+0x23f8/0x3044\n' +
      'sys_bpf+0x2c/0x6c\n' +
      'system_call_exception+0x124/0x320\n' +
      'system_call_vectored_common+0x15c/0x2ec\n' +
      '\n' +
      'kthread_run_worker() returns an ERR_PTR() on failure rather than NULL,\n' +
      'but the current code in scx_alloc_and_add_sched() only checks for a NULL\n' +
      'helper. Incase of failure on SIGQUIT, the error is not handled in\n' +
      'scx_alloc_and_add_sched() and scx_enable() ends up dereferencing an\n' +
      'error pointer.\n' +
      '\n' +
      'Error handling is fixed in scx_alloc_and_add_sched() to propagate\n' +
      'PTR_ERR() into ret, so that scx_enable() jumps to the existing error\n' +
      'path, avoiding random dereference on failure. | Severity UNKNOWN  ',
    contentSnippet: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'sched_ext Fix scx_enable() crash on helper kthread creation failure\n' +
      '\n' +
      'A crash was observed when the sched_ext selftests runner was\n' +
      'terminated with Ctrl+\\ while test 15 was running\n' +
      '\n' +
      'NIP [c00000000028fa58] scx_enable.constprop.0+0x358/0x12b0\n' +
      'LR [c00000000028fa2c] scx_enable.constprop.0+0x32c/0x12b0\n' +
      'Call Trace\n' +
      'scx_enable.constprop.0+0x32c/0x12b0 (unreliable)\n' +
      'bpf_struct_ops_link_create+0x18c/0x22c\n' +
      '__sys_bpf+0x23f8/0x3044\n' +
      'sys_bpf+0x2c/0x6c\n' +
      'system_call_exception+0x124/0x320\n' +
      'system_call_vectored_common+0x15c/0x2ec\n' +
      '\n' +
      'kthread_run_worker() returns an ERR_PTR() on failure rather than NULL,\n' +
      'but the current code in scx_alloc_and_add_sched() only checks for a NULL\n' +
      'helper. Incase of failure on SIGQUIT, the error is not handled in\n' +
      'scx_alloc_and_add_sched() and scx_enable() ends up dereferencing an\n' +
      'error pointer.\n' +
      '\n' +
      'Error handling is fixed in scx_alloc_and_add_sched() to propagate\n' +
      'PTR_ERR() into ret, so that scx_enable() jumps to the existing error\n' +
      'path, avoiding random dereference on failure. | Severity UNKNOWN',
    guid: 'CVE-2025-40260',
    isoDate: '2025-12-04T16:16:00.000Z'
  },
  {
    title: 'CVE-2025-40261 In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'nvme nvme-fc Ensure ->ioerr_w...',
    link: 'https//nvd.nist.gov/vuln/detail/CVE-2025-40261',
    pubDate: 'Thu, 04 Dec 2025 16:16:00 GMT',
    content: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'nvme nvme-fc Ensure ->ioerr_work is cancelled in nvme_fc_delete_ctrl()\n' +
      '\n' +
      'nvme_fc_delete_assocation() waits for pending I/O to complete before\n' +
      'returning, and an error can cause ->ioerr_work to be queued after\n' +
      'cancel_work_sync() had been called.  Move the call to cancel_work_sync() to\n' +
      'be after nvme_fc_delete_association() to ensure ->ioerr_work is not running\n' +
      'when the nvme_fc_ctrl object is freed.  Otherwise the following can occur\n' +
      '\n' +
      '[ 1135.911754] list_del corruption, ff2d24c8093f31f8->next is NULL\n' +
      '[ 1135.917705] ------------[ cut here ]------------\n' +
      '[ 1135.922336] kernel BUG at lib/list_debug.c52!\n' +
      '[ 1135.926784] Oops invalid opcode 0000 [#1] SMP NOPTI\n' +
      '[ 1135.931851] CPU 48 UID 0 PID 726 Comm kworker/u44923 Kdump loaded Not tainted 6.12.0 #1 PREEMPT(voluntary)\n' +
      '[ 1135.943490] Hardware name Dell Inc. PowerEdge R660/0HGTK9, BIOS 2.5.4 01/16/2025\n' +
      '[ 1135.950969] Workqueue  0x0 (nvme-wq)\n' +
      '[ 1135.954673] RIP 0010__list_del_entry_valid_or_report.cold+0xf/0x6f\n' +
      '[ 1135.961041] Code c7 c7 98 68 72 94 e8 26 45 fe ff 0f 0b 48 c7 c7 70 68 72 94 e8 18 45 fe ff 0f 0b 48 89 fe 48 c7 c7 80 69 72 94 e8 07 45 fe ff 0f> 0b 48 89 d1 48 c7 c7 a0 6a 72 94 48 89 c2 e8 f3 44 fe ff 0f 0b\n' +
      '[ 1135.979788] RSP 0018ff579b19482d3e50 EFLAGS 00010046\n' +
      '[ 1135.985015] RAX 0000000000000033 RBX ff2d24c8093f31f0 RCX 0000000000000000\n' +
      '[ 1135.992148] RDX 0000000000000000 RSI ff2d24d6bfa1d0c0 RDI ff2d24d6bfa1d0c0\n' +
      '[ 1135.999278] RBP ff2d24c8093f31f8 R08 0000000000000000 R09 ffffffff951e2b08\n' +
      '[ 1136.006413] R10 ffffffff95122ac8 R11 0000000000000003 R12 ff2d24c78697c100\n' +
      '[ 1136.013546] R13 fffffffffffffff8 R14 0000000000000000 R15 ff2d24c78697c0c0\n' +
      '[ 1136.020677] FS  0000000000000000(0000) GSff2d24d6bfa00000(0000) knlGS0000000000000000\n' +
      '[ 1136.028765] CS  0010 DS 0000 ES 0000 CR0 0000000080050033\n' +
      '[ 1136.034510] CR2 00007fd207f90b80 CR3 000000163ea22003 CR4 0000000000f73ef0\n' +
      '[ 1136.041641] DR0 0000000000000000 DR1 0000000000000000 DR2 0000000000000000\n' +
      '[ 1136.048776] DR3 0000000000000000 DR6 00000000fffe07f0 DR7 0000000000000400\n' +
      '[ 1136.055910] PKRU 55555554\n' +
      '[ 1136.058623] Call Trace\n' +
      '[ 1136.061074]  TASK>\n' +
      '[ 1136.063179]  ? show_trace_log_lvl+0x1b0/0x2f0\n' +
      '[ 1136.067540]  ? show_trace_log_lvl+0x1b0/0x2f0\n' +
      '[ 1136.071898]  ? move_linked_works+0x4a/0xa0\n' +
      '[ 1136.075998]  ? __list_del_entry_valid_or_report.cold+0xf/0x6f\n' +
      '[ 1136.081744]  ? __die_body.cold+0x8/0x12\n' +
      '[ 1136.085584]  ? die+0x2e/0x50\n' +
      '[ 1136.088469]  ? do_trap+0xca/0x110\n' +
      '[ 1136.091789]  ? do_error_trap+0x65/0x80\n' +
      '[ 1136.095543]  ? __list_del_entry_valid_or_report.cold+0xf/0x6f\n' +
      '[ 1136.101289]  ? exc_invalid_op+0x50/0x70\n' +
      '[ 1136.105127]  ? __list_del_entry_valid_or_report.cold+0xf/0x6f\n' +
      '[ 1136.110874]  ? asm_exc_invalid_op+0x1a/0x20\n' +
      '[ 1136.115059]  ? __list_del_entry_valid_or_report.cold+0xf/0x6f\n' +
      '[ 1136.120806]  move_linked_works+0x4a/0xa0\n' +
      '[ 1136.124733]  worker_thread+0x216/0x3a0\n' +
      '[ 1136.128485]  ? __pfx_worker_thread+0x10/0x10\n' +
      '[ 1136.132758]  kthread+0xfa/0x240\n' +
      '[ 1136.135904]  ? __pfx_kthread+0x10/0x10\n' +
      '[ 1136.139657]  ret_from_fork+0x31/0x50\n' +
      '[ 1136.143236]  ? __pfx_kthread+0x10/0x10\n' +
      '[ 1136.146988]  ret_from_fork_asm+0x1a/0x30\n' +
      '[ 1136.150915]  /TASK> | Severity UNKNOWN  ',
    contentSnippet: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'nvme nvme-fc Ensure ->ioerr_work is cancelled in nvme_fc_delete_ctrl()\n' +
      '\n' +
      'nvme_fc_delete_assocation() waits for pending I/O to complete before\n' +
      'returning, and an error can cause ->ioerr_work to be queued after\n' +
      'cancel_work_sync() had been called.  Move the call to cancel_work_sync() to\n' +
      'be after nvme_fc_delete_association() to ensure ->ioerr_work is not running\n' +
      'when the nvme_fc_ctrl object is freed.  Otherwise the following can occur\n' +
      '\n' +
      '[ 1135.911754] list_del corruption, ff2d24c8093f31f8->next is NULL\n' +
      '[ 1135.917705] ------------[ cut here ]------------\n' +
      '[ 1135.922336] kernel BUG at lib/list_debug.c52!\n' +
      '[ 1135.926784] Oops invalid opcode 0000 [#1] SMP NOPTI\n' +
      '[ 1135.931851] CPU 48 UID 0 PID 726 Comm kworker/u44923 Kdump loaded Not tainted 6.12.0 #1 PREEMPT(voluntary)\n' +
      '[ 1135.943490] Hardware name Dell Inc. PowerEdge R660/0HGTK9, BIOS 2.5.4 01/16/2025\n' +
      '[ 1135.950969] Workqueue  0x0 (nvme-wq)\n' +
      '[ 1135.954673] RIP 0010__list_del_entry_valid_or_report.cold+0xf/0x6f\n' +
      '[ 1135.961041] Code c7 c7 98 68 72 94 e8 26 45 fe ff 0f 0b 48 c7 c7 70 68 72 94 e8 18 45 fe ff 0f 0b 48 89 fe 48 c7 c7 80 69 72 94 e8 07 45 fe ff 0f> 0b 48 89 d1 48 c7 c7 a0 6a 72 94 48 89 c2 e8 f3 44 fe ff 0f 0b\n' +
      '[ 1135.979788] RSP 0018ff579b19482d3e50 EFLAGS 00010046\n' +
      '[ 1135.985015] RAX 0000000000000033 RBX ff2d24c8093f31f0 RCX 0000000000000000\n' +
      '[ 1135.992148] RDX 0000000000000000 RSI ff2d24d6bfa1d0c0 RDI ff2d24d6bfa1d0c0\n' +
      '[ 1135.999278] RBP ff2d24c8093f31f8 R08 0000000000000000 R09 ffffffff951e2b08\n' +
      '[ 1136.006413] R10 ffffffff95122ac8 R11 0000000000000003 R12 ff2d24c78697c100\n' +
      '[ 1136.013546] R13 fffffffffffffff8 R14 0000000000000000 R15 ff2d24c78697c0c0\n' +
      '[ 1136.020677] FS  0000000000000000(0000) GSff2d24d6bfa00000(0000) knlGS0000000000000000\n' +
      '[ 1136.028765] CS  0010 DS 0000 ES 0000 CR0 0000000080050033\n' +
      '[ 1136.034510] CR2 00007fd207f90b80 CR3 000000163ea22003 CR4 0000000000f73ef0\n' +
      '[ 1136.041641] DR0 0000000000000000 DR1 0000000000000000 DR2 0000000000000000\n' +
      '[ 1136.048776] DR3 0000000000000000 DR6 00000000fffe07f0 DR7 0000000000000400\n' +
      '[ 1136.055910] PKRU 55555554\n' +
      '[ 1136.058623] Call Trace\n' +
      '[ 1136.061074]  TASK>\n' +
      '[ 1136.063179]  ? show_trace_log_lvl+0x1b0/0x2f0\n' +
      '[ 1136.067540]  ? show_trace_log_lvl+0x1b0/0x2f0\n' +
      '[ 1136.071898]  ? move_linked_works+0x4a/0xa0\n' +
      '[ 1136.075998]  ? __list_del_entry_valid_or_report.cold+0xf/0x6f\n' +
      '[ 1136.081744]  ? __die_body.cold+0x8/0x12\n' +
      '[ 1136.085584]  ? die+0x2e/0x50\n' +
      '[ 1136.088469]  ? do_trap+0xca/0x110\n' +
      '[ 1136.091789]  ? do_error_trap+0x65/0x80\n' +
      '[ 1136.095543]  ? __list_del_entry_valid_or_report.cold+0xf/0x6f\n' +
      '[ 1136.101289]  ? exc_invalid_op+0x50/0x70\n' +
      '[ 1136.105127]  ? __list_del_entry_valid_or_report.cold+0xf/0x6f\n' +
      '[ 1136.110874]  ? asm_exc_invalid_op+0x1a/0x20\n' +
      '[ 1136.115059]  ? __list_del_entry_valid_or_report.cold+0xf/0x6f\n' +
      '[ 1136.120806]  move_linked_works+0x4a/0xa0\n' +
      '[ 1136.124733]  worker_thread+0x216/0x3a0\n' +
      '[ 1136.128485]  ? __pfx_worker_thread+0x10/0x10\n' +
      '[ 1136.132758]  kthread+0xfa/0x240\n' +
      '[ 1136.135904]  ? __pfx_kthread+0x10/0x10\n' +
      '[ 1136.139657]  ret_from_fork+0x31/0x50\n' +
      '[ 1136.143236]  ? __pfx_kthread+0x10/0x10\n' +
      '[ 1136.146988]  ret_from_fork_asm+0x1a/0x30\n' +
      '[ 1136.150915]  /TASK> | Severity UNKNOWN',
    guid: 'CVE-2025-40261',
    isoDate: '2025-12-04T16:16:00.000Z'
  },
  {
    title: 'CVE-2025-40262 In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'Input imx_sc_key - fix memory ...',
    link: 'https//nvd.nist.gov/vuln/detail/CVE-2025-40262',
    pubDate: 'Thu, 04 Dec 2025 16:16:00 GMT',
    content: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'Input imx_sc_key - fix memory corruption on unload\n' +
      '\n' +
      'This is supposed to be "priv" but we accidentally pass "priv" which is\n' +
      'an address in the stack and so it will lead to memory corruption when\n' +
      'the imx_sc_key_action() function is called.  Remove the . | Severity UNKNOWN  ',
    contentSnippet: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'Input imx_sc_key - fix memory corruption on unload\n' +
      '\n' +
      'This is supposed to be "priv" but we accidentally pass "priv" which is\n' +
      'an address in the stack and so it will lead to memory corruption when\n' +
      'the imx_sc_key_action() function is called.  Remove the . | Severity UNKNOWN',
    guid: 'CVE-2025-40262',
    isoDate: '2025-12-04T16:16:00.000Z'
  },
  {
    title: 'CVE-2025-40263 In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'Input cros_ec_keyb - fix an in...',
    link: 'https//nvd.nist.gov/vuln/detail/CVE-2025-40263',
    pubDate: 'Thu, 04 Dec 2025 16:16:00 GMT',
    content: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'Input cros_ec_keyb - fix an invalid memory access\n' +
      '\n' +
      "If cros_ec_keyb_register_matrix() isn't called (due to\n" +
      '`buttons_switches_only`) in cros_ec_keyb_probe(), `ckdev->idev` remains\n' +
      'NULL.  An invalid memory access is observed in cros_ec_keyb_process()\n' +
      'when receiving an EC_MKBP_EVENT_KEY_MATRIX event in cros_ec_keyb_work()\n' +
      'in such case.\n' +
      '\n' +
      '  Unable to handle kernel read from unreadable memory at virtual address 0000000000000028\n' +
      '  ...\n' +
      '  x3  0000000000000000 x2  0000000000000000\n' +
      '  x1  0000000000000000 x0  0000000000000000\n' +
      '  Call trace\n' +
      '  input_event\n' +
      '  cros_ec_keyb_work\n' +
      '  blocking_notifier_call_chain\n' +
      '  ec_irq_thread\n' +
      '\n' +
      "It's still unknown about why the kernel receives such malformed event,\n" +
      "in any cases, the kernel shouldn't access `ckdev->idev` and friends if\n" +
      "the driver doesn't intend to initialize them. | Severity UNKNOWN  ",
    contentSnippet: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'Input cros_ec_keyb - fix an invalid memory access\n' +
      '\n' +
      "If cros_ec_keyb_register_matrix() isn't called (due to\n" +
      '`buttons_switches_only`) in cros_ec_keyb_probe(), `ckdev->idev` remains\n' +
      'NULL.  An invalid memory access is observed in cros_ec_keyb_process()\n' +
      'when receiving an EC_MKBP_EVENT_KEY_MATRIX event in cros_ec_keyb_work()\n' +
      'in such case.\n' +
      '\n' +
      '  Unable to handle kernel read from unreadable memory at virtual address 0000000000000028\n' +
      '  ...\n' +
      '  x3  0000000000000000 x2  0000000000000000\n' +
      '  x1  0000000000000000 x0  0000000000000000\n' +
      '  Call trace\n' +
      '  input_event\n' +
      '  cros_ec_keyb_work\n' +
      '  blocking_notifier_call_chain\n' +
      '  ec_irq_thread\n' +
      '\n' +
      "It's still unknown about why the kernel receives such malformed event,\n" +
      "in any cases, the kernel shouldn't access `ckdev->idev` and friends if\n" +
      "the driver doesn't intend to initialize them. | Severity UNKNOWN",
    guid: 'CVE-2025-40263',
    isoDate: '2025-12-04T16:16:00.000Z'
  },
  {
    title: 'CVE-2025-40264 In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'be2net pass wrb_params in case...',
    link: 'https//nvd.nist.gov/vuln/detail/CVE-2025-40264',
    pubDate: 'Thu, 04 Dec 2025 16:16:00 GMT',
    content: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'be2net pass wrb_params in case of OS2BMC\n' +
      '\n' +
      'be_insert_vlan_in_pkt() is called with the wrb_params argument being NULL\n' +
      'at be_send_pkt_to_bmc() call site. This may lead to dereferencing a NULL\n' +
      'pointer when processing a workaround for specific packet, as commit\n' +
      'bc0c3405abbb ("be2net fix a Tx stall bug caused by a specific ipv6\n' +
      'packet") states.\n' +
      '\n' +
      'The correct way would be to pass the wrb_params from be_xmit(). | Severity UNKNOWN  ',
    contentSnippet: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'be2net pass wrb_params in case of OS2BMC\n' +
      '\n' +
      'be_insert_vlan_in_pkt() is called with the wrb_params argument being NULL\n' +
      'at be_send_pkt_to_bmc() call site. This may lead to dereferencing a NULL\n' +
      'pointer when processing a workaround for specific packet, as commit\n' +
      'bc0c3405abbb ("be2net fix a Tx stall bug caused by a specific ipv6\n' +
      'packet") states.\n' +
      '\n' +
      'The correct way would be to pass the wrb_params from be_xmit(). | Severity UNKNOWN',
    guid: 'CVE-2025-40264',
    isoDate: '2025-12-04T16:16:00.000Z'
  },
  {
    title: 'CVE-2025-40265 In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'vfat fix missing sb_min_blocks...',
    link: 'https//nvd.nist.gov/vuln/detail/CVE-2025-40265',
    pubDate: 'Thu, 04 Dec 2025 16:16:00 GMT',
    content: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'vfat fix missing sb_min_blocksize() return value checks\n' +
      '\n' +
      'When emulating an nvme device on qemu with both logical_block_size and\n' +
      'physical_block_size set to 8 KiB, but without format, a kernel panic\n' +
      'was triggered during the early boot stage while attempting to mount a\n' +
      'vfat filesystem.\n' +
      '\n' +
      '[95553.682035] EXT4-fs (nvme0n1) unable to set blocksize\n' +
      '[95553.684326] EXT4-fs (nvme0n1) unable to set blocksize\n' +
      '[95553.686501] EXT4-fs (nvme0n1) unable to set blocksize\n' +
      '[95553.696448] ISOFS unsupported/invalid hardware sector size 8192\n' +
      '[95553.697117] ------------[ cut here ]------------\n' +
      '[95553.697567] kernel BUG at fs/buffer.c1582!\n' +
      '[95553.697984] Oops invalid opcode 0000 [#1] SMP NOPTI\n' +
      '[95553.698602] CPU 0 UID 0 PID 7212 Comm mount Kdump loaded Not tainted 6.18.0-rc2+ #38 PREEMPT(voluntary)\n' +
      '[95553.699511] Hardware name QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.16.3-0-ga6ed6b701f0a-prebuilt.qemu.org 04/01/2014\n' +
      '[95553.700534] RIP 0010folio_alloc_buffers+0x1bb/0x1c0\n' +
      '[95553.701018] Code 48 8b 15 e8 93 18 02 65 48 89 35 e0 93 18 02 48 83 c4 10 5b 41 5c 41 5d 41 5e 41 5f 5d 31 d2 31 c9 31 f6 31 ff c3 cc cc cc cc 0f> 0b 90 66 90 90 90 90 90 90 90 90 90 90 90 90 90 90 90 90 90 0f\n' +
      '[95553.702648] RSP 0018ffffd1b0c676f990 EFLAGS 00010246\n' +
      '[95553.703132] RAX ffff8cfc4176d820 RBX 0000000000508c48 RCX 0000000000000001\n' +
      '[95553.703805] RDX 0000000000002000 RSI 0000000000000000 RDI 0000000000000000\n' +
      '[95553.704481] RBP ffffd1b0c676f9c8 R08 0000000000000000 R09 0000000000000000\n' +
      '[95553.705148] R10 0000000000000000 R11 0000000000000000 R12 0000000000000001\n' +
      '[95553.705816] R13 0000000000002000 R14 fffff8bc8257e800 R15 0000000000000000\n' +
      '[95553.706483] FS  000072ee77315840(0000) GSffff8cfdd2c8d000(0000) knlGS0000000000000000\n' +
      '[95553.707248] CS  0010 DS 0000 ES 0000 CR0 0000000080050033\n' +
      '[95553.707782] CR2 00007d8f2a9e5a20 CR3 0000000039d0c006 CR4 0000000000772ef0\n' +
      '[95553.708439] PKRU 55555554\n' +
      '[95553.708734] Call Trace\n' +
      '[95553.709015]  TASK>\n' +
      '[95553.709266]  __getblk_slow+0xd2/0x230\n' +
      '[95553.709641]  ? find_get_block_common+0x8b/0x530\n' +
      '[95553.710084]  bdev_getblk+0x77/0xa0\n' +
      '[95553.710449]  __bread_gfp+0x22/0x140\n' +
      '[95553.710810]  fat_fill_super+0x23a/0xfc0\n' +
      '[95553.711216]  ? __pfx_setup+0x10/0x10\n' +
      '[95553.711580]  ? __pfx_vfat_fill_super+0x10/0x10\n' +
      '[95553.712014]  vfat_fill_super+0x15/0x30\n' +
      '[95553.712401]  get_tree_bdev_flags+0x141/0x1e0\n' +
      '[95553.712817]  get_tree_bdev+0x10/0x20\n' +
      '[95553.713177]  vfat_get_tree+0x15/0x20\n' +
      '[95553.713550]  vfs_get_tree+0x2a/0x100\n' +
      '[95553.713910]  vfs_cmd_create+0x62/0xf0\n' +
      '[95553.714273]  __do_sys_fsconfig+0x4e7/0x660\n' +
      '[95553.714669]  __x64_sys_fsconfig+0x20/0x40\n' +
      '[95553.715062]  x64_sys_call+0x21ee/0x26a0\n' +
      '[95553.715453]  do_syscall_64+0x80/0x670\n' +
      '[95553.715816]  ? __fs_parse+0x65/0x1e0\n' +
      '[95553.716172]  ? fat_parse_param+0x103/0x4b0\n' +
      '[95553.716587]  ? vfs_parse_fs_param_source+0x21/0xa0\n' +
      '[95553.717034]  ? __do_sys_fsconfig+0x3d9/0x660\n' +
      '[95553.717548]  ? __x64_sys_fsconfig+0x20/0x40\n' +
      '[95553.717957]  ? x64_sys_call+0x21ee/0x26a0\n' +
      '[95553.718360]  ? do_syscall_64+0xb8/0x670\n' +
      '[95553.718734]  ? __x64_sys_fsconfig+0x20/0x40\n' +
      '[95553.719141]  ? x64_sys_call+0x21ee/0x26a0\n' +
      '[95553.719545]  ? do_syscall_64+0xb8/0x670\n' +
      '[95553.719922]  ? x64_sys_call+0x1405/0x26a0\n' +
      '[95553.720317]  ? do_syscall_64+0xb8/0x670\n' +
      '[95553.720702]  ? __x64_sys_close+0x3e/0x90\n' +
      '[95553.721080]  ? x64_sys_call+0x1b5e/0x26a0\n' +
      '[95553.721478]  ? do_syscall_64+0xb8/0x670\n' +
      '[95553.721841]  ? irqentry_exit+0x43/0x50\n' +
      '[95553.722211]  ? exc_page_fault+0x90/0x1b0\n' +
      '[95553.722681]  entry_SYSCALL_64_after_hwframe+0x76/0x7e\n' +
      '[95553.723166] RIP 00330x72ee774f3afe\n' +
      '[95553.723562] Code 73 01 c3 48 8b 0d 0a 33 0f 00 f7 d8 64 89 01 48 83 c8 ff c3 0f 1f 84 00 00 00 00 00 f3 0f 1e fa 49 89 ca b8 af 01 00 00 0f 05 48> 3d 01 f0 ff ff 73 01 c3 48 8b 0d da 32 0f 00 f7 d8 64 89 01 48\n' +
      '[95553.725188] RSP 002b00007ffe97148978 EFLAGS 00000246 ORIG_RAX 00000000000001af\n' +
      '[95553.725892] RAX ffffffffffffffda RBX \n' +
      '---truncated--- | Severity UNKNOWN  ',
    contentSnippet: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'vfat fix missing sb_min_blocksize() return value checks\n' +
      '\n' +
      'When emulating an nvme device on qemu with both logical_block_size and\n' +
      'physical_block_size set to 8 KiB, but without format, a kernel panic\n' +
      'was triggered during the early boot stage while attempting to mount a\n' +
      'vfat filesystem.\n' +
      '\n' +
      '[95553.682035] EXT4-fs (nvme0n1) unable to set blocksize\n' +
      '[95553.684326] EXT4-fs (nvme0n1) unable to set blocksize\n' +
      '[95553.686501] EXT4-fs (nvme0n1) unable to set blocksize\n' +
      '[95553.696448] ISOFS unsupported/invalid hardware sector size 8192\n' +
      '[95553.697117] ------------[ cut here ]------------\n' +
      '[95553.697567] kernel BUG at fs/buffer.c1582!\n' +
      '[95553.697984] Oops invalid opcode 0000 [#1] SMP NOPTI\n' +
      '[95553.698602] CPU 0 UID 0 PID 7212 Comm mount Kdump loaded Not tainted 6.18.0-rc2+ #38 PREEMPT(voluntary)\n' +
      '[95553.699511] Hardware name QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.16.3-0-ga6ed6b701f0a-prebuilt.qemu.org 04/01/2014\n' +
      '[95553.700534] RIP 0010folio_alloc_buffers+0x1bb/0x1c0\n' +
      '[95553.701018] Code 48 8b 15 e8 93 18 02 65 48 89 35 e0 93 18 02 48 83 c4 10 5b 41 5c 41 5d 41 5e 41 5f 5d 31 d2 31 c9 31 f6 31 ff c3 cc cc cc cc 0f> 0b 90 66 90 90 90 90 90 90 90 90 90 90 90 90 90 90 90 90 90 0f\n' +
      '[95553.702648] RSP 0018ffffd1b0c676f990 EFLAGS 00010246\n' +
      '[95553.703132] RAX ffff8cfc4176d820 RBX 0000000000508c48 RCX 0000000000000001\n' +
      '[95553.703805] RDX 0000000000002000 RSI 0000000000000000 RDI 0000000000000000\n' +
      '[95553.704481] RBP ffffd1b0c676f9c8 R08 0000000000000000 R09 0000000000000000\n' +
      '[95553.705148] R10 0000000000000000 R11 0000000000000000 R12 0000000000000001\n' +
      '[95553.705816] R13 0000000000002000 R14 fffff8bc8257e800 R15 0000000000000000\n' +
      '[95553.706483] FS  000072ee77315840(0000) GSffff8cfdd2c8d000(0000) knlGS0000000000000000\n' +
      '[95553.707248] CS  0010 DS 0000 ES 0000 CR0 0000000080050033\n' +
      '[95553.707782] CR2 00007d8f2a9e5a20 CR3 0000000039d0c006 CR4 0000000000772ef0\n' +
      '[95553.708439] PKRU 55555554\n' +
      '[95553.708734] Call Trace\n' +
      '[95553.709015]  TASK>\n' +
      '[95553.709266]  __getblk_slow+0xd2/0x230\n' +
      '[95553.709641]  ? find_get_block_common+0x8b/0x530\n' +
      '[95553.710084]  bdev_getblk+0x77/0xa0\n' +
      '[95553.710449]  __bread_gfp+0x22/0x140\n' +
      '[95553.710810]  fat_fill_super+0x23a/0xfc0\n' +
      '[95553.711216]  ? __pfx_setup+0x10/0x10\n' +
      '[95553.711580]  ? __pfx_vfat_fill_super+0x10/0x10\n' +
      '[95553.712014]  vfat_fill_super+0x15/0x30\n' +
      '[95553.712401]  get_tree_bdev_flags+0x141/0x1e0\n' +
      '[95553.712817]  get_tree_bdev+0x10/0x20\n' +
      '[95553.713177]  vfat_get_tree+0x15/0x20\n' +
      '[95553.713550]  vfs_get_tree+0x2a/0x100\n' +
      '[95553.713910]  vfs_cmd_create+0x62/0xf0\n' +
      '[95553.714273]  __do_sys_fsconfig+0x4e7/0x660\n' +
      '[95553.714669]  __x64_sys_fsconfig+0x20/0x40\n' +
      '[95553.715062]  x64_sys_call+0x21ee/0x26a0\n' +
      '[95553.715453]  do_syscall_64+0x80/0x670\n' +
      '[95553.715816]  ? __fs_parse+0x65/0x1e0\n' +
      '[95553.716172]  ? fat_parse_param+0x103/0x4b0\n' +
      '[95553.716587]  ? vfs_parse_fs_param_source+0x21/0xa0\n' +
      '[95553.717034]  ? __do_sys_fsconfig+0x3d9/0x660\n' +
      '[95553.717548]  ? __x64_sys_fsconfig+0x20/0x40\n' +
      '[95553.717957]  ? x64_sys_call+0x21ee/0x26a0\n' +
      '[95553.718360]  ? do_syscall_64+0xb8/0x670\n' +
      '[95553.718734]  ? __x64_sys_fsconfig+0x20/0x40\n' +
      '[95553.719141]  ? x64_sys_call+0x21ee/0x26a0\n' +
      '[95553.719545]  ? do_syscall_64+0xb8/0x670\n' +
      '[95553.719922]  ? x64_sys_call+0x1405/0x26a0\n' +
      '[95553.720317]  ? do_syscall_64+0xb8/0x670\n' +
      '[95553.720702]  ? __x64_sys_close+0x3e/0x90\n' +
      '[95553.721080]  ? x64_sys_call+0x1b5e/0x26a0\n' +
      '[95553.721478]  ? do_syscall_64+0xb8/0x670\n' +
      '[95553.721841]  ? irqentry_exit+0x43/0x50\n' +
      '[95553.722211]  ? exc_page_fault+0x90/0x1b0\n' +
      '[95553.722681]  entry_SYSCALL_64_after_hwframe+0x76/0x7e\n' +
      '[95553.723166] RIP 00330x72ee774f3afe\n' +
      '[95553.723562] Code 73 01 c3 48 8b 0d 0a 33 0f 00 f7 d8 64 89 01 48 83 c8 ff c3 0f 1f 84 00 00 00 00 00 f3 0f 1e fa 49 89 ca b8 af 01 00 00 0f 05 48> 3d 01 f0 ff ff 73 01 c3 48 8b 0d da 32 0f 00 f7 d8 64 89 01 48\n' +
      '[95553.725188] RSP 002b00007ffe97148978 EFLAGS 00000246 ORIG_RAX 00000000000001af\n' +
      '[95553.725892] RAX ffffffffffffffda RBX \n' +
      '---truncated--- | Severity UNKNOWN',
    guid: 'CVE-2025-40265',
    isoDate: '2025-12-04T16:16:00.000Z'
  },
  {
    title: 'CVE-2025-40266 In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'KVM arm64 Check the untrusted...',
    link: 'https//nvd.nist.gov/vuln/detail/CVE-2025-40266',
    pubDate: 'Thu, 04 Dec 2025 16:16:00 GMT',
    content: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'KVM arm64 Check the untrusted offset in FF-A memory share\n' +
      '\n' +
      'Verify the offset to prevent OOB access in the hypervisor\n' +
      'FF-A buffer in case an untrusted large enough value\n' +
      '[U32_MAX - sizeof(struct ffa_composite_mem_region) + 1, U32_MAX]\n' +
      'is set from the host kernel. | Severity UNKNOWN  ',
    contentSnippet: 'In the Linux kernel, the following vulnerability has been resolved\n' +
      '\n' +
      'KVM arm64 Check the untrusted offset in FF-A memory share\n' +
      '\n' +
      'Verify the offset to prevent OOB access in the hypervisor\n' +
      'FF-A buffer in case an untrusted large enough value\n' +
      '[U32_MAX - sizeof(struct ffa_composite_mem_region) + 1, U32_MAX]\n' +
      'is set from the host kernel. | Severity UNKNOWN',
    guid: 'CVE-2025-40266',
    isoDate: '2025-12-04T16:16:00.000Z'
  },
  {
    title: 'CVE-2025-54158 Missing authentication for critical function vulnerability in BeeDrive in Synology BeeDrive for desk...',
    link: 'https//nvd.nist.gov/vuln/detail/CVE-2025-54158',
    pubDate: 'Thu, 04 Dec 2025 16:16:00 GMT',
    content: 'Missing authentication for critical function vulnerability in BeeDrive in Synology BeeDrive for desktop before 1.4.2-13960 allows local users to execute arbitrary code via unspecified vectors. | CVSS Score 7.8 (HIGH)  ',
    contentSnippet: 'Missing authentication for critical function vulnerability in BeeDrive in Synology BeeDrive for desktop before 1.4.2-13960 allows local users to execute arbitrary code via unspecified vectors. | CVSS Score 7.8 (HIGH)',
    guid: 'CVE-2025-54158',
    isoDate: '2025-12-04T16:16:00.000Z'
  },
  {
    title: 'CVE-2025-54159 Missing authorization vulnerability in BeeDrive in Synology BeeDrive for desktop before 1.4.2-13960 ...',
    link: 'https//nvd.nist.gov/vuln/detail/CVE-2025-54159',
    pubDate: 'Thu, 04 Dec 2025 16:16:00 GMT',
    content: 'Missing authorization vulnerability in BeeDrive in Synology BeeDrive for desktop before 1.4.2-13960 allows remote attackers to delete arbitrary files via unspecified vectors. | CVSS Score 7.5 (HIGH)  ',
    contentSnippet: 'Missing authorization vulnerability in BeeDrive in Synology BeeDrive for desktop before 1.4.2-13960 allows remote attackers to delete arbitrary files via unspecified vectors. | CVSS Score 7.5 (HIGH)',
    guid: 'CVE-2025-54159',
    isoDate: '2025-12-04T16:16:00.000Z'
  },
  {
    title: "CVE-2025-54160 Improper limitation of a pathname to a restricted directory ('Path Traversal') vulnerability in BeeD...",
    link: 'https//nvd.nist.gov/vuln/detail/CVE-2025-54160',
    pubDate: 'Thu, 04 Dec 2025 16:16:00 GMT',
    content: "Improper limitation of a pathname to a restricted directory ('Path Traversal') vulnerability in BeeDrive in Synology BeeDrive for desktop before 1.4.2-13960 allows local users to execute arbitrary code via unspecified vectors. | CVSS Score 7.8 (HIGH)  ",
    contentSnippet: "Improper limitation of a pathname to a restricted directory ('Path Traversal') vulnerability in BeeDrive in Synology BeeDrive for desktop before 1.4.2-13960 allows local users to execute arbitrary code via unspecified vectors. | CVSS Score 7.8 (HIGH)",
    guid: 'CVE-2025-54160',
    isoDate: '2025-12-04T16:16:00.000Z'
  },
  {
    title: 'CVE-2025-56427 Directory Traversal vulnerability in ComposioHQ v.0.7.20 allows a remote attacker to obtain sensitiv...',
    link: 'https//nvd.nist.gov/vuln/detail/CVE-2025-56427',
    pubDate: 'Thu, 04 Dec 2025 16:16:00 GMT',
    content: 'Directory Traversal vulnerability in ComposioHQ v.0.7.20 allows a remote attacker to obtain sensitive information via the _download_file_or_dir function. | Severity UNKNOWN  ',
    contentSnippet: 'Directory Traversal vulnerability in ComposioHQ v.0.7.20 allows a remote attacker to obtain sensitive information via the _download_file_or_dir function. | Severity UNKNOWN',
    guid: 'CVE-2025-56427',
    isoDate: '2025-12-04T16:16:00.000Z'
  },
  {
    title: 'CVE-2025-57210 Incorrect access control in the component ApiPayController.java of platform v1.0.0 allows attackers ...',
    link: 'https//nvd.nist.gov/vuln/detail/CVE-2025-57210',
    pubDate: 'Thu, 04 Dec 2025 16:16:00 GMT',
    content: 'Incorrect access control in the component ApiPayController.java of platform v1.0.0 allows attackers to access sensitive information via unspecified vectors. | Severity UNKNOWN  ',
    contentSnippet: 'Incorrect access control in the component ApiPayController.java of platform v1.0.0 allows attackers to access sensitive information via unspecified vectors. | Severity UNKNOWN',
    guid: 'CVE-2025-57210',
    isoDate: '2025-12-04T16:16:00.000Z'
  },
  {
    title: 'CVE-2025-57212 Incorrect access control in the component ApiOrderService.java of platform v1.0.0 allows attackers t...',
    link: 'https//nvd.nist.gov/vuln/detail/CVE-2025-57212',
    pubDate: 'Thu, 04 Dec 2025 16:16:00 GMT',
    content: 'Incorrect access control in the component ApiOrderService.java of platform v1.0.0 allows attackers to access sensitive information via a crafted request. | Severity UNKNOWN  ',
    contentSnippet: 'Incorrect access control in the component ApiOrderService.java of platform v1.0.0 allows attackers to access sensitive information via a crafted request. | Severity UNKNOWN',
    guid: 'CVE-2025-57212',
    isoDate: '2025-12-04T16:16:00.000Z'
  },
  {
    title: 'CVE-2025-57213 Incorrect access control in the component orderService.queryObject of platform v1.0.0 allows attacke...',
    link: 'https//nvd.nist.gov/vuln/detail/CVE-2025-57213',
    pubDate: 'Thu, 04 Dec 2025 16:16:00 GMT',
    content: 'Incorrect access control in the component orderService.queryObject of platform v1.0.0 allows attackers to access sensitive information via a crafted request. | Severity UNKNOWN  ',
    contentSnippet: 'Incorrect access control in the component orderService.queryObject of platform v1.0.0 allows attackers to access sensitive information via a crafted request. | Severity UNKNOWN',
    guid: 'CVE-2025-57213',
    isoDate: '2025-12-04T16:16:00.000Z'
  },
  {
    title: 'CVE-2025-61148 An Insecure Direct Object Reference (IDOR) vulnerability in the EduplusCampus 3.0.1 Student Payment ...',
    link: 'https//nvd.nist.gov/vuln/detail/CVE-2025-61148',
    pubDate: 'Thu, 04 Dec 2025 16:16:00 GMT',
    content: "An Insecure Direct Object Reference (IDOR) vulnerability in the EduplusCampus 3.0.1 Student Payment API allows authenticated users to access other students personal and financial records by modifying the 'rec_no' parameter in the /student/get-receipt endpoint. | Severity UNKNOWN  ",
    contentSnippet: "An Insecure Direct Object Reference (IDOR) vulnerability in the EduplusCampus 3.0.1 Student Payment API allows authenticated users to access other students personal and financial records by modifying the 'rec_no' parameter in the /student/get-receipt endpoint. | Severity UNKNOWN",
    guid: 'CVE-2025-61148',
    isoDate: '2025-12-04T16:16:00.000Z'
  },
  {
    title: 'CVE-2025-63681 open-webui v0.6.33 is vulnerable to Incorrect Access Control. The API /api/tasks/stop/ directly acce...',
    link: 'https//nvd.nist.gov/vuln/detail/CVE-2025-63681',
    pubDate: 'Thu, 04 Dec 2025 16:16:00 GMT',
    content: 'open-webui v0.6.33 is vulnerable to Incorrect Access Control. The API /api/tasks/stop/ directly accesses and cancels tasks without verifying user ownership, enabling attackers (a normal user) to stop arbitrary LLM response tasks. | Severity UNKNOWN  ',
    contentSnippet: 'open-webui v0.6.33 is vulnerable to Incorrect Access Control. The API /api/tasks/stop/ directly accesses and cancels tasks without verifying user ownership, enabling attackers (a normal user) to stop arbitrary LLM response tasks. | Severity UNKNOWN',
    guid: 'CVE-2025-63681',
    isoDate: '2025-12-04T16:16:00.000Z'
  },
  {
    title: 'CVE-2025-65516 A stored cross-site scripting (XSS) vulnerability was discovered in Seafile Community Edition prior ...',
    link: 'https//nvd.nist.gov/vuln/detail/CVE-2025-65516',
    pubDate: 'Thu, 04 Dec 2025 16:16:00 GMT',
    content: "A stored cross-site scripting (XSS) vulnerability was discovered in Seafile Community Edition prior to version 13.0.12. When Seafile is configured with the Golang file server, an attacker can upload a crafted SVG file containing malicious JavaScript and share it using a public link. Opening the link triggers script execution in the victim's browser. This issue has been fixed in Seafile Community Edition 13.0.12. | Severity UNKNOWN  ",
    contentSnippet: "A stored cross-site scripting (XSS) vulnerability was discovered in Seafile Community Edition prior to version 13.0.12. When Seafile is configured with the Golang file server, an attacker can upload a crafted SVG file containing malicious JavaScript and share it using a public link. Opening the link triggers script execution in the victim's browser. This issue has been fixed in Seafile Community Edition 13.0.12. | Severity UNKNOWN",
    guid: 'CVE-2025-65516',
    isoDate: '2025-12-04T16:16:00.000Z'
  },
  {
    title: 'CVE-2025-8074 Origin validation error vulnerability in BeeDrive in Synology BeeDrive for desktop before 1.4.3-1397...',
    link: 'https//nvd.nist.gov/vuln/detail/CVE-2025-8074',
    pubDate: 'Thu, 04 Dec 2025 16:16:00 GMT',
    content: 'Origin validation error vulnerability in BeeDrive in Synology BeeDrive for desktop before 1.4.3-13973 allows local users to write arbitrary files with non-sensitive information via unspecified vectors. | CVSS Score 5.6 (MEDIUM)  ',
    contentSnippet: 'Origin validation error vulnerability in BeeDrive in Synology BeeDrive for desktop before 1.4.3-13973 allows local users to write arbitrary files with non-sensitive information via unspecified vectors. | CVSS Score 5.6 (MEDIUM)',
    guid: 'CVE-2025-8074',
    isoDate: '2025-12-04T16:16:00.000Z'
  },
  {
    title: 'Enfin ! Google copie la meilleure fonction de lApple Watch pour ses Pixel Watch',
    link: 'https//www.frandroid.com/marques/google/2899053_enfin-google-copie-la-meilleure-fonction-de-lapple-watch-pour-ses-pixel-watch',
    pubDate: 'Thu, 04 Dec 2025 15:51:00 GMT',
    content: '![CDATA[div class="chapo has-text-weight-semibold mb-5">\n' +
      'div>Surprise ! Google prpare la prise en charge de deux nouveaux gestes sur ses montres connectes Pixel Watch./div>\n' +
      '/div>]]>  ',
    contentSnippet: '![CDATA[div class="chapo has-text-weight-semibold mb-5">\n' +
      'div>Surprise ! Google prpare la prise en charge de deux nouveaux gestes sur ses montres connectes Pixel Watch./div>\n' +
      '/div>]]>',
    guid: 'https://www.frandroid.com/marques/google/2899053_enfin-google-copie-la-meilleure-fonction-de-lapple-watch-pour-ses-pixel-watch',
    categories: [
      'Google',
      'Marques',
      'Montres connectes',
      'OS',
      'Produits',
      'Wear OS (Android Wear)',
      'Wearables',
      'Google Pixel Watch',
      'Google Pixel Watch 4'
    ],
    isoDate: '2025-12-04T15:51:00.000Z'
  },
  {
    title: 'Envie dun son Dolby Atmos ? Cette barre de son Samsung vous loffre pour moins de 250  grce  cette offre',
    link: 'https//www.frandroid.com/bons-plans/2898715_envie-dun-son-dolby-atmos-cette-barre-de-son-samsung-vous-loffre-pour-moins-de-250-e-grace-a-cette-offre',
    pubDate: 'Thu, 04 Dec 2025 16:06:00 GMT',
    content: '![CDATA[div class="chapo has-text-weight-semibold mb-5">\n' +
      'div>Pour donner un peu de relief  vos films et sries, rien ne vaut un vrai traitement Dolby Atmos. Cest exactement la promesse de la Samsung HW-Q610F/XE. Lance  499 euros, la barre de son tombe  248 euros grce  une rduction et une ODR de 100 euros chez Electro Depot./div>\n' +
      '/div>]]>  ',
    contentSnippet: '![CDATA[div class="chapo has-text-weight-semibold mb-5">\n' +
      'div>Pour donner un peu de relief  vos films et sries, rien ne vaut un vrai traitement Dolby Atmos. Cest exactement la promesse de la Samsung HW-Q610F/XE. Lance  499 euros, la barre de son tombe  248 euros grce  une rduction et une ODR de 100 euros chez Electro Depot./div>\n' +
      '/div>]]>',
    guid: 'https://www.frandroid.com/bons-plans/2898715_envie-dun-son-dolby-atmos-cette-barre-de-son-samsung-vous-loffre-pour-moins-de-250-e-grace-a-cette-offre',
    categories: [
      'Audio',
      'Barre de son',
      'Bons plans',
      'Bons plans audio',
      'Bons plans barres de son',
      'Marques',
      'Produits',
      'Samsung',
      'Bons plans Electrodepot'
    ],
    isoDate: '2025-12-04T16:06:00.000Z'
  },
  {
    title: '#FrandroidOffreMoi une imprimante photo Canon Selphy QX20',
    link: 'https//www.frandroid.com/marques/canon/2899035_frandroidoffremoi-une-imprimante-photo-canon-selphy-qx20',
    pubDate: 'Thu, 04 Dec 2025 16:10:00 GMT',
    content: '![CDATA[div class="chapo has-text-weight-semibold mb-5">\n' +
      "div>Pour le quatrime jour du concours #FrandroidOffreMoi du calendrier de l'Avent, nous vous faisons gagner une imprimante Canon Selphy QX20. Voici comment participer !/div>\n" +
      '/div>]]>  ',
    contentSnippet: '![CDATA[div class="chapo has-text-weight-semibold mb-5">\n' +
      "div>Pour le quatrime jour du concours #FrandroidOffreMoi du calendrier de l'Avent, nous vous faisons gagner une imprimante Canon Selphy QX20. Voici comment participer !/div>\n" +
      '/div>]]>',
    guid: 'https://www.frandroid.com/marques/canon/2899035_frandroidoffremoi-une-imprimante-photo-canon-selphy-qx20',
    categories: [
      'Canon',
      'Concours',
      'Humanoid',
      'Marques',
      'Photos et Vidos',
      'Produits',
      '#FrandroidOffreMoi',
      'imprimante mobile'
    ],
    isoDate: '2025-12-04T16:10:00.000Z'
  },
  {
    title: 'Crucial quitte le march en pleine crise de la RAM  la flambe des prix ne fait que commencer',
    link: 'https//www.numerama.com/tech/2134505-crucial-quitte-le-marche-en-pleine-crise-de-la-ram-la-flambee-des-prix-ne-fait-que-commencer.html',
    pubDate: 'Thu, 04 Dec 2025 15:54:00 GMT',
    content: '![CDATA[\n' +
      'Alors que le march de la RAM traverse une crise sans prcdent, un nouveau coup de massue est tomb. Pour ne rien arranger, Crucial vient de claquer la porte du march grand public.\n' +
      ']]>  ',
    contentSnippet: '![CDATA[\n' +
      'Alors que le march de la RAM traverse une crise sans prcdent, un nouveau coup de massue est tomb. Pour ne rien arranger, Crucial vient de claquer la porte du march grand public.\n' +
      ']]>',
    guid: 'https://www.numerama.com/tech/2134505-crucial-quitte-le-marche-en-pleine-crise-de-la-ram-la-flambee-des-prix-ne-fait-que-commencer.html',
    categories: [
      'Informatique',
      'Tech',
      'composant',
      'crucial',
      'informatique',
      'Intelligence artificielle'
    ],
    isoDate: '2025-12-04T15:54:00.000Z'
  },
  {
    title: 'Scuriser les VM Windows Server  la MFA sans complexit',
    link: 'https//www.zataz.com/securiser-les-vm-windows-server-la-mfa-sans-complexite/',
    pubDate: 'Thu, 04 Dec 2025 15:57:00 GMT',
    content: '![CDATA[La virtualisation constitue lun des piliers de linformatique moderne, mais elle nest pas sans dfis de scurit. Le premier problme le nombre dinstances de serveurs virtualiss (machines virtuelles, ou VM) que les administrateurs doivent dsormais dfendre....]]>  ',
    contentSnippet: '![CDATA[La virtualisation constitue lun des piliers de linformatique moderne, mais elle nest pas sans dfis de scurit. Le premier problme le nombre dinstances de serveurs virtualiss (machines virtuelles, ou VM) que les administrateurs doivent dsormais dfendre....]]>',
    guid: 'https://www.zataz.com/securiser-les-vm-windows-server-la-mfa-sans-complexite/',
    categories: [
      'Actualits',
      'Divers',
      'Article partenaire',
      'machines virtuelles',
      'virtualisation'
    ],
    isoDate: '2025-12-04T15:57:00.000Z'
  },
  {
    title: 'ICN (Seoul) on 2025-12-15',
    link: 'https//www.cloudflarestatus.com/incidents/wv1jccnb1gch',
    pubDate: 'Mon, 15 Dec 2025 17:00:00 GMT',
    content: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>15/var>, var data-var='time'>1700/var> - var data-var='time'>2300/var> UTC/strong>small>Dec var data-var='date'> 4/var>, var data-var='time'>0110/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in ICN (Seoul) datacenter on 2025-12-15 between 1700 and 2300 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ",
    contentSnippet: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>15/var>, var data-var='time'>1700/var> - var data-var='time'>2300/var> UTC/strong>small>Dec var data-var='date'> 4/var>, var data-var='time'>0110/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in ICN (Seoul) datacenter on 2025-12-15 between 1700 and 2300 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>",
    guid: 'https://www.cloudflarestatus.com/incidents/wv1jccnb1gch',
    isoDate: '2025-12-15T17:00:00.000Z'
  },
  {
    title: 'IAD (Ashburn) on 2025-12-15',
    link: 'https//www.cloudflarestatus.com/incidents/zy74fzks8cdq',
    pubDate: 'Mon, 15 Dec 2025 07:00:00 GMT',
    content: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>15/var>, var data-var='time'>0700/var> - var data-var='time'>1100/var> UTC/strong>small>Dec var data-var='date'> 4/var>, var data-var='time'>1018/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in IAD (Ashburn) datacenter on 2025-12-15 between 0700 and 1100 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ",
    contentSnippet: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>15/var>, var data-var='time'>0700/var> - var data-var='time'>1100/var> UTC/strong>small>Dec var data-var='date'> 4/var>, var data-var='time'>1018/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in IAD (Ashburn) datacenter on 2025-12-15 between 0700 and 1100 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>",
    guid: 'https://www.cloudflarestatus.com/incidents/zy74fzks8cdq',
    isoDate: '2025-12-15T07:00:00.000Z'
  },
  {
    title: 'YXE (Saskatoon) on 2025-12-12',
    link: 'https//www.cloudflarestatus.com/incidents/jr4wt9dntrvj',
    pubDate: 'Fri, 12 Dec 2025 08:30:00 GMT',
    content: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>12/var>, var data-var='time'>0830/var> - var data-var='time'>1300/var> UTC/strong>small>Dec var data-var='date'> 4/var>, var data-var='time'>0858/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in YXE (Saskatoon) datacenter on 2025-12-12 between 0830 and 1300 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ",
    contentSnippet: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>12/var>, var data-var='time'>0830/var> - var data-var='time'>1300/var> UTC/strong>small>Dec var data-var='date'> 4/var>, var data-var='time'>0858/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in YXE (Saskatoon) datacenter on 2025-12-12 between 0830 and 1300 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>",
    guid: 'https://www.cloudflarestatus.com/incidents/jr4wt9dntrvj',
    isoDate: '2025-12-12T08:30:00.000Z'
  },
  {
    title: 'YYC (Calgary) on 2025-12-12',
    link: 'https//www.cloudflarestatus.com/incidents/b70fwxb4g22t',
    pubDate: 'Fri, 12 Dec 2025 08:30:00 GMT',
    content: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>12/var>, var data-var='time'>0830/var> - var data-var='time'>1300/var> UTC/strong>small>Dec var data-var='date'> 4/var>, var data-var='time'>0858/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in YYC (Calgary) datacenter on 2025-12-12 between 0830 and 1300 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ",
    contentSnippet: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>12/var>, var data-var='time'>0830/var> - var data-var='time'>1300/var> UTC/strong>small>Dec var data-var='date'> 4/var>, var data-var='time'>0858/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in YYC (Calgary) datacenter on 2025-12-12 between 0830 and 1300 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>",
    guid: 'https://www.cloudflarestatus.com/incidents/b70fwxb4g22t',
    isoDate: '2025-12-12T08:30:00.000Z'
  },
  {
    title: 'DEN (Denver) on 2025-12-12',
    link: 'https//www.cloudflarestatus.com/incidents/hj7zvl61kxl8',
    pubDate: 'Fri, 12 Dec 2025 08:30:00 GMT',
    content: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>12/var>, var data-var='time'>0830/var> - var data-var='time'>1300/var> UTC/strong>small>Dec var data-var='date'> 4/var>, var data-var='time'>0902/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in DEN (Denver) datacenter on 2025-12-12 between 0830 and 1300 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ",
    contentSnippet: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>12/var>, var data-var='time'>0830/var> - var data-var='time'>1300/var> UTC/strong>small>Dec var data-var='date'> 4/var>, var data-var='time'>0902/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in DEN (Denver) datacenter on 2025-12-12 between 0830 and 1300 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>",
    guid: 'https://www.cloudflarestatus.com/incidents/hj7zvl61kxl8',
    isoDate: '2025-12-12T08:30:00.000Z'
  },
  {
    title: 'DFW (Dallas) on 2025-12-12',
    link: 'https//www.cloudflarestatus.com/incidents/g038h6c8h1nh',
    pubDate: 'Fri, 12 Dec 2025 08:00:00 GMT',
    content: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>12/var>, var data-var='time'>0800/var> - var data-var='time'>1200/var> UTC/strong>small>Dec var data-var='date'> 4/var>, var data-var='time'>1104/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in DFW (Dallas) datacenter on 2025-12-12 between 0800 and 1200 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ",
    contentSnippet: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>12/var>, var data-var='time'>0800/var> - var data-var='time'>1200/var> UTC/strong>small>Dec var data-var='date'> 4/var>, var data-var='time'>1104/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in DFW (Dallas) datacenter on 2025-12-12 between 0800 and 1200 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>",
    guid: 'https://www.cloudflarestatus.com/incidents/g038h6c8h1nh',
    isoDate: '2025-12-12T08:00:00.000Z'
  },
  {
    title: 'HKG (Hong Kong) on 2025-12-11',
    link: 'https//www.cloudflarestatus.com/incidents/zs533w5kzgdx',
    pubDate: 'Thu, 11 Dec 2025 18:00:00 GMT',
    content: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>11/var>, var data-var='time'>1800/var> - var data-var='time'>2300/var> UTC/strong>small>Dec var data-var='date'> 3/var>, var data-var='time'>0530/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in HKG (Hong Kong) datacenter on 2025-12-11 between 1800 and 2300 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ",
    contentSnippet: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>11/var>, var data-var='time'>1800/var> - var data-var='time'>2300/var> UTC/strong>small>Dec var data-var='date'> 3/var>, var data-var='time'>0530/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in HKG (Hong Kong) datacenter on 2025-12-11 between 1800 and 2300 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>",
    guid: 'https://www.cloudflarestatus.com/incidents/zs533w5kzgdx',
    isoDate: '2025-12-11T18:00:00.000Z'
  },
  {
    title: 'SIN (Singapore) on 2025-12-11',
    link: 'https//www.cloudflarestatus.com/incidents/6wlpd2nz1zpd',
    pubDate: 'Thu, 11 Dec 2025 16:00:00 GMT',
    content: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>11/var>, var data-var='time'>1600/var> UTC nbsp-nbsp Dec var data-var='date'>12/var>, var data-var='time'>0000/var> UTC/strong>small>Dec var data-var='date'> 4/var>, var data-var='time'>0346/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in SIN (Singapore) datacenter between 2025-12-11 1600 and 2025-12-12 0000 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ",
    contentSnippet: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>11/var>, var data-var='time'>1600/var> UTC nbsp-nbsp Dec var data-var='date'>12/var>, var data-var='time'>0000/var> UTC/strong>small>Dec var data-var='date'> 4/var>, var data-var='time'>0346/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in SIN (Singapore) datacenter between 2025-12-11 1600 and 2025-12-12 0000 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>",
    guid: 'https://www.cloudflarestatus.com/incidents/6wlpd2nz1zpd',
    isoDate: '2025-12-11T16:00:00.000Z'
  },
  {
    title: 'AUS (Austin) on 2025-12-11',
    link: 'https//www.cloudflarestatus.com/incidents/vq283hs7vtqw',
    pubDate: 'Thu, 11 Dec 2025 09:00:00 GMT',
    content: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>11/var>, var data-var='time'>0900/var> - var data-var='time'>1200/var> UTC/strong>small>Dec var data-var='date'> 4/var>, var data-var='time'>1102/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in AUS (Austin) datacenter on 2025-12-11 between 0900 and 1200 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ",
    contentSnippet: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>11/var>, var data-var='time'>0900/var> - var data-var='time'>1200/var> UTC/strong>small>Dec var data-var='date'> 4/var>, var data-var='time'>1102/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in AUS (Austin) datacenter on 2025-12-11 between 0900 and 1200 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>",
    guid: 'https://www.cloudflarestatus.com/incidents/vq283hs7vtqw',
    isoDate: '2025-12-11T09:00:00.000Z'
  },
  {
    title: 'SJC (San Jose) on 2025-12-11',
    link: 'https//www.cloudflarestatus.com/incidents/9rcq983c8w6z',
    pubDate: 'Thu, 11 Dec 2025 08:30:00 GMT',
    content: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>11/var>, var data-var='time'>0830/var> - var data-var='time'>1300/var> UTC/strong>small>Dec var data-var='date'> 3/var>, var data-var='time'>2300/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in SJC (San Jose) datacenter on 2025-12-11 between 0830 and 1300 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ",
    contentSnippet: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>11/var>, var data-var='time'>0830/var> - var data-var='time'>1300/var> UTC/strong>small>Dec var data-var='date'> 3/var>, var data-var='time'>2300/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in SJC (San Jose) datacenter on 2025-12-11 between 0830 and 1300 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>",
    guid: 'https://www.cloudflarestatus.com/incidents/9rcq983c8w6z',
    isoDate: '2025-12-11T08:30:00.000Z'
  },
  {
    title: 'TLH (Tallahassee) on 2025-12-11',
    link: 'https//www.cloudflarestatus.com/incidents/gqs7jxs4ndzw',
    pubDate: 'Thu, 11 Dec 2025 07:00:00 GMT',
    content: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>11/var>, var data-var='time'>0700/var> - var data-var='time'>1100/var> UTC/strong>small>Dec var data-var='date'> 3/var>, var data-var='time'>2232/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in TLH (Tallahassee) datacenter on 2025-12-11 between 0700 and 1100 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ",
    contentSnippet: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>11/var>, var data-var='time'>0700/var> - var data-var='time'>1100/var> UTC/strong>small>Dec var data-var='date'> 3/var>, var data-var='time'>2232/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in TLH (Tallahassee) datacenter on 2025-12-11 between 0700 and 1100 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>",
    guid: 'https://www.cloudflarestatus.com/incidents/gqs7jxs4ndzw',
    isoDate: '2025-12-11T07:00:00.000Z'
  },
  {
    title: 'IAD (Ashburn) on 2025-12-11',
    link: 'https//www.cloudflarestatus.com/incidents/fgtpdgmv4mr5',
    pubDate: 'Thu, 11 Dec 2025 07:00:00 GMT',
    content: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>11/var>, var data-var='time'>0700/var> - var data-var='time'>1100/var> UTC/strong>small>Dec var data-var='date'> 3/var>, var data-var='time'>1816/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in IAD (Ashburn) datacenter on 2025-12-11 between 0700 and 1100 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ",
    contentSnippet: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>11/var>, var data-var='time'>0700/var> - var data-var='time'>1100/var> UTC/strong>small>Dec var data-var='date'> 3/var>, var data-var='time'>1816/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in IAD (Ashburn) datacenter on 2025-12-11 between 0700 and 1100 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>",
    guid: 'https://www.cloudflarestatus.com/incidents/fgtpdgmv4mr5',
    isoDate: '2025-12-11T07:00:00.000Z'
  },
  {
    title: 'EZE (Buenos Aires) on 2025-12-11',
    link: 'https//www.cloudflarestatus.com/incidents/cb2j6y554165',
    pubDate: 'Thu, 11 Dec 2025 05:00:00 GMT',
    content: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>11/var>, var data-var='time'>0500/var> - var data-var='time'>0900/var> UTC/strong>small>Dec var data-var='date'> 4/var>, var data-var='time'>0942/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in EZE (Buenos Aires) datacenter on 2025-12-11 between 0500 and 0900 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ",
    contentSnippet: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>11/var>, var data-var='time'>0500/var> - var data-var='time'>0900/var> UTC/strong>small>Dec var data-var='date'> 4/var>, var data-var='time'>0942/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in EZE (Buenos Aires) datacenter on 2025-12-11 between 0500 and 0900 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>",
    guid: 'https://www.cloudflarestatus.com/incidents/cb2j6y554165',
    isoDate: '2025-12-11T05:00:00.000Z'
  },
  {
    title: 'GRU (So Paulo) on 2025-12-11',
    link: 'https//www.cloudflarestatus.com/incidents/mzlhhfz1lnhc',
    pubDate: 'Thu, 11 Dec 2025 05:00:00 GMT',
    content: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>11/var>, var data-var='time'>0500/var> - var data-var='time'>0900/var> UTC/strong>small>Dec var data-var='date'> 2/var>, var data-var='time'>1726/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in GRU (So Paulo) datacenter on 2025-12-11 between 0500 and 0900 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ",
    contentSnippet: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>11/var>, var data-var='time'>0500/var> - var data-var='time'>0900/var> UTC/strong>small>Dec var data-var='date'> 2/var>, var data-var='time'>1726/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in GRU (So Paulo) datacenter on 2025-12-11 between 0500 and 0900 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>",
    guid: 'https://www.cloudflarestatus.com/incidents/mzlhhfz1lnhc',
    isoDate: '2025-12-11T05:00:00.000Z'
  },
  {
    title: 'SIN (Singapore) on 2025-12-10',
    link: 'https//www.cloudflarestatus.com/incidents/lwl9y07g3jr8',
    pubDate: 'Wed, 10 Dec 2025 16:00:00 GMT',
    content: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>10/var>, var data-var='time'>1600/var> UTC nbsp-nbsp Dec var data-var='date'>11/var>, var data-var='time'>0000/var> UTC/strong>small>Dec var data-var='date'> 4/var>, var data-var='time'>0344/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in SIN (Singapore) datacenter between 2025-12-10 1600 and 2025-12-11 0000 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ",
    contentSnippet: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>10/var>, var data-var='time'>1600/var> UTC nbsp-nbsp Dec var data-var='date'>11/var>, var data-var='time'>0000/var> UTC/strong>small>Dec var data-var='date'> 4/var>, var data-var='time'>0344/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in SIN (Singapore) datacenter between 2025-12-10 1600 and 2025-12-11 0000 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>",
    guid: 'https://www.cloudflarestatus.com/incidents/lwl9y07g3jr8',
    isoDate: '2025-12-10T16:00:00.000Z'
  },
  {
    title: 'ATL (Atlanta) on 2025-12-10',
    link: 'https//www.cloudflarestatus.com/incidents/881xjrpxl4h7',
    pubDate: 'Wed, 10 Dec 2025 08:30:00 GMT',
    content: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>10/var>, var data-var='time'>0830/var> - var data-var='time'>1300/var> UTC/strong>small>Dec var data-var='date'> 3/var>, var data-var='time'>2246/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in ATL (Atlanta) datacenter on 2025-12-10 between 0830 and 1300 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ",
    contentSnippet: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>10/var>, var data-var='time'>0830/var> - var data-var='time'>1300/var> UTC/strong>small>Dec var data-var='date'> 3/var>, var data-var='time'>2246/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in ATL (Atlanta) datacenter on 2025-12-10 between 0830 and 1300 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>",
    guid: 'https://www.cloudflarestatus.com/incidents/881xjrpxl4h7',
    isoDate: '2025-12-10T08:30:00.000Z'
  },
  {
    title: 'QRO (Queretaro) on 2025-12-10',
    link: 'https//www.cloudflarestatus.com/incidents/vhhdg0jypmp6',
    pubDate: 'Wed, 10 Dec 2025 08:00:00 GMT',
    content: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>10/var>, var data-var='time'>0800/var> - var data-var='time'>1200/var> UTC/strong>small>Dec var data-var='date'> 3/var>, var data-var='time'>2212/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in QRO (Queretaro) datacenter on 2025-12-10 between 0800 and 1200 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ",
    contentSnippet: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>10/var>, var data-var='time'>0800/var> - var data-var='time'>1200/var> UTC/strong>small>Dec var data-var='date'> 3/var>, var data-var='time'>2212/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in QRO (Queretaro) datacenter on 2025-12-10 between 0800 and 1200 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>",
    guid: 'https://www.cloudflarestatus.com/incidents/vhhdg0jypmp6',
    isoDate: '2025-12-10T08:00:00.000Z'
  },
  {
    title: 'STL (St. Louis) on 2025-12-10',
    link: 'https//www.cloudflarestatus.com/incidents/vjxjrwn7ckn7',
    pubDate: 'Wed, 10 Dec 2025 08:00:00 GMT',
    content: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>10/var>, var data-var='time'>0800/var> - var data-var='time'>1200/var> UTC/strong>small>Dec var data-var='date'> 3/var>, var data-var='time'>2220/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in STL (St. Louis) datacenter on 2025-12-10 between 0800 and 1200 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ",
    contentSnippet: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>10/var>, var data-var='time'>0800/var> - var data-var='time'>1200/var> UTC/strong>small>Dec var data-var='date'> 3/var>, var data-var='time'>2220/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in STL (St. Louis) datacenter on 2025-12-10 between 0800 and 1200 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>",
    guid: 'https://www.cloudflarestatus.com/incidents/vjxjrwn7ckn7',
    isoDate: '2025-12-10T08:00:00.000Z'
  },
  {
    title: 'MEM (Memphis) on 2025-12-10',
    link: 'https//www.cloudflarestatus.com/incidents/cvr6jtmth2my',
    pubDate: 'Wed, 10 Dec 2025 08:00:00 GMT',
    content: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>10/var>, var data-var='time'>0800/var> - var data-var='time'>1200/var> UTC/strong>small>Dec var data-var='date'> 3/var>, var data-var='time'>2224/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in MEM (Memphis) datacenter on 2025-12-10 between 0800 and 1200 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ",
    contentSnippet: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>10/var>, var data-var='time'>0800/var> - var data-var='time'>1200/var> UTC/strong>small>Dec var data-var='date'> 3/var>, var data-var='time'>2224/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in MEM (Memphis) datacenter on 2025-12-10 between 0800 and 1200 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>",
    guid: 'https://www.cloudflarestatus.com/incidents/cvr6jtmth2my',
    isoDate: '2025-12-10T08:00:00.000Z'
  },
  {
    title: 'UIO (Quito) on 2025-12-10',
    link: 'https//www.cloudflarestatus.com/incidents/szsc5kf0jxzx',
    pubDate: 'Wed, 10 Dec 2025 07:00:00 GMT',
    content: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>10/var>, var data-var='time'>0700/var> - var data-var='time'>1100/var> UTC/strong>small>Dec var data-var='date'> 4/var>, var data-var='time'>1058/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in UIO (Quito) datacenter on 2025-12-10 between 0700 and 1100 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ",
    contentSnippet: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>10/var>, var data-var='time'>0700/var> - var data-var='time'>1100/var> UTC/strong>small>Dec var data-var='date'> 4/var>, var data-var='time'>1058/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in UIO (Quito) datacenter on 2025-12-10 between 0700 and 1100 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>",
    guid: 'https://www.cloudflarestatus.com/incidents/szsc5kf0jxzx',
    isoDate: '2025-12-10T07:00:00.000Z'
  },
  {
    title: 'DTW (Detroit) on 2025-12-10',
    link: 'https//www.cloudflarestatus.com/incidents/22lp73hp9rhh',
    pubDate: 'Wed, 10 Dec 2025 07:00:00 GMT',
    content: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>10/var>, var data-var='time'>0700/var> - var data-var='time'>1100/var> UTC/strong>small>Dec var data-var='date'> 3/var>, var data-var='time'>2206/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in DTW (Detroit) datacenter on 2025-12-10 between 0700 and 1100 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ",
    contentSnippet: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>10/var>, var data-var='time'>0700/var> - var data-var='time'>1100/var> UTC/strong>small>Dec var data-var='date'> 3/var>, var data-var='time'>2206/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in DTW (Detroit) datacenter on 2025-12-10 between 0700 and 1100 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>",
    guid: 'https://www.cloudflarestatus.com/incidents/22lp73hp9rhh',
    isoDate: '2025-12-10T07:00:00.000Z'
  },
  {
    title: 'PIT (Pittsburgh) on 2025-12-10',
    link: 'https//www.cloudflarestatus.com/incidents/cdxn4ykf0qj9',
    pubDate: 'Wed, 10 Dec 2025 07:00:00 GMT',
    content: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>10/var>, var data-var='time'>0700/var> - var data-var='time'>1100/var> UTC/strong>small>Dec var data-var='date'> 3/var>, var data-var='time'>2210/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in PIT (Pittsburgh) datacenter on 2025-12-10 between 0700 and 1100 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ",
    contentSnippet: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>10/var>, var data-var='time'>0700/var> - var data-var='time'>1100/var> UTC/strong>small>Dec var data-var='date'> 3/var>, var data-var='time'>2210/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in PIT (Pittsburgh) datacenter on 2025-12-10 between 0700 and 1100 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>",
    guid: 'https://www.cloudflarestatus.com/incidents/cdxn4ykf0qj9',
    isoDate: '2025-12-10T07:00:00.000Z'
  },
  {
    title: 'YYZ (Toronto) on 2025-12-10',
    link: 'https//www.cloudflarestatus.com/incidents/k3pdp1s98ycc',
    pubDate: 'Wed, 10 Dec 2025 07:00:00 GMT',
    content: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>10/var>, var data-var='time'>0700/var> - var data-var='time'>1100/var> UTC/strong>small>Dec var data-var='date'> 3/var>, var data-var='time'>1758/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in YYZ (Toronto) datacenter on 2025-12-10 between 0700 and 1100 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ",
    contentSnippet: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>10/var>, var data-var='time'>0700/var> - var data-var='time'>1100/var> UTC/strong>small>Dec var data-var='date'> 3/var>, var data-var='time'>1758/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in YYZ (Toronto) datacenter on 2025-12-10 between 0700 and 1100 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>",
    guid: 'https://www.cloudflarestatus.com/incidents/k3pdp1s98ycc',
    isoDate: '2025-12-10T07:00:00.000Z'
  },
  {
    title: 'IAD (Ashburn) on 2025-12-10',
    link: 'https//www.cloudflarestatus.com/incidents/cvmrqcs2qxgx',
    pubDate: 'Wed, 10 Dec 2025 07:00:00 GMT',
    content: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>10/var>, var data-var='time'>0700/var> - var data-var='time'>1100/var> UTC/strong>small>Dec var data-var='date'> 2/var>, var data-var='time'>1804/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in IAD (Ashburn) datacenter on 2025-12-10 between 0700 and 1100 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ",
    contentSnippet: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>10/var>, var data-var='time'>0700/var> - var data-var='time'>1100/var> UTC/strong>small>Dec var data-var='date'> 2/var>, var data-var='time'>1804/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in IAD (Ashburn) datacenter on 2025-12-10 between 0700 and 1100 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>",
    guid: 'https://www.cloudflarestatus.com/incidents/cvmrqcs2qxgx',
    isoDate: '2025-12-10T07:00:00.000Z'
  },
  {
    title: 'GRU (So Paulo) on 2025-12-10',
    link: 'https//www.cloudflarestatus.com/incidents/pxqc2ddt7cj0',
    pubDate: 'Wed, 10 Dec 2025 05:00:00 GMT',
    content: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>10/var>, var data-var='time'>0500/var> - var data-var='time'>0900/var> UTC/strong>small>Dec var data-var='date'> 2/var>, var data-var='time'>1724/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in GRU (So Paulo) datacenter on 2025-12-10 between 0500 and 0900 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ",
    contentSnippet: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>10/var>, var data-var='time'>0500/var> - var data-var='time'>0900/var> UTC/strong>small>Dec var data-var='date'> 2/var>, var data-var='time'>1724/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in GRU (So Paulo) datacenter on 2025-12-10 between 0500 and 0900 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>",
    guid: 'https://www.cloudflarestatus.com/incidents/pxqc2ddt7cj0',
    isoDate: '2025-12-10T05:00:00.000Z'
  },
  {
    title: 'SIN (Singapore) on 2025-12-09',
    link: 'https//www.cloudflarestatus.com/incidents/pmjjdkdvq8km',
    pubDate: 'Tue, 09 Dec 2025 16:00:00 GMT',
    content: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>9/var>, var data-var='time'>1600/var> UTC nbsp-nbsp Dec var data-var='date'>10/var>, var data-var='time'>0000/var> UTC/strong>small>Dec var data-var='date'> 4/var>, var data-var='time'>0344/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in SIN (Singapore) datacenter between 2025-12-09 1600 and 2025-12-10 0000 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ",
    contentSnippet: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>9/var>, var data-var='time'>1600/var> UTC nbsp-nbsp Dec var data-var='date'>10/var>, var data-var='time'>0000/var> UTC/strong>small>Dec var data-var='date'> 4/var>, var data-var='time'>0344/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in SIN (Singapore) datacenter between 2025-12-09 1600 and 2025-12-10 0000 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>",
    guid: 'https://www.cloudflarestatus.com/incidents/pmjjdkdvq8km',
    isoDate: '2025-12-09T16:00:00.000Z'
  },
  {
    title: 'AUS (Austin) on 2025-12-09',
    link: 'https//www.cloudflarestatus.com/incidents/yd2zrg547x43',
    pubDate: 'Tue, 09 Dec 2025 08:00:00 GMT',
    content: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>9/var>, var data-var='time'>0800/var> - var data-var='time'>1200/var> UTC/strong>small>Dec var data-var='date'> 3/var>, var data-var='time'>2150/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in AUS (Austin) datacenter on 2025-12-09 between 0800 and 1200 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ",
    contentSnippet: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>9/var>, var data-var='time'>0800/var> - var data-var='time'>1200/var> UTC/strong>small>Dec var data-var='date'> 3/var>, var data-var='time'>2150/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in AUS (Austin) datacenter on 2025-12-09 between 0800 and 1200 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>",
    guid: 'https://www.cloudflarestatus.com/incidents/yd2zrg547x43',
    isoDate: '2025-12-09T08:00:00.000Z'
  },
  {
    title: 'BNA (Nashville) on 2025-12-09',
    link: 'https//www.cloudflarestatus.com/incidents/sjxbt42t9k69',
    pubDate: 'Tue, 09 Dec 2025 08:00:00 GMT',
    content: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>9/var>, var data-var='time'>0800/var> - var data-var='time'>1200/var> UTC/strong>small>Dec var data-var='date'> 3/var>, var data-var='time'>1506/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in BNA (Nashville) datacenter on 2025-12-09 between 0800 and 1200 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ",
    contentSnippet: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>9/var>, var data-var='time'>0800/var> - var data-var='time'>1200/var> UTC/strong>small>Dec var data-var='date'> 3/var>, var data-var='time'>1506/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in BNA (Nashville) datacenter on 2025-12-09 between 0800 and 1200 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>",
    guid: 'https://www.cloudflarestatus.com/incidents/sjxbt42t9k69',
    isoDate: '2025-12-09T08:00:00.000Z'
  },
  {
    title: 'DFW (Dallas) on 2025-12-09',
    link: 'https//www.cloudflarestatus.com/incidents/yj9pnxw5ttx2',
    pubDate: 'Tue, 09 Dec 2025 08:00:00 GMT',
    content: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>9/var>, var data-var='time'>0800/var> - var data-var='time'>1200/var> UTC/strong>small>Dec var data-var='date'> 2/var>, var data-var='time'>1412/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in DFW (Dallas) datacenter on 2025-12-09 between 0800 and 1200 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ",
    contentSnippet: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>9/var>, var data-var='time'>0800/var> - var data-var='time'>1200/var> UTC/strong>small>Dec var data-var='date'> 2/var>, var data-var='time'>1412/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in DFW (Dallas) datacenter on 2025-12-09 between 0800 and 1200 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>",
    guid: 'https://www.cloudflarestatus.com/incidents/yj9pnxw5ttx2',
    isoDate: '2025-12-09T08:00:00.000Z'
  },
  {
    title: 'BUF (Buffalo) on 2025-12-09',
    link: 'https//www.cloudflarestatus.com/incidents/kbjmzdg16ffq',
    pubDate: 'Tue, 09 Dec 2025 07:00:00 GMT',
    content: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>9/var>, var data-var='time'>0700/var> - var data-var='time'>1100/var> UTC/strong>small>Dec var data-var='date'> 3/var>, var data-var='time'>2156/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in BUF (Buffalo) datacenter on 2025-12-09 between 0700 and 1100 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ",
    contentSnippet: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>9/var>, var data-var='time'>0700/var> - var data-var='time'>1100/var> UTC/strong>small>Dec var data-var='date'> 3/var>, var data-var='time'>2156/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in BUF (Buffalo) datacenter on 2025-12-09 between 0700 and 1100 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>",
    guid: 'https://www.cloudflarestatus.com/incidents/kbjmzdg16ffq',
    isoDate: '2025-12-09T07:00:00.000Z'
  },
  {
    title: 'IAD (Ashburn) on 2025-12-09',
    link: 'https//www.cloudflarestatus.com/incidents/8bqvf7gky4st',
    pubDate: 'Tue, 09 Dec 2025 07:00:00 GMT',
    content: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>9/var>, var data-var='time'>0700/var> - var data-var='time'>1100/var> UTC/strong>small>Dec var data-var='date'> 3/var>, var data-var='time'>1813/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in IAD (Ashburn) datacenter on 2025-12-09 between 0700 and 1100 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ",
    contentSnippet: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>9/var>, var data-var='time'>0700/var> - var data-var='time'>1100/var> UTC/strong>small>Dec var data-var='date'> 3/var>, var data-var='time'>1813/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in IAD (Ashburn) datacenter on 2025-12-09 between 0700 and 1100 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>",
    guid: 'https://www.cloudflarestatus.com/incidents/8bqvf7gky4st',
    isoDate: '2025-12-09T07:00:00.000Z'
  },
  {
    title: 'YYZ (Toronto) on 2025-12-09',
    link: 'https//www.cloudflarestatus.com/incidents/t05tmjs0d5mn',
    pubDate: 'Tue, 09 Dec 2025 07:00:00 GMT',
    content: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>9/var>, var data-var='time'>0700/var> - var data-var='time'>1100/var> UTC/strong>small>Dec var data-var='date'> 3/var>, var data-var='time'>1754/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in YYZ (Toronto) datacenter on 2025-12-09 between 0700 and 1100 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ",
    contentSnippet: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>9/var>, var data-var='time'>0700/var> - var data-var='time'>1100/var> UTC/strong>small>Dec var data-var='date'> 3/var>, var data-var='time'>1754/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in YYZ (Toronto) datacenter on 2025-12-09 between 0700 and 1100 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>",
    guid: 'https://www.cloudflarestatus.com/incidents/t05tmjs0d5mn',
    isoDate: '2025-12-09T07:00:00.000Z'
  },
  {
    title: 'CMH (Columbus) on 2025-12-09',
    link: 'https//www.cloudflarestatus.com/incidents/x5q2dk93y2b6',
    pubDate: 'Tue, 09 Dec 2025 07:00:00 GMT',
    content: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>9/var>, var data-var='time'>0700/var> - var data-var='time'>1100/var> UTC/strong>small>Dec var data-var='date'> 3/var>, var data-var='time'>1440/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in CMH (Columbus) datacenter on 2025-12-09 between 0700 and 1100 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ",
    contentSnippet: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>9/var>, var data-var='time'>0700/var> - var data-var='time'>1100/var> UTC/strong>small>Dec var data-var='date'> 3/var>, var data-var='time'>1440/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in CMH (Columbus) datacenter on 2025-12-09 between 0700 and 1100 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>",
    guid: 'https://www.cloudflarestatus.com/incidents/x5q2dk93y2b6',
    isoDate: '2025-12-09T07:00:00.000Z'
  },
  {
    title: 'IAD (Ashburn) on 2025-12-09',
    link: 'https//www.cloudflarestatus.com/incidents/hlyvxz2wg6rf',
    pubDate: 'Tue, 09 Dec 2025 07:00:00 GMT',
    content: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>9/var>, var data-var='time'>0700/var> - var data-var='time'>1100/var> UTC/strong>small>Dec var data-var='date'> 2/var>, var data-var='time'>1744/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in IAD (Ashburn) datacenter on 2025-12-09 between 0700 and 1100 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ",
    contentSnippet: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>9/var>, var data-var='time'>0700/var> - var data-var='time'>1100/var> UTC/strong>small>Dec var data-var='date'> 2/var>, var data-var='time'>1744/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in IAD (Ashburn) datacenter on 2025-12-09 between 0700 and 1100 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>",
    guid: 'https://www.cloudflarestatus.com/incidents/hlyvxz2wg6rf',
    isoDate: '2025-12-09T07:00:00.000Z'
  },
  {
    title: 'GRU (So Paulo) on 2025-12-09',
    link: 'https//www.cloudflarestatus.com/incidents/2q1qzj2vzbvq',
    pubDate: 'Tue, 09 Dec 2025 05:00:00 GMT',
    content: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>9/var>, var data-var='time'>0500/var> - var data-var='time'>0900/var> UTC/strong>small>Dec var data-var='date'> 2/var>, var data-var='time'>1722/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in GRU (So Paulo) datacenter on 2025-12-09 between 0500 and 0900 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ",
    contentSnippet: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>9/var>, var data-var='time'>0500/var> - var data-var='time'>0900/var> UTC/strong>small>Dec var data-var='date'> 2/var>, var data-var='time'>1722/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in GRU (So Paulo) datacenter on 2025-12-09 between 0500 and 0900 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>",
    guid: 'https://www.cloudflarestatus.com/incidents/2q1qzj2vzbvq',
    isoDate: '2025-12-09T05:00:00.000Z'
  },
  {
    title: 'BNA (Nashville) on 2025-12-08',
    link: 'https//www.cloudflarestatus.com/incidents/yffdhw5f27tz',
    pubDate: 'Mon, 08 Dec 2025 08:00:00 GMT',
    content: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>8/var>, var data-var='time'>0800/var> - var data-var='time'>1200/var> UTC/strong>small>Dec var data-var='date'> 3/var>, var data-var='time'>1402/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in BNA (Nashville) datacenter on 2025-12-08 between 0800 and 1200 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ",
    contentSnippet: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>8/var>, var data-var='time'>0800/var> - var data-var='time'>1200/var> UTC/strong>small>Dec var data-var='date'> 3/var>, var data-var='time'>1402/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in BNA (Nashville) datacenter on 2025-12-08 between 0800 and 1200 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>",
    guid: 'https://www.cloudflarestatus.com/incidents/yffdhw5f27tz',
    isoDate: '2025-12-08T08:00:00.000Z'
  },
  {
    title: 'BOS (Boston) on 2025-12-08',
    link: 'https//www.cloudflarestatus.com/incidents/h433hnnlrc9b',
    pubDate: 'Mon, 08 Dec 2025 07:00:00 GMT',
    content: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>8/var>, var data-var='time'>0700/var> - var data-var='time'>1100/var> UTC/strong>small>Dec var data-var='date'> 3/var>, var data-var='time'>1746/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in BOS (Boston) datacenter on 2025-12-08 between 0700 and 1100 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ",
    contentSnippet: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>8/var>, var data-var='time'>0700/var> - var data-var='time'>1100/var> UTC/strong>small>Dec var data-var='date'> 3/var>, var data-var='time'>1746/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in BOS (Boston) datacenter on 2025-12-08 between 0700 and 1100 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>",
    guid: 'https://www.cloudflarestatus.com/incidents/h433hnnlrc9b',
    isoDate: '2025-12-08T07:00:00.000Z'
  },
  {
    title: 'CMH (Columbus) on 2025-12-08',
    link: 'https//www.cloudflarestatus.com/incidents/02q2016k78dm',
    pubDate: 'Mon, 08 Dec 2025 07:00:00 GMT',
    content: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>8/var>, var data-var='time'>0700/var> - var data-var='time'>1100/var> UTC/strong>small>Dec var data-var='date'> 3/var>, var data-var='time'>1440/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in CMH (Columbus) datacenter on 2025-12-08 between 0700 and 1100 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ",
    contentSnippet: "![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[![CDATA[strong>THIS IS A SCHEDULED EVENT Dec var data-var='date'>8/var>, var data-var='time'>0700/var> - var data-var='time'>1100/var> UTC/strong>small>Dec var data-var='date'> 3/var>, var data-var='time'>1440/var> UTC/small>strong>Scheduled/strong> - We will be performing scheduled maintenance in CMH (Columbus) datacenter on 2025-12-08 between 0700 and 1100 UTC.br />br />Traffic might be re-routed from this location, hence there is a possibility of a slight increase in latency during this maintenance window for end-users in the affected region. For PNI / CNI customers connecting with us in this location, please make sure you are expecting this traffic to fail over elsewhere during this maintenance window as network interfaces in this datacentre may become temporarily unavailable.br />br />You can now subscribe to these notifications via Cloudflare dashboard and receive these updates directly via email, PagerDuty and webhooks (based on your plan) https//developers.cloudflare.com/notifications/notification-available/#cloudflare-status.]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>  ]]>",
    guid: 'https://www.cloudflarestatus.com/incidents/02q2016k78dm',
    isoDate: '2025-12-08T07:00:00.000Z'
  },
  ... 62 more items
]
